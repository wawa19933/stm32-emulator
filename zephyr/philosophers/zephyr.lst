
zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

08000000 <_vector_table>:
 8000000:	80 47 00 20 4d 17 00 08 3b 4b 00 08 21 17 00 08     .G. M...;K..!...
 8000010:	21 17 00 08 21 17 00 08 21 17 00 08 00 00 00 00     !...!...!.......
	...
 800002c:	95 13 00 08 21 17 00 08 00 00 00 00 3d 13 00 08     ....!.......=...
 800003c:	71 23 00 08                                         q#..

08000040 <_irq_vector_table>:
 8000040:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000050:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000060:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000070:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000080:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000090:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 80000a0:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 80000b0:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 80000c0:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 80000d0:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 80000e0:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 80000f0:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000100:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000110:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000120:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000130:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000140:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000150:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000160:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000170:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000180:	49 14 00 08 49 14 00 08 49 14 00 08 49 14 00 08     I...I...I...I...
 8000190:	49 14 00 08 49 14 00 08                             I...I...

Disassembly of section text:

08000198 <__aeabi_uldivmod>:
 8000198:	b953      	cbnz	r3, 80001b0 <__aeabi_uldivmod+0x18>
 800019a:	b94a      	cbnz	r2, 80001b0 <__aeabi_uldivmod+0x18>
 800019c:	2900      	cmp	r1, #0
 800019e:	bf08      	it	eq
 80001a0:	2800      	cmpeq	r0, #0
 80001a2:	bf1c      	itt	ne
 80001a4:	f04f 31ff 	movne.w	r1, #4294967295	; 0xffffffff
 80001a8:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
 80001ac:	f000 b80c 	b.w	80001c8 <__aeabi_idiv0>
 80001b0:	f1ad 0c08 	sub.w	ip, sp, #8
 80001b4:	e96d ce04 	strd	ip, lr, [sp, #-16]!
 80001b8:	f000 f808 	bl	80001cc <__udivmoddi4>
 80001bc:	f8dd e004 	ldr.w	lr, [sp, #4]
 80001c0:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
 80001c4:	b004      	add	sp, #16
 80001c6:	4770      	bx	lr

080001c8 <__aeabi_idiv0>:
 80001c8:	4770      	bx	lr
 80001ca:	bf00      	nop

080001cc <__udivmoddi4>:
 80001cc:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
 80001d0:	4686      	mov	lr, r0
 80001d2:	468c      	mov	ip, r1
 80001d4:	4608      	mov	r0, r1
 80001d6:	9e08      	ldr	r6, [sp, #32]
 80001d8:	4615      	mov	r5, r2
 80001da:	4674      	mov	r4, lr
 80001dc:	4619      	mov	r1, r3
 80001de:	2b00      	cmp	r3, #0
 80001e0:	f040 80c2 	bne.w	8000368 <__udivmoddi4+0x19c>
 80001e4:	4285      	cmp	r5, r0
 80001e6:	fab2 f282 	clz	r2, r2
 80001ea:	d945      	bls.n	8000278 <__udivmoddi4+0xac>
 80001ec:	b14a      	cbz	r2, 8000202 <__udivmoddi4+0x36>
 80001ee:	f1c2 0320 	rsb	r3, r2, #32
 80001f2:	fa00 fc02 	lsl.w	ip, r0, r2
 80001f6:	fa2e f303 	lsr.w	r3, lr, r3
 80001fa:	4095      	lsls	r5, r2
 80001fc:	ea43 0c0c 	orr.w	ip, r3, ip
 8000200:	4094      	lsls	r4, r2
 8000202:	ea4f 4e15 	mov.w	lr, r5, lsr #16
 8000206:	b2a8      	uxth	r0, r5
 8000208:	fbbc f8fe 	udiv	r8, ip, lr
 800020c:	0c23      	lsrs	r3, r4, #16
 800020e:	fb0e cc18 	mls	ip, lr, r8, ip
 8000212:	fb08 f900 	mul.w	r9, r8, r0
 8000216:	ea43 430c 	orr.w	r3, r3, ip, lsl #16
 800021a:	4599      	cmp	r9, r3
 800021c:	d928      	bls.n	8000270 <__udivmoddi4+0xa4>
 800021e:	18eb      	adds	r3, r5, r3
 8000220:	f108 37ff 	add.w	r7, r8, #4294967295	; 0xffffffff
 8000224:	d204      	bcs.n	8000230 <__udivmoddi4+0x64>
 8000226:	4599      	cmp	r9, r3
 8000228:	d902      	bls.n	8000230 <__udivmoddi4+0x64>
 800022a:	f1a8 0702 	sub.w	r7, r8, #2
 800022e:	442b      	add	r3, r5
 8000230:	eba3 0309 	sub.w	r3, r3, r9
 8000234:	b2a4      	uxth	r4, r4
 8000236:	fbb3 fcfe 	udiv	ip, r3, lr
 800023a:	fb0e 331c 	mls	r3, lr, ip, r3
 800023e:	fb0c f000 	mul.w	r0, ip, r0
 8000242:	ea44 4403 	orr.w	r4, r4, r3, lsl #16
 8000246:	42a0      	cmp	r0, r4
 8000248:	d914      	bls.n	8000274 <__udivmoddi4+0xa8>
 800024a:	192c      	adds	r4, r5, r4
 800024c:	f10c 33ff 	add.w	r3, ip, #4294967295	; 0xffffffff
 8000250:	d204      	bcs.n	800025c <__udivmoddi4+0x90>
 8000252:	42a0      	cmp	r0, r4
 8000254:	d902      	bls.n	800025c <__udivmoddi4+0x90>
 8000256:	f1ac 0302 	sub.w	r3, ip, #2
 800025a:	442c      	add	r4, r5
 800025c:	1a24      	subs	r4, r4, r0
 800025e:	ea43 4007 	orr.w	r0, r3, r7, lsl #16
 8000262:	b11e      	cbz	r6, 800026c <__udivmoddi4+0xa0>
 8000264:	40d4      	lsrs	r4, r2
 8000266:	2300      	movs	r3, #0
 8000268:	6034      	str	r4, [r6, #0]
 800026a:	6073      	str	r3, [r6, #4]
 800026c:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 8000270:	4647      	mov	r7, r8
 8000272:	e7dd      	b.n	8000230 <__udivmoddi4+0x64>
 8000274:	4663      	mov	r3, ip
 8000276:	e7f1      	b.n	800025c <__udivmoddi4+0x90>
 8000278:	bb92      	cbnz	r2, 80002e0 <__udivmoddi4+0x114>
 800027a:	1b43      	subs	r3, r0, r5
 800027c:	2101      	movs	r1, #1
 800027e:	ea4f 4e15 	mov.w	lr, r5, lsr #16
 8000282:	b2af      	uxth	r7, r5
 8000284:	fbb3 fcfe 	udiv	ip, r3, lr
 8000288:	0c20      	lsrs	r0, r4, #16
 800028a:	fb0e 331c 	mls	r3, lr, ip, r3
 800028e:	fb0c f807 	mul.w	r8, ip, r7
 8000292:	ea40 4303 	orr.w	r3, r0, r3, lsl #16
 8000296:	4598      	cmp	r8, r3
 8000298:	d962      	bls.n	8000360 <__udivmoddi4+0x194>
 800029a:	18eb      	adds	r3, r5, r3
 800029c:	f10c 30ff 	add.w	r0, ip, #4294967295	; 0xffffffff
 80002a0:	d204      	bcs.n	80002ac <__udivmoddi4+0xe0>
 80002a2:	4598      	cmp	r8, r3
 80002a4:	d902      	bls.n	80002ac <__udivmoddi4+0xe0>
 80002a6:	f1ac 0002 	sub.w	r0, ip, #2
 80002aa:	442b      	add	r3, r5
 80002ac:	eba3 0308 	sub.w	r3, r3, r8
 80002b0:	b2a4      	uxth	r4, r4
 80002b2:	fbb3 fcfe 	udiv	ip, r3, lr
 80002b6:	fb0e 331c 	mls	r3, lr, ip, r3
 80002ba:	fb0c f707 	mul.w	r7, ip, r7
 80002be:	ea44 4403 	orr.w	r4, r4, r3, lsl #16
 80002c2:	42a7      	cmp	r7, r4
 80002c4:	d94e      	bls.n	8000364 <__udivmoddi4+0x198>
 80002c6:	192c      	adds	r4, r5, r4
 80002c8:	f10c 33ff 	add.w	r3, ip, #4294967295	; 0xffffffff
 80002cc:	d204      	bcs.n	80002d8 <__udivmoddi4+0x10c>
 80002ce:	42a7      	cmp	r7, r4
 80002d0:	d902      	bls.n	80002d8 <__udivmoddi4+0x10c>
 80002d2:	f1ac 0302 	sub.w	r3, ip, #2
 80002d6:	442c      	add	r4, r5
 80002d8:	1be4      	subs	r4, r4, r7
 80002da:	ea43 4000 	orr.w	r0, r3, r0, lsl #16
 80002de:	e7c0      	b.n	8000262 <__udivmoddi4+0x96>
 80002e0:	f1c2 0320 	rsb	r3, r2, #32
 80002e4:	fa20 f103 	lsr.w	r1, r0, r3
 80002e8:	4095      	lsls	r5, r2
 80002ea:	4090      	lsls	r0, r2
 80002ec:	fa2e f303 	lsr.w	r3, lr, r3
 80002f0:	4303      	orrs	r3, r0
 80002f2:	ea4f 4e15 	mov.w	lr, r5, lsr #16
 80002f6:	b2af      	uxth	r7, r5
 80002f8:	fbb1 fcfe 	udiv	ip, r1, lr
 80002fc:	fb0e 101c 	mls	r0, lr, ip, r1
 8000300:	0c19      	lsrs	r1, r3, #16
 8000302:	fb0c f807 	mul.w	r8, ip, r7
 8000306:	ea41 4100 	orr.w	r1, r1, r0, lsl #16
 800030a:	4588      	cmp	r8, r1
 800030c:	fa04 f402 	lsl.w	r4, r4, r2
 8000310:	d922      	bls.n	8000358 <__udivmoddi4+0x18c>
 8000312:	1869      	adds	r1, r5, r1
 8000314:	f10c 30ff 	add.w	r0, ip, #4294967295	; 0xffffffff
 8000318:	d204      	bcs.n	8000324 <__udivmoddi4+0x158>
 800031a:	4588      	cmp	r8, r1
 800031c:	d902      	bls.n	8000324 <__udivmoddi4+0x158>
 800031e:	f1ac 0002 	sub.w	r0, ip, #2
 8000322:	4429      	add	r1, r5
 8000324:	eba1 0108 	sub.w	r1, r1, r8
 8000328:	b29b      	uxth	r3, r3
 800032a:	fbb1 fcfe 	udiv	ip, r1, lr
 800032e:	fb0e 111c 	mls	r1, lr, ip, r1
 8000332:	fb0c f707 	mul.w	r7, ip, r7
 8000336:	ea43 4301 	orr.w	r3, r3, r1, lsl #16
 800033a:	429f      	cmp	r7, r3
 800033c:	d90e      	bls.n	800035c <__udivmoddi4+0x190>
 800033e:	18eb      	adds	r3, r5, r3
 8000340:	f10c 31ff 	add.w	r1, ip, #4294967295	; 0xffffffff
 8000344:	d204      	bcs.n	8000350 <__udivmoddi4+0x184>
 8000346:	429f      	cmp	r7, r3
 8000348:	d902      	bls.n	8000350 <__udivmoddi4+0x184>
 800034a:	f1ac 0102 	sub.w	r1, ip, #2
 800034e:	442b      	add	r3, r5
 8000350:	1bdb      	subs	r3, r3, r7
 8000352:	ea41 4100 	orr.w	r1, r1, r0, lsl #16
 8000356:	e792      	b.n	800027e <__udivmoddi4+0xb2>
 8000358:	4660      	mov	r0, ip
 800035a:	e7e3      	b.n	8000324 <__udivmoddi4+0x158>
 800035c:	4661      	mov	r1, ip
 800035e:	e7f7      	b.n	8000350 <__udivmoddi4+0x184>
 8000360:	4660      	mov	r0, ip
 8000362:	e7a3      	b.n	80002ac <__udivmoddi4+0xe0>
 8000364:	4663      	mov	r3, ip
 8000366:	e7b7      	b.n	80002d8 <__udivmoddi4+0x10c>
 8000368:	4283      	cmp	r3, r0
 800036a:	d906      	bls.n	800037a <__udivmoddi4+0x1ae>
 800036c:	b916      	cbnz	r6, 8000374 <__udivmoddi4+0x1a8>
 800036e:	2100      	movs	r1, #0
 8000370:	4608      	mov	r0, r1
 8000372:	e77b      	b.n	800026c <__udivmoddi4+0xa0>
 8000374:	e9c6 e000 	strd	lr, r0, [r6]
 8000378:	e7f9      	b.n	800036e <__udivmoddi4+0x1a2>
 800037a:	fab3 f783 	clz	r7, r3
 800037e:	b98f      	cbnz	r7, 80003a4 <__udivmoddi4+0x1d8>
 8000380:	4283      	cmp	r3, r0
 8000382:	d301      	bcc.n	8000388 <__udivmoddi4+0x1bc>
 8000384:	4572      	cmp	r2, lr
 8000386:	d808      	bhi.n	800039a <__udivmoddi4+0x1ce>
 8000388:	ebbe 0402 	subs.w	r4, lr, r2
 800038c:	eb60 0303 	sbc.w	r3, r0, r3
 8000390:	2001      	movs	r0, #1
 8000392:	469c      	mov	ip, r3
 8000394:	b91e      	cbnz	r6, 800039e <__udivmoddi4+0x1d2>
 8000396:	2100      	movs	r1, #0
 8000398:	e768      	b.n	800026c <__udivmoddi4+0xa0>
 800039a:	4638      	mov	r0, r7
 800039c:	e7fa      	b.n	8000394 <__udivmoddi4+0x1c8>
 800039e:	e9c6 4c00 	strd	r4, ip, [r6]
 80003a2:	e7f8      	b.n	8000396 <__udivmoddi4+0x1ca>
 80003a4:	f1c7 0c20 	rsb	ip, r7, #32
 80003a8:	40bb      	lsls	r3, r7
 80003aa:	fa22 f40c 	lsr.w	r4, r2, ip
 80003ae:	431c      	orrs	r4, r3
 80003b0:	fa2e f10c 	lsr.w	r1, lr, ip
 80003b4:	fa20 f30c 	lsr.w	r3, r0, ip
 80003b8:	40b8      	lsls	r0, r7
 80003ba:	4301      	orrs	r1, r0
 80003bc:	ea4f 4914 	mov.w	r9, r4, lsr #16
 80003c0:	fa0e f507 	lsl.w	r5, lr, r7
 80003c4:	fbb3 f8f9 	udiv	r8, r3, r9
 80003c8:	fa1f fe84 	uxth.w	lr, r4
 80003cc:	fb09 3018 	mls	r0, r9, r8, r3
 80003d0:	0c0b      	lsrs	r3, r1, #16
 80003d2:	fb08 fa0e 	mul.w	sl, r8, lr
 80003d6:	ea43 4300 	orr.w	r3, r3, r0, lsl #16
 80003da:	459a      	cmp	sl, r3
 80003dc:	fa02 f207 	lsl.w	r2, r2, r7
 80003e0:	d940      	bls.n	8000464 <__udivmoddi4+0x298>
 80003e2:	18e3      	adds	r3, r4, r3
 80003e4:	f108 30ff 	add.w	r0, r8, #4294967295	; 0xffffffff
 80003e8:	d204      	bcs.n	80003f4 <__udivmoddi4+0x228>
 80003ea:	459a      	cmp	sl, r3
 80003ec:	d902      	bls.n	80003f4 <__udivmoddi4+0x228>
 80003ee:	f1a8 0002 	sub.w	r0, r8, #2
 80003f2:	4423      	add	r3, r4
 80003f4:	eba3 030a 	sub.w	r3, r3, sl
 80003f8:	b289      	uxth	r1, r1
 80003fa:	fbb3 f8f9 	udiv	r8, r3, r9
 80003fe:	fb09 3318 	mls	r3, r9, r8, r3
 8000402:	fb08 fe0e 	mul.w	lr, r8, lr
 8000406:	ea41 4103 	orr.w	r1, r1, r3, lsl #16
 800040a:	458e      	cmp	lr, r1
 800040c:	d92c      	bls.n	8000468 <__udivmoddi4+0x29c>
 800040e:	1861      	adds	r1, r4, r1
 8000410:	f108 33ff 	add.w	r3, r8, #4294967295	; 0xffffffff
 8000414:	d204      	bcs.n	8000420 <__udivmoddi4+0x254>
 8000416:	458e      	cmp	lr, r1
 8000418:	d902      	bls.n	8000420 <__udivmoddi4+0x254>
 800041a:	f1a8 0302 	sub.w	r3, r8, #2
 800041e:	4421      	add	r1, r4
 8000420:	ea43 4000 	orr.w	r0, r3, r0, lsl #16
 8000424:	fba0 9802 	umull	r9, r8, r0, r2
 8000428:	eba1 010e 	sub.w	r1, r1, lr
 800042c:	4541      	cmp	r1, r8
 800042e:	46ce      	mov	lr, r9
 8000430:	4643      	mov	r3, r8
 8000432:	d302      	bcc.n	800043a <__udivmoddi4+0x26e>
 8000434:	d106      	bne.n	8000444 <__udivmoddi4+0x278>
 8000436:	454d      	cmp	r5, r9
 8000438:	d204      	bcs.n	8000444 <__udivmoddi4+0x278>
 800043a:	ebb9 0e02 	subs.w	lr, r9, r2
 800043e:	eb68 0304 	sbc.w	r3, r8, r4
 8000442:	3801      	subs	r0, #1
 8000444:	2e00      	cmp	r6, #0
 8000446:	d0a6      	beq.n	8000396 <__udivmoddi4+0x1ca>
 8000448:	ebb5 020e 	subs.w	r2, r5, lr
 800044c:	eb61 0103 	sbc.w	r1, r1, r3
 8000450:	fa01 fc0c 	lsl.w	ip, r1, ip
 8000454:	fa22 f307 	lsr.w	r3, r2, r7
 8000458:	ea4c 0303 	orr.w	r3, ip, r3
 800045c:	40f9      	lsrs	r1, r7
 800045e:	e9c6 3100 	strd	r3, r1, [r6]
 8000462:	e798      	b.n	8000396 <__udivmoddi4+0x1ca>
 8000464:	4640      	mov	r0, r8
 8000466:	e7c5      	b.n	80003f4 <__udivmoddi4+0x228>
 8000468:	4643      	mov	r3, r8
 800046a:	e7d9      	b.n	8000420 <__udivmoddi4+0x254>

0800046c <print_phil_state>:
#endif
}

#include <stdarg.h>
static void print_phil_state(int id, const char *fmt, int32_t delay)
{
 800046c:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
 8000470:	4606      	mov	r6, r0
 8000472:	460c      	mov	r4, r1
 8000474:	4615      	mov	r5, r2
	if (z_syscall_trap()) {
		return (k_tid_t) arch_syscall_invoke0(K_SYSCALL_Z_CURRENT_GET);
	}
#endif
	compiler_barrier();
	return z_impl_z_current_get();
 8000476:	f003 fda7 	bl	8003fc8 <z_impl_z_current_get>
		union { uintptr_t x; k_tid_t val; } parm0 = { .val = thread };
		return (int) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_PRIORITY_GET);
	}
#endif
	compiler_barrier();
	return z_impl_k_thread_priority_get(thread);
 800047a:	f004 ff4a 	bl	8005312 <z_impl_k_thread_priority_get>
	printk("\x1b[%d;%dH", id + 1, 1);
 800047e:	2201      	movs	r2, #1
 8000480:	4607      	mov	r7, r0
 8000482:	18b1      	adds	r1, r6, r2
 8000484:	4813      	ldr	r0, [pc, #76]	; (80004d4 <print_phil_state+0x68>)
	int prio = k_thread_priority_get(k_current_get());

	set_phil_state_pos(id);

	printk("Philosopher %d [%s:%s%d] ",
 8000486:	f8df 8050 	ldr.w	r8, [pc, #80]	; 80004d8 <print_phil_state+0x6c>
 800048a:	f8df 9050 	ldr.w	r9, [pc, #80]	; 80004dc <print_phil_state+0x70>
	printk("\x1b[%d;%dH", id + 1, 1);
 800048e:	f004 f948 	bl	8004722 <printk>
	printk("Philosopher %d [%s:%s%d] ",
 8000492:	4913      	ldr	r1, [pc, #76]	; (80004e0 <print_phil_state+0x74>)
 8000494:	4a13      	ldr	r2, [pc, #76]	; (80004e4 <print_phil_state+0x78>)
 8000496:	4814      	ldr	r0, [pc, #80]	; (80004e8 <print_phil_state+0x7c>)
 8000498:	9700      	str	r7, [sp, #0]
 800049a:	2f00      	cmp	r7, #0
 800049c:	bfba      	itte	lt
 800049e:	460a      	movlt	r2, r1
 80004a0:	4643      	movlt	r3, r8
 80004a2:	464b      	movge	r3, r9
 80004a4:	4631      	mov	r1, r6
 80004a6:	f004 f93c 	bl	8004722 <printk>
	       id, prio < 0 ? "C" : "P",
	       prio < 0 ? "" : " ",
	       prio);

	if (delay) {
 80004aa:	b175      	cbz	r5, 80004ca <print_phil_state+0x5e>
		printk(fmt, delay < 1000 ? " " : "", delay);
 80004ac:	462a      	mov	r2, r5
 80004ae:	f5b5 7f7a 	cmp.w	r5, #1000	; 0x3e8
 80004b2:	bfb4      	ite	lt
 80004b4:	4649      	movlt	r1, r9
 80004b6:	4641      	movge	r1, r8
 80004b8:	4620      	mov	r0, r4
 80004ba:	f004 f932 	bl	8004722 <printk>
	} else {
		printk(fmt, "");
	}

	printk("\n");
 80004be:	480b      	ldr	r0, [pc, #44]	; (80004ec <print_phil_state+0x80>)
}
 80004c0:	b003      	add	sp, #12
 80004c2:	e8bd 43f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, lr}
	printk("\n");
 80004c6:	f004 b92c 	b.w	8004722 <printk>
		printk(fmt, "");
 80004ca:	4641      	mov	r1, r8
 80004cc:	4620      	mov	r0, r4
 80004ce:	f004 f928 	bl	8004722 <printk>
 80004d2:	e7f4      	b.n	80004be <print_phil_state+0x52>
 80004d4:	08005a58 	.word	0x08005a58
 80004d8:	080065a4 	.word	0x080065a4
 80004dc:	08005a90 	.word	0x08005a90
 80004e0:	080062e6 	.word	0x080062e6
 80004e4:	08005a56 	.word	0x08005a56
 80004e8:	08005a61 	.word	0x08005a61
 80004ec:	080065a3 	.word	0x080065a3

080004f0 <philosopher>:
	fork_t fork2;

	int my_id = POINTER_TO_INT(id);

	/* Djkstra's solution: always pick up the lowest numbered fork first */
	if (is_last_philosopher(my_id)) {
 80004f0:	2805      	cmp	r0, #5
{
 80004f2:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
		fork1 = fork(0);
		fork2 = fork(my_id);
	} else {
		fork1 = fork(my_id);
 80004f6:	bf16      	itet	ne
 80004f8:	4b30      	ldrne	r3, [pc, #192]	; (80005bc <philosopher+0xcc>)
		fork2 = fork(my_id);
 80004fa:	4f31      	ldreq	r7, [pc, #196]	; (80005c0 <philosopher+0xd0>)
		fork1 = fork(my_id);
 80004fc:	f853 9020 	ldrne.w	r9, [r3, r0, lsl #2]
	}

	while (1) {
		int32_t delay;

		print_phil_state(my_id, "       STARVING       ", 0);
 8000500:	f8df b0c0 	ldr.w	fp, [pc, #192]	; 80005c4 <philosopher+0xd4>
		fork2 = fork(my_id + 1);
 8000504:	f100 0801 	add.w	r8, r0, #1
{
 8000508:	4604      	mov	r4, r0
		fork2 = fork(my_id + 1);
 800050a:	bf14      	ite	ne
 800050c:	f853 7028 	ldrne.w	r7, [r3, r8, lsl #2]
		fork1 = fork(0);
 8000510:	f1a7 0964 	subeq.w	r9, r7, #100	; 0x64
		print_phil_state(my_id, "       STARVING       ", 0);
 8000514:	2200      	movs	r2, #0
 8000516:	4659      	mov	r1, fp
 8000518:	4620      	mov	r0, r4
 800051a:	f7ff ffa7 	bl	800046c <print_phil_state>
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm1 = { .val = timeout };
		return (int) arch_syscall_invoke3(parm0.x, parm1.split.lo, parm1.split.hi, K_SYSCALL_K_MUTEX_LOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_lock(mutex, timeout);
 800051e:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
 8000522:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
 8000526:	4648      	mov	r0, r9
 8000528:	f002 fc7e 	bl	8002e28 <z_impl_k_mutex_lock>
		take(fork1);
		print_phil_state(my_id, "   HOLDING ONE FORK   ", 0);
 800052c:	4926      	ldr	r1, [pc, #152]	; (80005c8 <philosopher+0xd8>)
 800052e:	2200      	movs	r2, #0
 8000530:	4620      	mov	r0, r4
 8000532:	f7ff ff9b 	bl	800046c <print_phil_state>
 8000536:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
 800053a:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
 800053e:	4638      	mov	r0, r7
 8000540:	f002 fc72 	bl	8002e28 <z_impl_k_mutex_lock>
	return z_impl_k_uptime_ticks();
 8000544:	f004 feec 	bl	8005320 <z_impl_k_uptime_ticks>
	if (div_ratio) {
		t += off;
		if (result32 && (t < BIT64(32))) {
			return ((uint32_t)t) / (from_hz / to_hz);
		} else {
			return t / ((uint64_t)from_hz / to_hz);
 8000548:	2300      	movs	r3, #0
 800054a:	220a      	movs	r2, #10
 800054c:	f7ff fe24 	bl	8000198 <__aeabi_uldivmod>
	int32_t delay = (k_uptime_get_32()/100 * (id + 1)) & 0x1f;
 8000550:	f04f 0a64 	mov.w	sl, #100	; 0x64
 8000554:	fbb0 f5fa 	udiv	r5, r0, sl
 8000558:	fb08 f505 	mul.w	r5, r8, r5
	int32_t ms = (delay + 1) * period_in_ms;
 800055c:	2619      	movs	r6, #25
	int32_t delay = (k_uptime_get_32()/100 * (id + 1)) & 0x1f;
 800055e:	f005 051f 	and.w	r5, r5, #31
	int32_t ms = (delay + 1) * period_in_ms;
 8000562:	fb05 6506 	mla	r5, r5, r6, r6
		take(fork2);

		delay = get_random_delay(my_id, 25);
		print_phil_state(my_id, "  EATING  [ %s%d ms ] ", delay);
 8000566:	4919      	ldr	r1, [pc, #100]	; (80005cc <philosopher+0xdc>)
 8000568:	462a      	mov	r2, r5
 800056a:	4620      	mov	r0, r4
 800056c:	f7ff ff7e 	bl	800046c <print_phil_state>
		k_msleep(delay);
 8000570:	4628      	mov	r0, r5
 8000572:	f004 f8ba 	bl	80046ea <k_msleep.isra.0>
		union { uintptr_t x; struct k_mutex * val; } parm0 = { .val = mutex };
		return (int) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_MUTEX_UNLOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_unlock(mutex);
 8000576:	4638      	mov	r0, r7
 8000578:	f002 fd26 	bl	8002fc8 <z_impl_k_mutex_unlock>

		drop(fork2);
		print_phil_state(my_id, "   DROPPED ONE FORK   ", 0);
 800057c:	4914      	ldr	r1, [pc, #80]	; (80005d0 <philosopher+0xe0>)
 800057e:	2200      	movs	r2, #0
 8000580:	4620      	mov	r0, r4
 8000582:	f7ff ff73 	bl	800046c <print_phil_state>
 8000586:	4648      	mov	r0, r9
 8000588:	f002 fd1e 	bl	8002fc8 <z_impl_k_mutex_unlock>
	return z_impl_k_uptime_ticks();
 800058c:	f004 fec8 	bl	8005320 <z_impl_k_uptime_ticks>
 8000590:	2300      	movs	r3, #0
 8000592:	220a      	movs	r2, #10
 8000594:	f7ff fe00 	bl	8000198 <__aeabi_uldivmod>
	int32_t delay = (k_uptime_get_32()/100 * (id + 1)) & 0x1f;
 8000598:	fbb0 f0fa 	udiv	r0, r0, sl
 800059c:	fb08 f000 	mul.w	r0, r8, r0
 80005a0:	f000 001f 	and.w	r0, r0, #31
	int32_t ms = (delay + 1) * period_in_ms;
 80005a4:	fb00 6606 	mla	r6, r0, r6, r6
		drop(fork1);

		delay = get_random_delay(my_id, 25);
		print_phil_state(my_id, " THINKING [ %s%d ms ] ", delay);
 80005a8:	490a      	ldr	r1, [pc, #40]	; (80005d4 <philosopher+0xe4>)
 80005aa:	4620      	mov	r0, r4
 80005ac:	4632      	mov	r2, r6
 80005ae:	f7ff ff5d 	bl	800046c <print_phil_state>
		k_msleep(delay);
 80005b2:	4630      	mov	r0, r6
 80005b4:	f004 f899 	bl	80046ea <k_msleep.isra.0>
	while (1) {
 80005b8:	e7ac      	b.n	8000514 <philosopher+0x24>
 80005ba:	bf00      	nop
 80005bc:	08005858 	.word	0x08005858
 80005c0:	2000064c 	.word	0x2000064c
 80005c4:	08005a7b 	.word	0x08005a7b
 80005c8:	08005a92 	.word	0x08005a92
 80005cc:	08005aa9 	.word	0x08005aa9
 80005d0:	08005ac0 	.word	0x08005ac0
 80005d4:	08005ad7 	.word	0x08005ad7

080005d8 <main>:
	printk(DEMO_DESCRIPTION);
#endif
}

void main(void)
{
 80005d8:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	printk(DEMO_DESCRIPTION);
 80005dc:	4a23      	ldr	r2, [pc, #140]	; (800066c <main+0x94>)
 80005de:	4924      	ldr	r1, [pc, #144]	; (8000670 <main+0x98>)
 80005e0:	4824      	ldr	r0, [pc, #144]	; (8000674 <main+0x9c>)
 80005e2:	4d25      	ldr	r5, [pc, #148]	; (8000678 <main+0xa0>)
{
 80005e4:	b090      	sub	sp, #64	; 0x40
	printk(DEMO_DESCRIPTION);
 80005e6:	f004 f89c 	bl	8004722 <printk>
	display_demo_description();
#if CONFIG_TIMESLICING
	k_sched_time_slice_set(5000, 0);
 80005ea:	2100      	movs	r1, #0
 80005ec:	f241 3088 	movw	r0, #5000	; 0x1388
 80005f0:	f002 fdc2 	bl	8003178 <k_sched_time_slice_set>
	for (int i = 0; i < NUM_PHIL; i++) {
 80005f4:	2400      	movs	r4, #0
		fork_init(fork(i));
 80005f6:	f855 0b04 	ldr.w	r0, [r5], #4
	for (int i = 0; i < NUM_PHIL; i++) {
 80005fa:	3401      	adds	r4, #1
	return z_impl_k_mutex_init(mutex);
 80005fc:	f004 fe5a 	bl	80052b4 <z_impl_k_mutex_init>
 8000600:	2c06      	cmp	r4, #6
 8000602:	d1f8      	bne.n	80005f6 <main+0x1e>
 8000604:	4d1d      	ldr	r5, [pc, #116]	; (800067c <main+0xa4>)
 8000606:	4e1e      	ldr	r6, [pc, #120]	; (8000680 <main+0xa8>)
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
 8000608:	f8df a078 	ldr.w	sl, [pc, #120]	; 8000684 <main+0xac>
		snprintk(tname, CONFIG_THREAD_MAX_NAME_LEN, "Philosopher %d", i);
 800060c:	4f1e      	ldr	r7, [pc, #120]	; (8000688 <main+0xb0>)
	for (int i = 0; i < NUM_PHIL; i++) {
 800060e:	2400      	movs	r4, #0
 8000610:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
 8000614:	f04f 39ff 	mov.w	r9, #4294967295	; 0xffffffff
 8000618:	2304      	movs	r3, #4
 800061a:	9304      	str	r3, [sp, #16]
	return -(phil - (NUM_PHIL/2));
 800061c:	f1c4 0303 	rsb	r3, r4, #3
 8000620:	9303      	str	r3, [sp, #12]
 8000622:	2300      	movs	r3, #0
 8000624:	e9cd 3301 	strd	r3, r3, [sp, #4]
 8000628:	4631      	mov	r1, r6
 800062a:	4653      	mov	r3, sl
 800062c:	e9cd 8906 	strd	r8, r9, [sp, #24]
 8000630:	9400      	str	r4, [sp, #0]
 8000632:	f44f 6200 	mov.w	r2, #2048	; 0x800
 8000636:	4628      	mov	r0, r5
 8000638:	f002 fb1a 	bl	8002c70 <z_impl_k_thread_create>
		snprintk(tname, CONFIG_THREAD_MAX_NAME_LEN, "Philosopher %d", i);
 800063c:	2120      	movs	r1, #32
 800063e:	4623      	mov	r3, r4
 8000640:	463a      	mov	r2, r7
 8000642:	eb0d 0001 	add.w	r0, sp, r1
 8000646:	f004 f879 	bl	800473c <snprintk>
	return z_impl_k_thread_name_set(thread, str);
 800064a:	a908      	add	r1, sp, #32
 800064c:	4628      	mov	r0, r5
 800064e:	f002 f9d1 	bl	80029f4 <z_impl_k_thread_name_set>
		k_object_access_grant(fork((i + 1) % NUM_PHIL), &threads[i]);
 8000652:	3401      	adds	r4, #1
	z_impl_k_thread_start(thread);
 8000654:	4628      	mov	r0, r5
 8000656:	f004 fe23 	bl	80052a0 <z_impl_k_thread_start>
	for (int i = 0; i < NUM_PHIL; i++) {
 800065a:	2c06      	cmp	r4, #6
 800065c:	f105 05b0 	add.w	r5, r5, #176	; 0xb0
 8000660:	f506 6604 	add.w	r6, r6, #2112	; 0x840
 8000664:	d1d8      	bne.n	8000618 <main+0x40>
	/* Wait a few seconds before main() exit, giving the sample the
	 * opportunity to dump some output before coverage data gets emitted
	 */
	k_sleep(K_MSEC(5000));
#endif
}
 8000666:	b010      	add	sp, #64	; 0x40
 8000668:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 800066c:	08005aee 	.word	0x08005aee
 8000670:	08005af6 	.word	0x08005af6
 8000674:	08005afe 	.word	0x08005afe
 8000678:	08005858 	.word	0x08005858
 800067c:	20000060 	.word	0x20000060
 8000680:	20000840 	.word	0x20000840
 8000684:	080004f1 	.word	0x080004f1
 8000688:	08005c46 	.word	0x08005c46

0800068c <char_out>:
}

static int char_out(int c, void *ctx_p)
{
	(void) ctx_p;
	return _char_out(c);
 800068c:	4b01      	ldr	r3, [pc, #4]	; (8000694 <char_out+0x8>)
 800068e:	681b      	ldr	r3, [r3, #0]
 8000690:	4718      	bx	r3
 8000692:	bf00      	nop
 8000694:	20000000 	.word	0x20000000

08000698 <__printk_hook_install>:
	_char_out = fn;
 8000698:	4b01      	ldr	r3, [pc, #4]	; (80006a0 <__printk_hook_install+0x8>)
 800069a:	6018      	str	r0, [r3, #0]
}
 800069c:	4770      	bx	lr
 800069e:	bf00      	nop
 80006a0:	20000000 	.word	0x20000000

080006a4 <vprintk>:
}

void vprintk(const char *fmt, va_list ap)
{
 80006a4:	b507      	push	{r0, r1, r2, lr}
 80006a6:	460b      	mov	r3, r1
int cbvprintf(cbprintf_cb out, void *ctx, const char *format, va_list ap);
#else
static inline
int cbvprintf(cbprintf_cb out, void *ctx, const char *format, va_list ap)
{
	return z_cbvprintf_impl(out, ctx, format, ap, 0);
 80006a8:	2100      	movs	r1, #0
 80006aa:	4602      	mov	r2, r0
 80006ac:	9100      	str	r1, [sp, #0]
 80006ae:	4803      	ldr	r0, [pc, #12]	; (80006bc <vprintk+0x18>)
 80006b0:	f000 f9d8 	bl	8000a64 <z_cbvprintf_impl>

#ifdef CONFIG_PRINTK_SYNC
		k_spin_unlock(&lock, key);
#endif
	}
}
 80006b4:	b003      	add	sp, #12
 80006b6:	f85d fb04 	ldr.w	pc, [sp], #4
 80006ba:	bf00      	nop
 80006bc:	0800068d 	.word	0x0800068d

080006c0 <vsnprintk>:

	return ret;
}

int vsnprintk(char *str, size_t size, const char *fmt, va_list ap)
{
 80006c0:	b530      	push	{r4, r5, lr}
 80006c2:	b087      	sub	sp, #28
	struct str_context ctx = { str, size, 0 };
 80006c4:	2500      	movs	r5, #0
 80006c6:	e9cd 0103 	strd	r0, r1, [sp, #12]
{
 80006ca:	4604      	mov	r4, r0
 80006cc:	9500      	str	r5, [sp, #0]
 80006ce:	a903      	add	r1, sp, #12
 80006d0:	4805      	ldr	r0, [pc, #20]	; (80006e8 <vsnprintk+0x28>)
	struct str_context ctx = { str, size, 0 };
 80006d2:	9505      	str	r5, [sp, #20]
 80006d4:	f000 f9c6 	bl	8000a64 <z_cbvprintf_impl>

	cbvprintf(str_out, &ctx, fmt, ap);

	if (ctx.count < ctx.max) {
 80006d8:	e9dd 3004 	ldrd	r3, r0, [sp, #16]
 80006dc:	4298      	cmp	r0, r3
		str[ctx.count] = '\0';
 80006de:	bfb8      	it	lt
 80006e0:	5425      	strblt	r5, [r4, r0]
	}

	return ctx.count;
}
 80006e2:	b007      	add	sp, #28
 80006e4:	bd30      	pop	{r4, r5, pc}
 80006e6:	bf00      	nop
 80006e8:	080046fd 	.word	0x080046fd

080006ec <rb_remove>:
		return;
	}
}

void rb_remove(struct rbtree *tree, struct rbnode *node)
{
 80006ec:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
 80006f0:	b087      	sub	sp, #28
	struct rbnode *tmp;
#ifdef CONFIG_MISRA_SANE
	struct rbnode **stack = &tree->iter_stack[0];
#else
	struct rbnode *stack[tree->max_depth + 1];
 80006f2:	6883      	ldr	r3, [r0, #8]
 80006f4:	009b      	lsls	r3, r3, #2
{
 80006f6:	af00      	add	r7, sp, #0
	struct rbnode *stack[tree->max_depth + 1];
 80006f8:	330b      	adds	r3, #11
 80006fa:	f023 0307 	bic.w	r3, r3, #7
{
 80006fe:	f8c7 d00c 	str.w	sp, [r7, #12]
	struct rbnode *stack[tree->max_depth + 1];
 8000702:	ebad 0d03 	sub.w	sp, sp, r3
 8000706:	46e9      	mov	r9, sp
 8000708:	466b      	mov	r3, sp
 800070a:	089b      	lsrs	r3, r3, #2
#endif

	int stacksz = find_and_stack(tree, node, stack);
 800070c:	464a      	mov	r2, r9
{
 800070e:	460e      	mov	r6, r1
	struct rbnode *stack[tree->max_depth + 1];
 8000710:	613b      	str	r3, [r7, #16]
{
 8000712:	4683      	mov	fp, r0
	int stacksz = find_and_stack(tree, node, stack);
 8000714:	f004 f81f 	bl	8004756 <find_and_stack>
 8000718:	eb09 0880 	add.w	r8, r9, r0, lsl #2
 800071c:	4604      	mov	r4, r0

	if (node != stack[stacksz - 1]) {
 800071e:	f858 2c04 	ldr.w	r2, [r8, #-4]
 8000722:	42b2      	cmp	r2, r6
 8000724:	ea4f 0380 	mov.w	r3, r0, lsl #2
 8000728:	d15d      	bne.n	80007e6 <rb_remove+0xfa>
	uintptr_t l = (uintptr_t) n->children[0];
 800072a:	6835      	ldr	r5, [r6, #0]
	/* We can only remove a node with zero or one child, if we
	 * have two then pick the "biggest" child of side 0 (smallest
	 * of 1 would work too) and swap our spot in the tree with
	 * that one
	 */
	if ((get_child(node, 0U) != NULL) && (get_child(node, 1U) != NULL)) {
 800072c:	2d01      	cmp	r5, #1
 800072e:	d94d      	bls.n	80007cc <rb_remove+0xe0>
 8000730:	6872      	ldr	r2, [r6, #4]
 8000732:	2a00      	cmp	r2, #0
 8000734:	d04a      	beq.n	80007cc <rb_remove+0xe0>
		int stacksz0 = stacksz;
		struct rbnode *hiparent, *loparent;
		struct rbnode *node2 = get_child(node, 0U);

		hiparent = (stacksz > 1) ? stack[stacksz - 2] : NULL;
		stack[stacksz++] = node2;
 8000736:	693a      	ldr	r2, [r7, #16]
		hiparent = (stacksz > 1) ? stack[stacksz - 2] : NULL;
 8000738:	2801      	cmp	r0, #1
	l &= ~1UL;
 800073a:	f025 0501 	bic.w	r5, r5, #1
		hiparent = (stacksz > 1) ? stack[stacksz - 2] : NULL;
 800073e:	bfc8      	it	gt
 8000740:	f858 0c08 	ldrgt.w	r0, [r8, #-8]
		stack[stacksz++] = node2;
 8000744:	f843 5022 	str.w	r5, [r3, r2, lsl #2]
		hiparent = (stacksz > 1) ? stack[stacksz - 2] : NULL;
 8000748:	bfd8      	it	le
 800074a:	2000      	movle	r0, #0
		stack[stacksz++] = node2;
 800074c:	3401      	adds	r4, #1
		return n->children[1];
 800074e:	686b      	ldr	r3, [r5, #4]
		while (get_child(node2, 1U) != NULL) {
 8000750:	2b00      	cmp	r3, #0
 8000752:	d14e      	bne.n	80007f2 <rb_remove+0x106>
			node2 = get_child(node2, 1U);
			stack[stacksz++] = node2;
		}

		loparent = stack[stacksz - 2];
 8000754:	eb09 0a84 	add.w	sl, r9, r4, lsl #2
 8000758:	f85a 3c08 	ldr.w	r3, [sl, #-8]
		 * upper node.  Remember to swap the color bits of the
		 * two nodes also.  And of course we don't have parent
		 * pointers, so the stack tracking this structure
		 * needs to be swapped too!
		 */
		if (hiparent != NULL) {
 800075c:	2800      	cmp	r0, #0
 800075e:	d04d      	beq.n	80007fc <rb_remove+0x110>
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8000760:	6841      	ldr	r1, [r0, #4]
 8000762:	617b      	str	r3, [r7, #20]
			set_child(hiparent, get_side(hiparent, node), node2);
 8000764:	eba1 0c06 	sub.w	ip, r1, r6
 8000768:	f1dc 0100 	rsbs	r1, ip, #0
 800076c:	462a      	mov	r2, r5
 800076e:	eb41 010c 	adc.w	r1, r1, ip
 8000772:	f004 f82b 	bl	80047cc <set_child>
 8000776:	697b      	ldr	r3, [r7, #20]
		} else {
			tree->root = node2;
		}

		if (loparent == node) {
 8000778:	429e      	cmp	r6, r3
 800077a:	d142      	bne.n	8000802 <rb_remove+0x116>
	uintptr_t l = (uintptr_t) n->children[0];
 800077c:	682a      	ldr	r2, [r5, #0]
		n->children[0] = (void *) (new | (old & 1UL));
 800077e:	6833      	ldr	r3, [r6, #0]
	l &= ~1UL;
 8000780:	f022 0201 	bic.w	r2, r2, #1
		n->children[0] = (void *) (new | (old & 1UL));
 8000784:	f003 0301 	and.w	r3, r3, #1
 8000788:	4313      	orrs	r3, r2
 800078a:	6033      	str	r3, [r6, #0]
 800078c:	682b      	ldr	r3, [r5, #0]
 800078e:	f003 0301 	and.w	r3, r3, #1
 8000792:	4333      	orrs	r3, r6
 8000794:	602b      	str	r3, [r5, #0]
		return n->children[1];
 8000796:	6873      	ldr	r3, [r6, #4]
		n->children[1] = val;
 8000798:	606b      	str	r3, [r5, #4]
 800079a:	2300      	movs	r3, #0
 800079c:	6073      	str	r3, [r6, #4]

		set_child(node2, 1U, get_child(node, 1U));
		set_child(node, 1U, NULL);

		tmp = stack[stacksz0 - 1];
		stack[stacksz0 - 1] = stack[stacksz - 1];
 800079e:	f85a 2c04 	ldr.w	r2, [sl, #-4]
		tmp = stack[stacksz0 - 1];
 80007a2:	f858 3c04 	ldr.w	r3, [r8, #-4]
		stack[stacksz0 - 1] = stack[stacksz - 1];
 80007a6:	f848 2c04 	str.w	r2, [r8, #-4]
	return ((uintptr_t)n->children[0]) & 1UL;
 80007aa:	6832      	ldr	r2, [r6, #0]
		stack[stacksz - 1] = tmp;
 80007ac:	f84a 3c04 	str.w	r3, [sl, #-4]
	return ((uintptr_t)n->children[0]) & 1UL;
 80007b0:	682b      	ldr	r3, [r5, #0]
	*p = (*p & ~1UL) | (uint8_t)color;
 80007b2:	f022 0101 	bic.w	r1, r2, #1
 80007b6:	f003 0301 	and.w	r3, r3, #1
 80007ba:	430b      	orrs	r3, r1
 80007bc:	6033      	str	r3, [r6, #0]
 80007be:	682b      	ldr	r3, [r5, #0]
 80007c0:	f002 0201 	and.w	r2, r2, #1
 80007c4:	f023 0301 	bic.w	r3, r3, #1
 80007c8:	4313      	orrs	r3, r2
 80007ca:	602b      	str	r3, [r5, #0]
	uintptr_t l = (uintptr_t) n->children[0];
 80007cc:	6832      	ldr	r2, [r6, #0]
	CHECK((get_child(node, 0U) == NULL) ||
	      (get_child(node, 1U) == NULL));

	struct rbnode *child = get_child(node, 0U);

	if (child == NULL) {
 80007ce:	2a01      	cmp	r2, #1
 80007d0:	d92e      	bls.n	8000830 <rb_remove+0x144>
		child = get_child(node, 1U);
	}

	/* Removing the root */
	if (stacksz < 2) {
 80007d2:	2c01      	cmp	r4, #1
	l &= ~1UL;
 80007d4:	f022 0501 	bic.w	r5, r2, #1
	if (stacksz < 2) {
 80007d8:	dc34      	bgt.n	8000844 <rb_remove+0x158>
		tree->root = child;
 80007da:	f8cb 5000 	str.w	r5, [fp]
	*p = (*p & ~1UL) | (uint8_t)color;
 80007de:	682b      	ldr	r3, [r5, #0]
 80007e0:	f043 0301 	orr.w	r3, r3, #1
 80007e4:	602b      	str	r3, [r5, #0]
		return;
 80007e6:	f8d7 d00c 	ldr.w	sp, [r7, #12]
		}
	}

	/* We may have rotated up into the root! */
	tree->root = stack[0];
}
 80007ea:	371c      	adds	r7, #28
 80007ec:	46bd      	mov	sp, r7
 80007ee:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			stack[stacksz++] = node2;
 80007f2:	f849 3024 	str.w	r3, [r9, r4, lsl #2]
 80007f6:	461d      	mov	r5, r3
 80007f8:	3401      	adds	r4, #1
 80007fa:	e7a8      	b.n	800074e <rb_remove+0x62>
			tree->root = node2;
 80007fc:	f8cb 5000 	str.w	r5, [fp]
 8000800:	e7ba      	b.n	8000778 <rb_remove+0x8c>
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8000802:	6859      	ldr	r1, [r3, #4]
			set_child(loparent, get_side(loparent, node2), node);
 8000804:	1b48      	subs	r0, r1, r5
 8000806:	4241      	negs	r1, r0
 8000808:	4141      	adcs	r1, r0
 800080a:	4632      	mov	r2, r6
 800080c:	4618      	mov	r0, r3
 800080e:	f003 ffdd 	bl	80047cc <set_child>
	uintptr_t l = (uintptr_t) n->children[0];
 8000812:	6832      	ldr	r2, [r6, #0]
 8000814:	682b      	ldr	r3, [r5, #0]
		n->children[0] = (void *) (new | (old & 1UL));
 8000816:	f002 0101 	and.w	r1, r2, #1
	l &= ~1UL;
 800081a:	f023 0301 	bic.w	r3, r3, #1
		n->children[0] = (void *) (new | (old & 1UL));
 800081e:	430b      	orrs	r3, r1
 8000820:	6033      	str	r3, [r6, #0]
 8000822:	682b      	ldr	r3, [r5, #0]
	l &= ~1UL;
 8000824:	f022 0201 	bic.w	r2, r2, #1
		n->children[0] = (void *) (new | (old & 1UL));
 8000828:	f003 0301 	and.w	r3, r3, #1
 800082c:	4313      	orrs	r3, r2
 800082e:	e7b1      	b.n	8000794 <rb_remove+0xa8>
	if (stacksz < 2) {
 8000830:	2c01      	cmp	r4, #1
		return n->children[1];
 8000832:	6875      	ldr	r5, [r6, #4]
	if (stacksz < 2) {
 8000834:	dc28      	bgt.n	8000888 <rb_remove+0x19c>
		tree->root = child;
 8000836:	f8cb 5000 	str.w	r5, [fp]
		if (child != NULL) {
 800083a:	2d00      	cmp	r5, #0
 800083c:	d1cf      	bne.n	80007de <rb_remove+0xf2>
			tree->max_depth = 0;
 800083e:	f8cb 5008 	str.w	r5, [fp, #8]
 8000842:	e7d0      	b.n	80007e6 <rb_remove+0xfa>
	struct rbnode *parent = stack[stacksz - 2];
 8000844:	3c02      	subs	r4, #2
 8000846:	f859 0024 	ldr.w	r0, [r9, r4, lsl #2]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 800084a:	6841      	ldr	r1, [r0, #4]
		set_child(parent, get_side(parent, node), child);
 800084c:	1b8c      	subs	r4, r1, r6
 800084e:	4261      	negs	r1, r4
 8000850:	462a      	mov	r2, r5
 8000852:	4161      	adcs	r1, r4
 8000854:	f003 ffba 	bl	80047cc <set_child>
	return ((uintptr_t)n->children[0]) & 1UL;
 8000858:	6832      	ldr	r2, [r6, #0]
 800085a:	682b      	ldr	r3, [r5, #0]
		__ASSERT(is_black(node) || is_black(child), "both nodes red?!");
 800085c:	f012 0f01 	tst.w	r2, #1
 8000860:	f040 80f2 	bne.w	8000a48 <rb_remove+0x35c>
 8000864:	07d8      	lsls	r0, r3, #31
 8000866:	f100 80ed 	bmi.w	8000a44 <rb_remove+0x358>
 800086a:	497a      	ldr	r1, [pc, #488]	; (8000a54 <rb_remove+0x368>)
 800086c:	4a7a      	ldr	r2, [pc, #488]	; (8000a58 <rb_remove+0x36c>)
 800086e:	487b      	ldr	r0, [pc, #492]	; (8000a5c <rb_remove+0x370>)
 8000870:	f44f 73f3 	mov.w	r3, #486	; 0x1e6
 8000874:	f004 f947 	bl	8004b06 <assert_print>
 8000878:	4879      	ldr	r0, [pc, #484]	; (8000a60 <rb_remove+0x374>)
 800087a:	f004 f944 	bl	8004b06 <assert_print>
 800087e:	4876      	ldr	r0, [pc, #472]	; (8000a58 <rb_remove+0x36c>)
 8000880:	f44f 71f3 	mov.w	r1, #486	; 0x1e6
 8000884:	f004 f938 	bl	8004af8 <assert_post_action>
	struct rbnode *parent = stack[stacksz - 2];
 8000888:	1ea3      	subs	r3, r4, #2
 800088a:	f859 0023 	ldr.w	r0, [r9, r3, lsl #2]
	if (child == NULL) {
 800088e:	2d00      	cmp	r5, #0
 8000890:	d1db      	bne.n	800084a <rb_remove+0x15e>
		if (is_black(node)) {
 8000892:	f012 0201 	ands.w	r2, r2, #1
 8000896:	f000 80d0 	beq.w	8000a3a <rb_remove+0x34e>
		struct rbnode *n = stack[stacksz - 1];
 800089a:	f104 4380 	add.w	r3, r4, #1073741824	; 0x40000000
 800089e:	3b01      	subs	r3, #1
 80008a0:	eb09 0283 	add.w	r2, r9, r3, lsl #2
 80008a4:	f859 1023 	ldr.w	r1, [r9, r3, lsl #2]
		struct rbnode *parent = stack[stacksz - 2];
 80008a8:	f852 ac04 	ldr.w	sl, [r2, #-4]
		struct rbnode *n = stack[stacksz - 1];
 80008ac:	6179      	str	r1, [r7, #20]
		return n->children[1];
 80008ae:	f8da 5004 	ldr.w	r5, [sl, #4]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 80008b2:	42a9      	cmp	r1, r5
	uintptr_t l = (uintptr_t) n->children[0];
 80008b4:	bf02      	ittt	eq
 80008b6:	f8da 5000 	ldreq.w	r5, [sl]
	l &= ~1UL;
 80008ba:	f025 0501 	biceq.w	r5, r5, #1
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 80008be:	f04f 0801 	moveq.w	r8, #1
	return get_color(n) == BLACK;
 80008c2:	6829      	ldr	r1, [r5, #0]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 80008c4:	bf18      	it	ne
 80008c6:	f04f 0800 	movne.w	r8, #0
		if (!is_black(sib)) {
 80008ca:	07c9      	lsls	r1, r1, #31
 80008cc:	d41f      	bmi.n	800090e <rb_remove+0x222>
			rotate(stack, stacksz);
 80008ce:	4621      	mov	r1, r4
			stack[stacksz - 1] = sib;
 80008d0:	f849 5023 	str.w	r5, [r9, r3, lsl #2]
			rotate(stack, stacksz);
 80008d4:	4648      	mov	r0, r9
 80008d6:	607a      	str	r2, [r7, #4]
			stack[stacksz - 1] = sib;
 80008d8:	60bb      	str	r3, [r7, #8]
			rotate(stack, stacksz);
 80008da:	f003 ff80 	bl	80047de <rotate>
	*p = (*p & ~1UL) | (uint8_t)color;
 80008de:	f8da 1000 	ldr.w	r1, [sl]
			stack[stacksz++] = n;
 80008e2:	687a      	ldr	r2, [r7, #4]
 80008e4:	697b      	ldr	r3, [r7, #20]
 80008e6:	6053      	str	r3, [r2, #4]
	*p = (*p & ~1UL) | (uint8_t)color;
 80008e8:	f021 0101 	bic.w	r1, r1, #1
 80008ec:	f8ca 1000 	str.w	r1, [sl]
 80008f0:	6829      	ldr	r1, [r5, #0]
			parent = stack[stacksz - 2];
 80008f2:	68bb      	ldr	r3, [r7, #8]
	*p = (*p & ~1UL) | (uint8_t)color;
 80008f4:	f041 0101 	orr.w	r1, r1, #1
			parent = stack[stacksz - 2];
 80008f8:	f859 a023 	ldr.w	sl, [r9, r3, lsl #2]
	*p = (*p & ~1UL) | (uint8_t)color;
 80008fc:	6029      	str	r1, [r5, #0]
			stack[stacksz++] = n;
 80008fe:	3401      	adds	r4, #1
			sib = get_child(parent, (n_side == 0U) ? 1U : 0U);
 8000900:	f1b8 0f00 	cmp.w	r8, #0
 8000904:	d028      	beq.n	8000958 <rb_remove+0x26c>
	uintptr_t l = (uintptr_t) n->children[0];
 8000906:	f8da 5000 	ldr.w	r5, [sl]
	l &= ~1UL;
 800090a:	f025 0501 	bic.w	r5, r5, #1
	uintptr_t l = (uintptr_t) n->children[0];
 800090e:	6828      	ldr	r0, [r5, #0]
		return n->children[1];
 8000910:	686b      	ldr	r3, [r5, #4]
		if (((c0 == NULL) || is_black(c0)) && ((c1 == NULL) ||
 8000912:	2801      	cmp	r0, #1
	l &= ~1UL;
 8000914:	f020 0101 	bic.w	r1, r0, #1
		if (((c0 == NULL) || is_black(c0)) && ((c1 == NULL) ||
 8000918:	d902      	bls.n	8000920 <rb_remove+0x234>
	return get_color(n) == BLACK;
 800091a:	680a      	ldr	r2, [r1, #0]
		if (((c0 == NULL) || is_black(c0)) && ((c1 == NULL) ||
 800091c:	07d2      	lsls	r2, r2, #31
 800091e:	d550      	bpl.n	80009c2 <rb_remove+0x2d6>
 8000920:	b113      	cbz	r3, 8000928 <rb_remove+0x23c>
	return get_color(n) == BLACK;
 8000922:	681a      	ldr	r2, [r3, #0]
		if (((c0 == NULL) || is_black(c0)) && ((c1 == NULL) ||
 8000924:	07d2      	lsls	r2, r2, #31
 8000926:	d51f      	bpl.n	8000968 <rb_remove+0x27c>
			if (n == null_node) {
 8000928:	697b      	ldr	r3, [r7, #20]
 800092a:	429e      	cmp	r6, r3
 800092c:	d104      	bne.n	8000938 <rb_remove+0x24c>
				set_child(parent, n_side, NULL);
 800092e:	2200      	movs	r2, #0
 8000930:	4641      	mov	r1, r8
 8000932:	4650      	mov	r0, sl
 8000934:	f003 ff4a 	bl	80047cc <set_child>
	*p = (*p & ~1UL) | (uint8_t)color;
 8000938:	682b      	ldr	r3, [r5, #0]
 800093a:	f023 0301 	bic.w	r3, r3, #1
 800093e:	602b      	str	r3, [r5, #0]
	return ((uintptr_t)n->children[0]) & 1UL;
 8000940:	f8da 3000 	ldr.w	r3, [sl]
			if (is_black(parent)) {
 8000944:	07d9      	lsls	r1, r3, #31
 8000946:	d50a      	bpl.n	800095e <rb_remove+0x272>
				stacksz--;
 8000948:	3c01      	subs	r4, #1
	while (stacksz > 1) {
 800094a:	2c01      	cmp	r4, #1
 800094c:	d1a5      	bne.n	800089a <rb_remove+0x1ae>
	tree->root = stack[0];
 800094e:	f8d9 3000 	ldr.w	r3, [r9]
 8000952:	f8cb 3000 	str.w	r3, [fp]
 8000956:	e746      	b.n	80007e6 <rb_remove+0xfa>
		return n->children[1];
 8000958:	f8da 5004 	ldr.w	r5, [sl, #4]
 800095c:	e7d7      	b.n	800090e <rb_remove+0x222>
	*p = (*p & ~1UL) | (uint8_t)color;
 800095e:	f043 0301 	orr.w	r3, r3, #1
 8000962:	f8ca 3000 	str.w	r3, [sl]
				return;
 8000966:	e7f2      	b.n	800094e <rb_remove+0x262>
		outer = get_child(sib, (n_side == 0U) ? 1U : 0U);
 8000968:	f1b8 0f00 	cmp.w	r8, #0
 800096c:	d057      	beq.n	8000a1e <rb_remove+0x332>
		if (!((outer != NULL) && is_red(outer))) {
 800096e:	2801      	cmp	r0, #1
 8000970:	d82a      	bhi.n	80009c8 <rb_remove+0x2dc>
			stack[stacksz - 1] = sib;
 8000972:	f104 4180 	add.w	r1, r4, #1073741824	; 0x40000000
 8000976:	3901      	subs	r1, #1
 8000978:	008a      	lsls	r2, r1, #2
 800097a:	6938      	ldr	r0, [r7, #16]
 800097c:	607a      	str	r2, [r7, #4]
 800097e:	eb09 0181 	add.w	r1, r9, r1, lsl #2
 8000982:	f842 5020 	str.w	r5, [r2, r0, lsl #2]
			stack[stacksz++] = inner;
 8000986:	604b      	str	r3, [r1, #4]
			rotate(stack, stacksz);
 8000988:	4648      	mov	r0, r9
 800098a:	1c61      	adds	r1, r4, #1
			stack[stacksz++] = inner;
 800098c:	60bb      	str	r3, [r7, #8]
			rotate(stack, stacksz);
 800098e:	f003 ff26 	bl	80047de <rotate>
	*p = (*p & ~1UL) | (uint8_t)color;
 8000992:	6829      	ldr	r1, [r5, #0]
 8000994:	68bb      	ldr	r3, [r7, #8]
			sib = stack[stacksz - 2];
 8000996:	687a      	ldr	r2, [r7, #4]
	*p = (*p & ~1UL) | (uint8_t)color;
 8000998:	f021 0101 	bic.w	r1, r1, #1
 800099c:	6029      	str	r1, [r5, #0]
 800099e:	6819      	ldr	r1, [r3, #0]
 80009a0:	f041 0101 	orr.w	r1, r1, #1
 80009a4:	6019      	str	r1, [r3, #0]
			sib = stack[stacksz - 2];
 80009a6:	693b      	ldr	r3, [r7, #16]
 80009a8:	f852 5023 	ldr.w	r5, [r2, r3, lsl #2]
			outer = get_child(sib, (n_side == 0U) ? 1U : 0U);
 80009ac:	f1b8 0f00 	cmp.w	r8, #0
 80009b0:	d03d      	beq.n	8000a2e <rb_remove+0x342>
	uintptr_t l = (uintptr_t) n->children[0];
 80009b2:	6829      	ldr	r1, [r5, #0]
	l &= ~1UL;
 80009b4:	f021 0101 	bic.w	r1, r1, #1
			stack[stacksz - 2] = n;
 80009b8:	e9d7 3004 	ldrd	r3, r0, [r7, #16]
 80009bc:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
			stacksz--;
 80009c0:	e007      	b.n	80009d2 <rb_remove+0x2e6>
		outer = get_child(sib, (n_side == 0U) ? 1U : 0U);
 80009c2:	f1b8 0f00 	cmp.w	r8, #0
 80009c6:	d029      	beq.n	8000a1c <rb_remove+0x330>
	return ((uintptr_t)n->children[0]) & 1UL;
 80009c8:	680a      	ldr	r2, [r1, #0]
		if (!((outer != NULL) && is_red(outer))) {
 80009ca:	07d2      	lsls	r2, r2, #31
 80009cc:	f04f 0801 	mov.w	r8, #1
 80009d0:	d4cf      	bmi.n	8000972 <rb_remove+0x286>
	*p = (*p & ~1UL) | (uint8_t)color;
 80009d2:	682b      	ldr	r3, [r5, #0]
	return ((uintptr_t)n->children[0]) & 1UL;
 80009d4:	f8da 2000 	ldr.w	r2, [sl]
	*p = (*p & ~1UL) | (uint8_t)color;
 80009d8:	f023 0301 	bic.w	r3, r3, #1
 80009dc:	f002 0201 	and.w	r2, r2, #1
 80009e0:	4313      	orrs	r3, r2
 80009e2:	602b      	str	r3, [r5, #0]
 80009e4:	f8da 3000 	ldr.w	r3, [sl]
 80009e8:	f043 0301 	orr.w	r3, r3, #1
 80009ec:	f8ca 3000 	str.w	r3, [sl]
 80009f0:	680b      	ldr	r3, [r1, #0]
 80009f2:	f043 0301 	orr.w	r3, r3, #1
 80009f6:	600b      	str	r3, [r1, #0]
		stack[stacksz - 1] = sib;
 80009f8:	f104 4380 	add.w	r3, r4, #1073741824	; 0x40000000
 80009fc:	3b01      	subs	r3, #1
		rotate(stack, stacksz);
 80009fe:	4621      	mov	r1, r4
		stack[stacksz - 1] = sib;
 8000a00:	f849 5023 	str.w	r5, [r9, r3, lsl #2]
		rotate(stack, stacksz);
 8000a04:	4648      	mov	r0, r9
 8000a06:	f003 feea 	bl	80047de <rotate>
		if (n == null_node) {
 8000a0a:	697b      	ldr	r3, [r7, #20]
 8000a0c:	429e      	cmp	r6, r3
 8000a0e:	d19e      	bne.n	800094e <rb_remove+0x262>
			set_child(parent, n_side, NULL);
 8000a10:	2200      	movs	r2, #0
 8000a12:	4641      	mov	r1, r8
 8000a14:	4650      	mov	r0, sl
			set_child(parent, get_side(parent, node), NULL);
 8000a16:	f003 fed9 	bl	80047cc <set_child>
 8000a1a:	e798      	b.n	800094e <rb_remove+0x262>
		if (!((outer != NULL) && is_red(outer))) {
 8000a1c:	b12b      	cbz	r3, 8000a2a <rb_remove+0x33e>
	return ((uintptr_t)n->children[0]) & 1UL;
 8000a1e:	681a      	ldr	r2, [r3, #0]
	return get_color(n) == RED;
 8000a20:	ea6f 0802 	mvn.w	r8, r2
		if (!((outer != NULL) && is_red(outer))) {
 8000a24:	f018 0801 	ands.w	r8, r8, #1
 8000a28:	d103      	bne.n	8000a32 <rb_remove+0x346>
	return (struct rbnode *) l;
 8000a2a:	460b      	mov	r3, r1
 8000a2c:	e7a1      	b.n	8000972 <rb_remove+0x286>
		return n->children[1];
 8000a2e:	6869      	ldr	r1, [r5, #4]
 8000a30:	e7c2      	b.n	80009b8 <rb_remove+0x2cc>
		if (!((outer != NULL) && is_red(outer))) {
 8000a32:	4619      	mov	r1, r3
 8000a34:	f04f 0800 	mov.w	r8, #0
 8000a38:	e7cb      	b.n	80009d2 <rb_remove+0x2e6>
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8000a3a:	6841      	ldr	r1, [r0, #4]
			set_child(parent, get_side(parent, node), NULL);
 8000a3c:	1b8d      	subs	r5, r1, r6
 8000a3e:	4269      	negs	r1, r5
 8000a40:	4169      	adcs	r1, r5
 8000a42:	e7e8      	b.n	8000a16 <rb_remove+0x32a>
		if (is_red(node) || is_red(child)) {
 8000a44:	07d1      	lsls	r1, r2, #31
 8000a46:	d501      	bpl.n	8000a4c <rb_remove+0x360>
 8000a48:	07da      	lsls	r2, r3, #31
 8000a4a:	d480      	bmi.n	800094e <rb_remove+0x262>
	*p = (*p & ~1UL) | (uint8_t)color;
 8000a4c:	f043 0301 	orr.w	r3, r3, #1
 8000a50:	602b      	str	r3, [r5, #0]
}
 8000a52:	e77c      	b.n	800094e <rb_remove+0x262>
 8000a54:	08005c85 	.word	0x08005c85
 8000a58:	08005c66 	.word	0x08005c66
 8000a5c:	08005ca7 	.word	0x08005ca7
 8000a60:	08005cc4 	.word	0x08005cc4

08000a64 <z_cbvprintf_impl>:
	return (int)count;
}

int z_cbvprintf_impl(cbprintf_cb out, void *ctx, const char *fp,
		     va_list ap, uint32_t flags)
{
 8000a64:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
 8000a68:	4681      	mov	r9, r0
 8000a6a:	b095      	sub	sp, #84	; 0x54
 8000a6c:	468b      	mov	fp, r1
 8000a6e:	4617      	mov	r7, r2
 8000a70:	461c      	mov	r4, r3
	char buf[CONVERTED_BUFLEN];
	size_t count = 0;
 8000a72:	2500      	movs	r5, #0
		return rc; \
	} \
	count += rc; \
} while (false)

	while (*fp != 0) {
 8000a74:	7838      	ldrb	r0, [r7, #0]
 8000a76:	b908      	cbnz	r0, 8000a7c <z_cbvprintf_impl+0x18>
			OUTC(' ');
			--width;
		}
	}

	return count;
 8000a78:	4628      	mov	r0, r5
 8000a7a:	e358      	b.n	800112e <z_cbvprintf_impl+0x6ca>
			OUTC(*fp++);
 8000a7c:	1c7b      	adds	r3, r7, #1
		if (*fp != '%') {
 8000a7e:	2825      	cmp	r0, #37	; 0x25
			OUTC(*fp++);
 8000a80:	9303      	str	r3, [sp, #12]
		if (*fp != '%') {
 8000a82:	d006      	beq.n	8000a92 <z_cbvprintf_impl+0x2e>
			OUTC('%');
 8000a84:	4659      	mov	r1, fp
 8000a86:	47c8      	blx	r9
 8000a88:	2800      	cmp	r0, #0
 8000a8a:	f2c0 8350 	blt.w	800112e <z_cbvprintf_impl+0x6ca>
 8000a8e:	3501      	adds	r5, #1
		if (bps == NULL) {
 8000a90:	e1fb      	b.n	8000e8a <z_cbvprintf_impl+0x426>
		} state = {
 8000a92:	2218      	movs	r2, #24
 8000a94:	2100      	movs	r1, #0
 8000a96:	a80e      	add	r0, sp, #56	; 0x38
 8000a98:	f004 f885 	bl	8004ba6 <memset>
	if (*sp == '%') {
 8000a9c:	787b      	ldrb	r3, [r7, #1]
 8000a9e:	2b25      	cmp	r3, #37	; 0x25
 8000aa0:	d07d      	beq.n	8000b9e <z_cbvprintf_impl+0x13a>
 8000aa2:	2300      	movs	r3, #0
 8000aa4:	1c78      	adds	r0, r7, #1
 8000aa6:	4698      	mov	r8, r3
 8000aa8:	469e      	mov	lr, r3
 8000aaa:	469c      	mov	ip, r3
 8000aac:	461e      	mov	r6, r3
 8000aae:	4601      	mov	r1, r0
		switch (*sp) {
 8000ab0:	f810 2b01 	ldrb.w	r2, [r0], #1
 8000ab4:	2a2b      	cmp	r2, #43	; 0x2b
 8000ab6:	f000 80a1 	beq.w	8000bfc <z_cbvprintf_impl+0x198>
 8000aba:	f200 8098 	bhi.w	8000bee <z_cbvprintf_impl+0x18a>
 8000abe:	2a20      	cmp	r2, #32
 8000ac0:	f000 809f 	beq.w	8000c02 <z_cbvprintf_impl+0x19e>
 8000ac4:	2a23      	cmp	r2, #35	; 0x23
 8000ac6:	f000 809f 	beq.w	8000c08 <z_cbvprintf_impl+0x1a4>
 8000aca:	b12b      	cbz	r3, 8000ad8 <z_cbvprintf_impl+0x74>
 8000acc:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000ad0:	f043 0340 	orr.w	r3, r3, #64	; 0x40
 8000ad4:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
 8000ad8:	f1b8 0f00 	cmp.w	r8, #0
 8000adc:	d005      	beq.n	8000aea <z_cbvprintf_impl+0x86>
 8000ade:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000ae2:	f043 0320 	orr.w	r3, r3, #32
 8000ae6:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
 8000aea:	f1be 0f00 	cmp.w	lr, #0
 8000aee:	d005      	beq.n	8000afc <z_cbvprintf_impl+0x98>
 8000af0:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000af4:	f043 0310 	orr.w	r3, r3, #16
 8000af8:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
 8000afc:	f1bc 0f00 	cmp.w	ip, #0
 8000b00:	d005      	beq.n	8000b0e <z_cbvprintf_impl+0xaa>
 8000b02:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000b06:	f043 0308 	orr.w	r3, r3, #8
 8000b0a:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
 8000b0e:	b12e      	cbz	r6, 8000b1c <z_cbvprintf_impl+0xb8>
 8000b10:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000b14:	f043 0304 	orr.w	r3, r3, #4
 8000b18:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
	if (conv->flag_zero && conv->flag_dash) {
 8000b1c:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000b20:	f003 0044 	and.w	r0, r3, #68	; 0x44
 8000b24:	2844      	cmp	r0, #68	; 0x44
 8000b26:	d103      	bne.n	8000b30 <z_cbvprintf_impl+0xcc>
		conv->flag_zero = false;
 8000b28:	f36f 1386 	bfc	r3, #6, #1
 8000b2c:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
	conv->width_present = true;
 8000b30:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
	if (*sp == '*') {
 8000b34:	2a2a      	cmp	r2, #42	; 0x2a
	conv->width_present = true;
 8000b36:	f043 0380 	orr.w	r3, r3, #128	; 0x80
 8000b3a:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
	if (*sp == '*') {
 8000b3e:	d17f      	bne.n	8000c40 <z_cbvprintf_impl+0x1dc>
		conv->width_star = true;
 8000b40:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000b44:	f042 0201 	orr.w	r2, r2, #1
		return ++sp;
 8000b48:	1c4b      	adds	r3, r1, #1
		conv->width_star = true;
 8000b4a:	f88d 2041 	strb.w	r2, [sp, #65]	; 0x41
	conv->prec_present = (*sp == '.');
 8000b4e:	781a      	ldrb	r2, [r3, #0]
 8000b50:	2a2e      	cmp	r2, #46	; 0x2e
 8000b52:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000b56:	bf0c      	ite	eq
 8000b58:	2101      	moveq	r1, #1
 8000b5a:	2100      	movne	r1, #0
 8000b5c:	f361 0241 	bfi	r2, r1, #1, #1
 8000b60:	f88d 2041 	strb.w	r2, [sp, #65]	; 0x41
	if (!conv->prec_present) {
 8000b64:	d178      	bne.n	8000c58 <z_cbvprintf_impl+0x1f4>
	if (*sp == '*') {
 8000b66:	785a      	ldrb	r2, [r3, #1]
 8000b68:	2a2a      	cmp	r2, #42	; 0x2a
 8000b6a:	d06e      	beq.n	8000c4a <z_cbvprintf_impl+0x1e6>
	++sp;
 8000b6c:	3301      	adds	r3, #1
	size_t val = 0;
 8000b6e:	2200      	movs	r2, #0
		val = 10U * val + *sp++ - '0';
 8000b70:	f04f 0c0a 	mov.w	ip, #10
			(((unsigned)c) <= (unsigned)'~'));
}

static inline int isdigit(int a)
{
	return (int)(((unsigned)(a)-(unsigned)'0') < 10U);
 8000b74:	4619      	mov	r1, r3
 8000b76:	f811 0b01 	ldrb.w	r0, [r1], #1
 8000b7a:	f1a0 0630 	sub.w	r6, r0, #48	; 0x30
	while (isdigit((int)(unsigned char)*sp)) {
 8000b7e:	2e09      	cmp	r6, #9
 8000b80:	f240 8095 	bls.w	8000cae <z_cbvprintf_impl+0x24a>
	conv->unsupported |= ((conv->prec_value < 0)
 8000b84:	f89d 1040 	ldrb.w	r1, [sp, #64]	; 0x40
	conv->prec_value = prec;
 8000b88:	9212      	str	r2, [sp, #72]	; 0x48
	conv->unsupported |= ((conv->prec_value < 0)
 8000b8a:	f3c1 0040 	ubfx	r0, r1, #1, #1
 8000b8e:	ea40 70d2 	orr.w	r0, r0, r2, lsr #31
 8000b92:	460a      	mov	r2, r1
 8000b94:	f360 0241 	bfi	r2, r0, #1, #1
 8000b98:	f88d 2040 	strb.w	r2, [sp, #64]	; 0x40
	return sp;
 8000b9c:	e05c      	b.n	8000c58 <z_cbvprintf_impl+0x1f4>
		conv->specifier = *sp++;
 8000b9e:	1cba      	adds	r2, r7, #2
 8000ba0:	9203      	str	r2, [sp, #12]
 8000ba2:	f88d 3043 	strb.w	r3, [sp, #67]	; 0x43
		if (conv->width_star) {
 8000ba6:	f89d 3041 	ldrb.w	r3, [sp, #65]	; 0x41
 8000baa:	07da      	lsls	r2, r3, #31
 8000bac:	f140 812e 	bpl.w	8000e0c <z_cbvprintf_impl+0x3a8>
			width = va_arg(ap, int);
 8000bb0:	f854 8b04 	ldr.w	r8, [r4], #4
			if (width < 0) {
 8000bb4:	f1b8 0f00 	cmp.w	r8, #0
 8000bb8:	da07      	bge.n	8000bca <z_cbvprintf_impl+0x166>
				conv->flag_dash = true;
 8000bba:	f89d 2040 	ldrb.w	r2, [sp, #64]	; 0x40
 8000bbe:	f042 0204 	orr.w	r2, r2, #4
 8000bc2:	f88d 2040 	strb.w	r2, [sp, #64]	; 0x40
				width = -width;
 8000bc6:	f1c8 0800 	rsb	r8, r8, #0
		if (conv->prec_star) {
 8000bca:	075e      	lsls	r6, r3, #29
 8000bcc:	f140 8127 	bpl.w	8000e1e <z_cbvprintf_impl+0x3ba>
			int arg = va_arg(ap, int);
 8000bd0:	f854 ab04 	ldr.w	sl, [r4], #4
			if (arg < 0) {
 8000bd4:	f1ba 0f00 	cmp.w	sl, #0
 8000bd8:	f280 8126 	bge.w	8000e28 <z_cbvprintf_impl+0x3c4>
				conv->prec_present = false;
 8000bdc:	f89d 3041 	ldrb.w	r3, [sp, #65]	; 0x41
 8000be0:	f36f 0341 	bfc	r3, #1, #1
 8000be4:	f88d 3041 	strb.w	r3, [sp, #65]	; 0x41
		int precision = -1;
 8000be8:	f04f 3aff 	mov.w	sl, #4294967295	; 0xffffffff
 8000bec:	e11c      	b.n	8000e28 <z_cbvprintf_impl+0x3c4>
		switch (*sp) {
 8000bee:	2a2d      	cmp	r2, #45	; 0x2d
 8000bf0:	d00d      	beq.n	8000c0e <z_cbvprintf_impl+0x1aa>
 8000bf2:	2a30      	cmp	r2, #48	; 0x30
 8000bf4:	f47f af69 	bne.w	8000aca <z_cbvprintf_impl+0x66>
 8000bf8:	2301      	movs	r3, #1
	} while (loop);
 8000bfa:	e758      	b.n	8000aae <z_cbvprintf_impl+0x4a>
		switch (*sp) {
 8000bfc:	f04f 0c01 	mov.w	ip, #1
 8000c00:	e755      	b.n	8000aae <z_cbvprintf_impl+0x4a>
 8000c02:	f04f 0e01 	mov.w	lr, #1
 8000c06:	e752      	b.n	8000aae <z_cbvprintf_impl+0x4a>
 8000c08:	f04f 0801 	mov.w	r8, #1
 8000c0c:	e74f      	b.n	8000aae <z_cbvprintf_impl+0x4a>
 8000c0e:	2601      	movs	r6, #1
 8000c10:	e74d      	b.n	8000aae <z_cbvprintf_impl+0x4a>
		val = 10U * val + *sp++ - '0';
 8000c12:	fb0e 6202 	mla	r2, lr, r2, r6
 8000c16:	3a30      	subs	r2, #48	; 0x30
 8000c18:	4603      	mov	r3, r0
 8000c1a:	4618      	mov	r0, r3
 8000c1c:	f810 6b01 	ldrb.w	r6, [r0], #1
 8000c20:	f1a6 0c30 	sub.w	ip, r6, #48	; 0x30
	while (isdigit((int)(unsigned char)*sp)) {
 8000c24:	f1bc 0f09 	cmp.w	ip, #9
 8000c28:	d9f3      	bls.n	8000c12 <z_cbvprintf_impl+0x1ae>
	if (sp != wp) {
 8000c2a:	4299      	cmp	r1, r3
 8000c2c:	d08f      	beq.n	8000b4e <z_cbvprintf_impl+0xea>
		conv->unsupported |= ((conv->width_value < 0)
 8000c2e:	f89d 1040 	ldrb.w	r1, [sp, #64]	; 0x40
		conv->width_value = width;
 8000c32:	9211      	str	r2, [sp, #68]	; 0x44
				      || (width != (size_t)conv->width_value));
 8000c34:	0fd2      	lsrs	r2, r2, #31
		conv->unsupported |= ((conv->width_value < 0)
 8000c36:	f362 0141 	bfi	r1, r2, #1, #1
 8000c3a:	f88d 1040 	strb.w	r1, [sp, #64]	; 0x40
 8000c3e:	e786      	b.n	8000b4e <z_cbvprintf_impl+0xea>
 8000c40:	460b      	mov	r3, r1
	size_t val = 0;
 8000c42:	2200      	movs	r2, #0
		val = 10U * val + *sp++ - '0';
 8000c44:	f04f 0e0a 	mov.w	lr, #10
 8000c48:	e7e7      	b.n	8000c1a <z_cbvprintf_impl+0x1b6>
		conv->prec_star = true;
 8000c4a:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000c4e:	f042 0204 	orr.w	r2, r2, #4
 8000c52:	f88d 2041 	strb.w	r2, [sp, #65]	; 0x41
		return ++sp;
 8000c56:	3302      	adds	r3, #2
	switch (*sp) {
 8000c58:	781a      	ldrb	r2, [r3, #0]
 8000c5a:	2a6c      	cmp	r2, #108	; 0x6c
 8000c5c:	d047      	beq.n	8000cee <z_cbvprintf_impl+0x28a>
 8000c5e:	d82b      	bhi.n	8000cb8 <z_cbvprintf_impl+0x254>
 8000c60:	2a68      	cmp	r2, #104	; 0x68
 8000c62:	d031      	beq.n	8000cc8 <z_cbvprintf_impl+0x264>
 8000c64:	2a6a      	cmp	r2, #106	; 0x6a
 8000c66:	d04b      	beq.n	8000d00 <z_cbvprintf_impl+0x29c>
 8000c68:	2a4c      	cmp	r2, #76	; 0x4c
 8000c6a:	d051      	beq.n	8000d10 <z_cbvprintf_impl+0x2ac>
	conv->specifier = *sp++;
 8000c6c:	461a      	mov	r2, r3
 8000c6e:	f812 3b01 	ldrb.w	r3, [r2], #1
 8000c72:	9203      	str	r2, [sp, #12]
	switch (conv->specifier) {
 8000c74:	2b78      	cmp	r3, #120	; 0x78
		if (conv->length_mod == LENGTH_UPPER_L) {
 8000c76:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
	conv->specifier = *sp++;
 8000c7a:	f88d 3043 	strb.w	r3, [sp, #67]	; 0x43
	switch (conv->specifier) {
 8000c7e:	f200 80be 	bhi.w	8000dfe <z_cbvprintf_impl+0x39a>
 8000c82:	2b6d      	cmp	r3, #109	; 0x6d
 8000c84:	d851      	bhi.n	8000d2a <z_cbvprintf_impl+0x2c6>
 8000c86:	2b69      	cmp	r3, #105	; 0x69
 8000c88:	f200 80b9 	bhi.w	8000dfe <z_cbvprintf_impl+0x39a>
 8000c8c:	2b57      	cmp	r3, #87	; 0x57
 8000c8e:	d867      	bhi.n	8000d60 <z_cbvprintf_impl+0x2fc>
 8000c90:	2b41      	cmp	r3, #65	; 0x41
 8000c92:	d003      	beq.n	8000c9c <z_cbvprintf_impl+0x238>
 8000c94:	3b45      	subs	r3, #69	; 0x45
 8000c96:	2b02      	cmp	r3, #2
 8000c98:	f200 80b1 	bhi.w	8000dfe <z_cbvprintf_impl+0x39a>
		conv->specifier_cat = SPECIFIER_FP;
 8000c9c:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 8000ca0:	2204      	movs	r2, #4
 8000ca2:	f362 0302 	bfi	r3, r2, #0, #3
 8000ca6:	f88d 3042 	strb.w	r3, [sp, #66]	; 0x42
			unsupported = true;
 8000caa:	2301      	movs	r3, #1
			break;
 8000cac:	e073      	b.n	8000d96 <z_cbvprintf_impl+0x332>
		val = 10U * val + *sp++ - '0';
 8000cae:	fb0c 0202 	mla	r2, ip, r2, r0
 8000cb2:	3a30      	subs	r2, #48	; 0x30
 8000cb4:	460b      	mov	r3, r1
 8000cb6:	e75d      	b.n	8000b74 <z_cbvprintf_impl+0x110>
	switch (*sp) {
 8000cb8:	2a74      	cmp	r2, #116	; 0x74
 8000cba:	d025      	beq.n	8000d08 <z_cbvprintf_impl+0x2a4>
 8000cbc:	2a7a      	cmp	r2, #122	; 0x7a
 8000cbe:	d1d5      	bne.n	8000c6c <z_cbvprintf_impl+0x208>
		conv->length_mod = LENGTH_Z;
 8000cc0:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000cc4:	2106      	movs	r1, #6
 8000cc6:	e00c      	b.n	8000ce2 <z_cbvprintf_impl+0x27e>
		if (*++sp == 'h') {
 8000cc8:	785a      	ldrb	r2, [r3, #1]
 8000cca:	2a68      	cmp	r2, #104	; 0x68
 8000ccc:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000cd0:	d106      	bne.n	8000ce0 <z_cbvprintf_impl+0x27c>
			conv->length_mod = LENGTH_HH;
 8000cd2:	2101      	movs	r1, #1
			conv->length_mod = LENGTH_LL;
 8000cd4:	f361 02c6 	bfi	r2, r1, #3, #4
 8000cd8:	f88d 2041 	strb.w	r2, [sp, #65]	; 0x41
			++sp;
 8000cdc:	3302      	adds	r3, #2
 8000cde:	e7c5      	b.n	8000c6c <z_cbvprintf_impl+0x208>
			conv->length_mod = LENGTH_H;
 8000ce0:	2102      	movs	r1, #2
 8000ce2:	f361 02c6 	bfi	r2, r1, #3, #4
 8000ce6:	f88d 2041 	strb.w	r2, [sp, #65]	; 0x41
		if (*++sp == 'h') {
 8000cea:	3301      	adds	r3, #1
 8000cec:	e7be      	b.n	8000c6c <z_cbvprintf_impl+0x208>
		if (*++sp == 'l') {
 8000cee:	785a      	ldrb	r2, [r3, #1]
 8000cf0:	2a6c      	cmp	r2, #108	; 0x6c
 8000cf2:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000cf6:	d101      	bne.n	8000cfc <z_cbvprintf_impl+0x298>
			conv->length_mod = LENGTH_LL;
 8000cf8:	2104      	movs	r1, #4
 8000cfa:	e7eb      	b.n	8000cd4 <z_cbvprintf_impl+0x270>
			conv->length_mod = LENGTH_L;
 8000cfc:	2103      	movs	r1, #3
 8000cfe:	e7f0      	b.n	8000ce2 <z_cbvprintf_impl+0x27e>
		conv->length_mod = LENGTH_J;
 8000d00:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000d04:	2105      	movs	r1, #5
 8000d06:	e7ec      	b.n	8000ce2 <z_cbvprintf_impl+0x27e>
		conv->length_mod = LENGTH_T;
 8000d08:	f89d 2041 	ldrb.w	r2, [sp, #65]	; 0x41
 8000d0c:	2107      	movs	r1, #7
 8000d0e:	e7e8      	b.n	8000ce2 <z_cbvprintf_impl+0x27e>
		conv->unsupported = true;
 8000d10:	f8bd 2040 	ldrh.w	r2, [sp, #64]	; 0x40
 8000d14:	f422 42f0 	bic.w	r2, r2, #30720	; 0x7800
 8000d18:	f022 0202 	bic.w	r2, r2, #2
 8000d1c:	f442 4280 	orr.w	r2, r2, #16384	; 0x4000
 8000d20:	f042 0202 	orr.w	r2, r2, #2
 8000d24:	f8ad 2040 	strh.w	r2, [sp, #64]	; 0x40
		break;
 8000d28:	e7df      	b.n	8000cea <z_cbvprintf_impl+0x286>
	switch (conv->specifier) {
 8000d2a:	3b6e      	subs	r3, #110	; 0x6e
 8000d2c:	b2d9      	uxtb	r1, r3
 8000d2e:	2301      	movs	r3, #1
 8000d30:	408b      	lsls	r3, r1
 8000d32:	f240 4182 	movw	r1, #1154	; 0x482
 8000d36:	420b      	tst	r3, r1
 8000d38:	d137      	bne.n	8000daa <z_cbvprintf_impl+0x346>
 8000d3a:	f013 0f24 	tst.w	r3, #36	; 0x24
 8000d3e:	d151      	bne.n	8000de4 <z_cbvprintf_impl+0x380>
 8000d40:	07d8      	lsls	r0, r3, #31
 8000d42:	d55c      	bpl.n	8000dfe <z_cbvprintf_impl+0x39a>
		conv->specifier_cat = SPECIFIER_PTR;
 8000d44:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 8000d48:	2103      	movs	r1, #3
 8000d4a:	f361 0302 	bfi	r3, r1, #0, #3
 8000d4e:	f88d 3042 	strb.w	r3, [sp, #66]	; 0x42
		if (conv->length_mod == LENGTH_UPPER_L) {
 8000d52:	f002 0378 	and.w	r3, r2, #120	; 0x78
 8000d56:	f1a3 0140 	sub.w	r1, r3, #64	; 0x40
 8000d5a:	424b      	negs	r3, r1
 8000d5c:	414b      	adcs	r3, r1
 8000d5e:	e01a      	b.n	8000d96 <z_cbvprintf_impl+0x332>
	switch (conv->specifier) {
 8000d60:	f1a3 0158 	sub.w	r1, r3, #88	; 0x58
 8000d64:	b2c9      	uxtb	r1, r1
 8000d66:	2001      	movs	r0, #1
 8000d68:	fa00 f101 	lsl.w	r1, r0, r1
 8000d6c:	f411 4f62 	tst.w	r1, #57856	; 0xe200
 8000d70:	d194      	bne.n	8000c9c <z_cbvprintf_impl+0x238>
 8000d72:	f640 0601 	movw	r6, #2049	; 0x801
 8000d76:	4231      	tst	r1, r6
 8000d78:	d11d      	bne.n	8000db6 <z_cbvprintf_impl+0x352>
 8000d7a:	f411 3f04 	tst.w	r1, #135168	; 0x21000
 8000d7e:	d03e      	beq.n	8000dfe <z_cbvprintf_impl+0x39a>
		conv->specifier_cat = SPECIFIER_SINT;
 8000d80:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 8000d84:	f360 0302 	bfi	r3, r0, #0, #3
		if (conv->length_mod == LENGTH_UPPER_L) {
 8000d88:	f002 0278 	and.w	r2, r2, #120	; 0x78
 8000d8c:	2a40      	cmp	r2, #64	; 0x40
		conv->specifier_cat = SPECIFIER_SINT;
 8000d8e:	f88d 3042 	strb.w	r3, [sp, #66]	; 0x42
		if (conv->length_mod == LENGTH_UPPER_L) {
 8000d92:	d034      	beq.n	8000dfe <z_cbvprintf_impl+0x39a>
	bool unsupported = false;
 8000d94:	2300      	movs	r3, #0
	conv->unsupported |= unsupported;
 8000d96:	f89d 2040 	ldrb.w	r2, [sp, #64]	; 0x40
 8000d9a:	f3c2 0140 	ubfx	r1, r2, #1, #1
 8000d9e:	430b      	orrs	r3, r1
 8000da0:	f363 0241 	bfi	r2, r3, #1, #1
 8000da4:	f88d 2040 	strb.w	r2, [sp, #64]	; 0x40
	return sp;
 8000da8:	e6fd      	b.n	8000ba6 <z_cbvprintf_impl+0x142>
		conv->specifier_cat = SPECIFIER_UINT;
 8000daa:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 8000dae:	2102      	movs	r1, #2
 8000db0:	f361 0302 	bfi	r3, r1, #0, #3
 8000db4:	e7e8      	b.n	8000d88 <z_cbvprintf_impl+0x324>
 8000db6:	f89d 1042 	ldrb.w	r1, [sp, #66]	; 0x42
 8000dba:	2002      	movs	r0, #2
		if (conv->length_mod == LENGTH_UPPER_L) {
 8000dbc:	f002 0278 	and.w	r2, r2, #120	; 0x78
		conv->specifier_cat = SPECIFIER_UINT;
 8000dc0:	f360 0102 	bfi	r1, r0, #0, #3
		if (conv->length_mod == LENGTH_UPPER_L) {
 8000dc4:	2a40      	cmp	r2, #64	; 0x40
		conv->specifier_cat = SPECIFIER_UINT;
 8000dc6:	f88d 1042 	strb.w	r1, [sp, #66]	; 0x42
			conv->invalid = true;
 8000dca:	bf02      	ittt	eq
 8000dcc:	f89d 1040 	ldrbeq.w	r1, [sp, #64]	; 0x40
 8000dd0:	f041 0101 	orreq.w	r1, r1, #1
 8000dd4:	f88d 1040 	strbeq.w	r1, [sp, #64]	; 0x40
		if (conv->specifier == 'c') {
 8000dd8:	2b63      	cmp	r3, #99	; 0x63
 8000dda:	d1db      	bne.n	8000d94 <z_cbvprintf_impl+0x330>
			unsupported = (conv->length_mod != LENGTH_NONE);
 8000ddc:	1e13      	subs	r3, r2, #0
 8000dde:	bf18      	it	ne
 8000de0:	2301      	movne	r3, #1
 8000de2:	e7d8      	b.n	8000d96 <z_cbvprintf_impl+0x332>
		conv->specifier_cat = SPECIFIER_PTR;
 8000de4:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 8000de8:	2103      	movs	r1, #3
 8000dea:	f361 0302 	bfi	r3, r1, #0, #3
		if (conv->length_mod != LENGTH_NONE) {
 8000dee:	f012 0f78 	tst.w	r2, #120	; 0x78
		conv->specifier_cat = SPECIFIER_PTR;
 8000df2:	f88d 3042 	strb.w	r3, [sp, #66]	; 0x42
		if (conv->length_mod != LENGTH_NONE) {
 8000df6:	bf14      	ite	ne
 8000df8:	2301      	movne	r3, #1
 8000dfa:	2300      	moveq	r3, #0
 8000dfc:	e7cb      	b.n	8000d96 <z_cbvprintf_impl+0x332>
		conv->invalid = true;
 8000dfe:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000e02:	f043 0301 	orr.w	r3, r3, #1
 8000e06:	f88d 3040 	strb.w	r3, [sp, #64]	; 0x40
		break;
 8000e0a:	e7c3      	b.n	8000d94 <z_cbvprintf_impl+0x330>
		} else if (conv->width_present) {
 8000e0c:	f99d 2040 	ldrsb.w	r2, [sp, #64]	; 0x40
 8000e10:	2a00      	cmp	r2, #0
			width = conv->width_value;
 8000e12:	bfb4      	ite	lt
 8000e14:	f8dd 8044 	ldrlt.w	r8, [sp, #68]	; 0x44
		int width = -1;
 8000e18:	f04f 38ff 	movge.w	r8, #4294967295	; 0xffffffff
 8000e1c:	e6d5      	b.n	8000bca <z_cbvprintf_impl+0x166>
		} else if (conv->prec_present) {
 8000e1e:	0798      	lsls	r0, r3, #30
 8000e20:	f57f aee2 	bpl.w	8000be8 <z_cbvprintf_impl+0x184>
			precision = conv->prec_value;
 8000e24:	f8dd a048 	ldr.w	sl, [sp, #72]	; 0x48
			= (enum length_mod_enum)conv->length_mod;
 8000e28:	f89d 1041 	ldrb.w	r1, [sp, #65]	; 0x41
		conv->pad0_value = 0;
 8000e2c:	2300      	movs	r3, #0
		conv->pad0_pre_exp = 0;
 8000e2e:	e9cd 3311 	strd	r3, r3, [sp, #68]	; 0x44
			= (enum specifier_cat_enum)conv->specifier_cat;
 8000e32:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
		enum specifier_cat_enum specifier_cat
 8000e36:	f003 0307 	and.w	r3, r3, #7
		if (specifier_cat == SPECIFIER_SINT) {
 8000e3a:	2b01      	cmp	r3, #1
			= (enum length_mod_enum)conv->length_mod;
 8000e3c:	f3c1 01c3 	ubfx	r1, r1, #3, #4
		if (specifier_cat == SPECIFIER_SINT) {
 8000e40:	d133      	bne.n	8000eaa <z_cbvprintf_impl+0x446>
			switch (length_mod) {
 8000e42:	1ecb      	subs	r3, r1, #3
 8000e44:	2b04      	cmp	r3, #4
 8000e46:	d804      	bhi.n	8000e52 <z_cbvprintf_impl+0x3ee>
 8000e48:	e8df f003 	tbb	[pc, r3]
 8000e4c:	21464621 	.word	0x21464621
 8000e50:	21          	.byte	0x21
 8000e51:	00          	.byte	0x00
				value->sint = va_arg(ap, int);
 8000e52:	6823      	ldr	r3, [r4, #0]
			if (length_mod == LENGTH_HH) {
 8000e54:	2901      	cmp	r1, #1
				value->sint = va_arg(ap, int);
 8000e56:	ea4f 72e3 	mov.w	r2, r3, asr #31
 8000e5a:	e9cd 320e 	strd	r3, r2, [sp, #56]	; 0x38
			if (length_mod == LENGTH_HH) {
 8000e5e:	d11c      	bne.n	8000e9a <z_cbvprintf_impl+0x436>
				value->sint = (signed char)value->sint;
 8000e60:	f99d 3038 	ldrsb.w	r3, [sp, #56]	; 0x38
 8000e64:	17da      	asrs	r2, r3, #31
 8000e66:	e9cd 320e 	strd	r3, r2, [sp, #56]	; 0x38
				value->sint = va_arg(ap, int);
 8000e6a:	3404      	adds	r4, #4
		if (conv->invalid || conv->unsupported) {
 8000e6c:	f89d 3040 	ldrb.w	r3, [sp, #64]	; 0x40
 8000e70:	f013 0603 	ands.w	r6, r3, #3
 8000e74:	d050      	beq.n	8000f18 <z_cbvprintf_impl+0x4b4>
			OUTS(sp, fp);
 8000e76:	9b03      	ldr	r3, [sp, #12]
 8000e78:	463a      	mov	r2, r7
 8000e7a:	4659      	mov	r1, fp
 8000e7c:	4648      	mov	r0, r9
 8000e7e:	f003 fe24 	bl	8004aca <outs>
 8000e82:	2800      	cmp	r0, #0
 8000e84:	f2c0 8153 	blt.w	800112e <z_cbvprintf_impl+0x6ca>
 8000e88:	4405      	add	r5, r0
			continue;
 8000e8a:	9f03      	ldr	r7, [sp, #12]
 8000e8c:	e5f2      	b.n	8000a74 <z_cbvprintf_impl+0x10>
					(sint_value_type)va_arg(ap, ptrdiff_t);
 8000e8e:	f854 3b04 	ldr.w	r3, [r4], #4
 8000e92:	17da      	asrs	r2, r3, #31
				value->uint = (unsigned char)value->uint;
 8000e94:	e9cd 320e 	strd	r3, r2, [sp, #56]	; 0x38
 8000e98:	e7e8      	b.n	8000e6c <z_cbvprintf_impl+0x408>
			} else if (length_mod == LENGTH_H) {
 8000e9a:	2902      	cmp	r1, #2
 8000e9c:	d1e5      	bne.n	8000e6a <z_cbvprintf_impl+0x406>
				value->sint = (short)value->sint;
 8000e9e:	b21a      	sxth	r2, r3
 8000ea0:	f343 33c0 	sbfx	r3, r3, #15, #1
 8000ea4:	e9cd 230e 	strd	r2, r3, [sp, #56]	; 0x38
 8000ea8:	e7df      	b.n	8000e6a <z_cbvprintf_impl+0x406>
		} else if (specifier_cat == SPECIFIER_UINT) {
 8000eaa:	2b02      	cmp	r3, #2
 8000eac:	d124      	bne.n	8000ef8 <z_cbvprintf_impl+0x494>
			switch (length_mod) {
 8000eae:	1ecb      	subs	r3, r1, #3
 8000eb0:	2b04      	cmp	r3, #4
 8000eb2:	d804      	bhi.n	8000ebe <z_cbvprintf_impl+0x45a>
 8000eb4:	e8df f003 	tbb	[pc, r3]
 8000eb8:	18101018 	.word	0x18101018
 8000ebc:	18          	.byte	0x18
 8000ebd:	00          	.byte	0x00
			if (length_mod == LENGTH_HH) {
 8000ebe:	2901      	cmp	r1, #1
				value->uint = va_arg(ap, unsigned int);
 8000ec0:	f854 3b04 	ldr.w	r3, [r4], #4
			if (length_mod == LENGTH_HH) {
 8000ec4:	f04f 0200 	mov.w	r2, #0
 8000ec8:	d014      	beq.n	8000ef4 <z_cbvprintf_impl+0x490>
			} else if (length_mod == LENGTH_H) {
 8000eca:	2902      	cmp	r1, #2
				value->uint = va_arg(ap, unsigned int);
 8000ecc:	e9cd 320e 	strd	r3, r2, [sp, #56]	; 0x38
			} else if (length_mod == LENGTH_H) {
 8000ed0:	d1cc      	bne.n	8000e6c <z_cbvprintf_impl+0x408>
				value->uint = (unsigned short)value->uint;
 8000ed2:	b29b      	uxth	r3, r3
			value->ptr = va_arg(ap, void *);
 8000ed4:	930e      	str	r3, [sp, #56]	; 0x38
 8000ed6:	e7c9      	b.n	8000e6c <z_cbvprintf_impl+0x408>
					(uint_value_type)va_arg(ap,
 8000ed8:	3407      	adds	r4, #7
 8000eda:	f024 0407 	bic.w	r4, r4, #7
				value->uint =
 8000ede:	e8f4 2302 	ldrd	r2, r3, [r4], #8
 8000ee2:	e9cd 230e 	strd	r2, r3, [sp, #56]	; 0x38
			if (length_mod == LENGTH_HH) {
 8000ee6:	e7c1      	b.n	8000e6c <z_cbvprintf_impl+0x408>
					(uint_value_type)va_arg(ap, size_t);
 8000ee8:	f854 3b04 	ldr.w	r3, [r4], #4
 8000eec:	930e      	str	r3, [sp, #56]	; 0x38
 8000eee:	2300      	movs	r3, #0
 8000ef0:	930f      	str	r3, [sp, #60]	; 0x3c
			} else if (length_mod == LENGTH_H) {
 8000ef2:	e7bb      	b.n	8000e6c <z_cbvprintf_impl+0x408>
				value->uint = (unsigned char)value->uint;
 8000ef4:	b2db      	uxtb	r3, r3
 8000ef6:	e7cd      	b.n	8000e94 <z_cbvprintf_impl+0x430>
		} else if (specifier_cat == SPECIFIER_FP) {
 8000ef8:	2b04      	cmp	r3, #4
 8000efa:	d108      	bne.n	8000f0e <z_cbvprintf_impl+0x4aa>
					(sint_value_type)va_arg(ap, long long);
 8000efc:	3407      	adds	r4, #7
				value->ldbl = va_arg(ap, long double);
 8000efe:	f024 0407 	bic.w	r4, r4, #7
 8000f02:	e9d4 2300 	ldrd	r2, r3, [r4]
 8000f06:	3408      	adds	r4, #8
 8000f08:	e9cd 230e 	strd	r2, r3, [sp, #56]	; 0x38
 8000f0c:	e7ae      	b.n	8000e6c <z_cbvprintf_impl+0x408>
		} else if (specifier_cat == SPECIFIER_PTR) {
 8000f0e:	2b03      	cmp	r3, #3
 8000f10:	d1ac      	bne.n	8000e6c <z_cbvprintf_impl+0x408>
			value->ptr = va_arg(ap, void *);
 8000f12:	f854 3b04 	ldr.w	r3, [r4], #4
 8000f16:	e7dd      	b.n	8000ed4 <z_cbvprintf_impl+0x470>
		switch (conv->specifier) {
 8000f18:	f89d 0043 	ldrb.w	r0, [sp, #67]	; 0x43
 8000f1c:	2878      	cmp	r0, #120	; 0x78
 8000f1e:	d8b4      	bhi.n	8000e8a <z_cbvprintf_impl+0x426>
 8000f20:	2862      	cmp	r0, #98	; 0x62
 8000f22:	d81c      	bhi.n	8000f5e <z_cbvprintf_impl+0x4fa>
 8000f24:	2825      	cmp	r0, #37	; 0x25
 8000f26:	f43f adad 	beq.w	8000a84 <z_cbvprintf_impl+0x20>
 8000f2a:	2858      	cmp	r0, #88	; 0x58
 8000f2c:	d1ad      	bne.n	8000e8a <z_cbvprintf_impl+0x426>
			bps = encode_uint(value->uint, conv, buf, bpe);
 8000f2e:	f10d 0336 	add.w	r3, sp, #54	; 0x36
 8000f32:	9300      	str	r3, [sp, #0]
 8000f34:	e9dd 010e 	ldrd	r0, r1, [sp, #56]	; 0x38
 8000f38:	ab08      	add	r3, sp, #32
 8000f3a:	aa10      	add	r2, sp, #64	; 0x40
 8000f3c:	f003 fd7f 	bl	8004a3e <encode_uint>
			if (precision >= 0) {
 8000f40:	f1ba 0f00 	cmp.w	sl, #0
			bps = encode_uint(value->uint, conv, buf, bpe);
 8000f44:	4607      	mov	r7, r0
			if (precision >= 0) {
 8000f46:	f280 809a 	bge.w	800107e <z_cbvprintf_impl+0x61a>
		if (bps == NULL) {
 8000f4a:	2f00      	cmp	r7, #0
 8000f4c:	d09d      	beq.n	8000e8a <z_cbvprintf_impl+0x426>
		size_t nj_len = (bpe - bps);
 8000f4e:	f10d 0336 	add.w	r3, sp, #54	; 0x36
 8000f52:	1bd8      	subs	r0, r3, r7
		if (sign != 0) {
 8000f54:	2e00      	cmp	r6, #0
 8000f56:	f000 80c1 	beq.w	80010dc <z_cbvprintf_impl+0x678>
			nj_len += 1U;
 8000f5a:	3001      	adds	r0, #1
 8000f5c:	e0be      	b.n	80010dc <z_cbvprintf_impl+0x678>
		switch (conv->specifier) {
 8000f5e:	3863      	subs	r0, #99	; 0x63
 8000f60:	2815      	cmp	r0, #21
 8000f62:	d892      	bhi.n	8000e8a <z_cbvprintf_impl+0x426>
 8000f64:	a201      	add	r2, pc, #4	; (adr r2, 8000f6c <z_cbvprintf_impl+0x508>)
 8000f66:	f852 f020 	ldr.w	pc, [r2, r0, lsl #2]
 8000f6a:	bf00      	nop
 8000f6c:	08001041 	.word	0x08001041
 8000f70:	08001053 	.word	0x08001053
 8000f74:	08000e8b 	.word	0x08000e8b
 8000f78:	08000e8b 	.word	0x08000e8b
 8000f7c:	08000e8b 	.word	0x08000e8b
 8000f80:	08000e8b 	.word	0x08000e8b
 8000f84:	08001053 	.word	0x08001053
 8000f88:	08000e8b 	.word	0x08000e8b
 8000f8c:	08000e8b 	.word	0x08000e8b
 8000f90:	08000e8b 	.word	0x08000e8b
 8000f94:	08000e8b 	.word	0x08000e8b
 8000f98:	080010e1 	.word	0x080010e1
 8000f9c:	08001079 	.word	0x08001079
 8000fa0:	0800109f 	.word	0x0800109f
 8000fa4:	08000e8b 	.word	0x08000e8b
 8000fa8:	08000e8b 	.word	0x08000e8b
 8000fac:	08000fc5 	.word	0x08000fc5
 8000fb0:	08000e8b 	.word	0x08000e8b
 8000fb4:	08001079 	.word	0x08001079
 8000fb8:	08000e8b 	.word	0x08000e8b
 8000fbc:	08000e8b 	.word	0x08000e8b
 8000fc0:	08001079 	.word	0x08001079
			if (precision >= 0) {
 8000fc4:	f1ba 0f00 	cmp.w	sl, #0
			bps = (const char *)value->ptr;
 8000fc8:	9f0e      	ldr	r7, [sp, #56]	; 0x38
			if (precision >= 0) {
 8000fca:	db35      	blt.n	8001038 <z_cbvprintf_impl+0x5d4>
				len = strnlen(bps, precision);
 8000fcc:	4651      	mov	r1, sl
 8000fce:	4638      	mov	r0, r7
 8000fd0:	f003 fdd5 	bl	8004b7e <strnlen>
			bpe = bps + len;
 8000fd4:	eb07 0a00 	add.w	sl, r7, r0
		if (bps == NULL) {
 8000fd8:	2f00      	cmp	r7, #0
 8000fda:	f43f af56 	beq.w	8000e8a <z_cbvprintf_impl+0x426>
		char sign = 0;
 8000fde:	2600      	movs	r6, #0
		if (conv->altform_0c) {
 8000fe0:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 8000fe4:	f013 0210 	ands.w	r2, r3, #16
 8000fe8:	9205      	str	r2, [sp, #20]
 8000fea:	f000 8093 	beq.w	8001114 <z_cbvprintf_impl+0x6b0>
			nj_len += 2U;
 8000fee:	3002      	adds	r0, #2
		if (conv->pad_fp) {
 8000ff0:	065b      	lsls	r3, r3, #25
		nj_len += conv->pad0_value;
 8000ff2:	9a11      	ldr	r2, [sp, #68]	; 0x44
			nj_len += conv->pad0_pre_exp;
 8000ff4:	bf48      	it	mi
 8000ff6:	9b12      	ldrmi	r3, [sp, #72]	; 0x48
		nj_len += conv->pad0_value;
 8000ff8:	9204      	str	r2, [sp, #16]
 8000ffa:	4410      	add	r0, r2
			nj_len += conv->pad0_pre_exp;
 8000ffc:	bf48      	it	mi
 8000ffe:	18c0      	addmi	r0, r0, r3
		if (width > 0) {
 8001000:	f1b8 0f00 	cmp.w	r8, #0
 8001004:	f340 80a0 	ble.w	8001148 <z_cbvprintf_impl+0x6e4>
			if (!conv->flag_dash) {
 8001008:	f89d 2040 	ldrb.w	r2, [sp, #64]	; 0x40
			width -= (int)nj_len;
 800100c:	eba8 0800 	sub.w	r8, r8, r0
			if (!conv->flag_dash) {
 8001010:	f3c2 0380 	ubfx	r3, r2, #2, #1
 8001014:	0750      	lsls	r0, r2, #29
 8001016:	9306      	str	r3, [sp, #24]
 8001018:	f100 8096 	bmi.w	8001148 <z_cbvprintf_impl+0x6e4>
				if (conv->flag_zero) {
 800101c:	0651      	lsls	r1, r2, #25
 800101e:	f140 8089 	bpl.w	8001134 <z_cbvprintf_impl+0x6d0>
					if (sign != 0) {
 8001022:	b13e      	cbz	r6, 8001034 <z_cbvprintf_impl+0x5d0>
						OUTC(sign);
 8001024:	4659      	mov	r1, fp
 8001026:	4630      	mov	r0, r6
 8001028:	47c8      	blx	r9
 800102a:	2800      	cmp	r0, #0
 800102c:	db7f      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 800102e:	9b06      	ldr	r3, [sp, #24]
 8001030:	3501      	adds	r5, #1
 8001032:	461e      	mov	r6, r3
					pad = '0';
 8001034:	2230      	movs	r2, #48	; 0x30
 8001036:	e07e      	b.n	8001136 <z_cbvprintf_impl+0x6d2>
				len = strlen(bps);
 8001038:	4638      	mov	r0, r7
 800103a:	f003 fd99 	bl	8004b70 <strlen>
 800103e:	e7c9      	b.n	8000fd4 <z_cbvprintf_impl+0x570>
			buf[0] = CHAR_IS_SIGNED ? value->sint : value->uint;
 8001040:	9b0e      	ldr	r3, [sp, #56]	; 0x38
 8001042:	f88d 3020 	strb.w	r3, [sp, #32]
		char sign = 0;
 8001046:	2600      	movs	r6, #0
			bps = buf;
 8001048:	af08      	add	r7, sp, #32
			bpe = buf + 1;
 800104a:	f10d 0a21 	add.w	sl, sp, #33	; 0x21
		size_t nj_len = (bpe - bps);
 800104e:	2001      	movs	r0, #1
 8001050:	e7c6      	b.n	8000fe0 <z_cbvprintf_impl+0x57c>
			if (conv->flag_plus) {
 8001052:	0719      	lsls	r1, r3, #28
			} else if (conv->flag_space) {
 8001054:	bf5c      	itt	pl
 8001056:	f3c3 1300 	ubfxpl	r3, r3, #4, #1
 800105a:	015e      	lslpl	r6, r3, #5
			sint = value->sint;
 800105c:	e9dd 230e 	ldrd	r2, r3, [sp, #56]	; 0x38
				sign = '+';
 8001060:	bf48      	it	mi
 8001062:	262b      	movmi	r6, #43	; 0x2b
			if (sint < 0) {
 8001064:	2b00      	cmp	r3, #0
 8001066:	f6bf af62 	bge.w	8000f2e <z_cbvprintf_impl+0x4ca>
				value->uint = (uint_value_type)-sint;
 800106a:	4252      	negs	r2, r2
 800106c:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
 8001070:	e9cd 230e 	strd	r2, r3, [sp, #56]	; 0x38
				sign = '-';
 8001074:	262d      	movs	r6, #45	; 0x2d
 8001076:	e75a      	b.n	8000f2e <z_cbvprintf_impl+0x4ca>
		switch (conv->specifier) {
 8001078:	2600      	movs	r6, #0
 800107a:	e758      	b.n	8000f2e <z_cbvprintf_impl+0x4ca>
		char sign = 0;
 800107c:	2600      	movs	r6, #0
				conv->flag_zero = false;
 800107e:	f89d 2040 	ldrb.w	r2, [sp, #64]	; 0x40
				size_t len = bpe - bps;
 8001082:	f10d 0336 	add.w	r3, sp, #54	; 0x36
 8001086:	1bdb      	subs	r3, r3, r7
				conv->flag_zero = false;
 8001088:	f36f 1286 	bfc	r2, #6, #1
				if (len < (size_t)precision) {
 800108c:	459a      	cmp	sl, r3
				conv->flag_zero = false;
 800108e:	f88d 2040 	strb.w	r2, [sp, #64]	; 0x40
				if (len < (size_t)precision) {
 8001092:	f67f af5a 	bls.w	8000f4a <z_cbvprintf_impl+0x4e6>
					conv->pad0_value = precision - (int)len;
 8001096:	ebaa 0303 	sub.w	r3, sl, r3
 800109a:	9311      	str	r3, [sp, #68]	; 0x44
 800109c:	e755      	b.n	8000f4a <z_cbvprintf_impl+0x4e6>
			if (value->ptr != NULL) {
 800109e:	980e      	ldr	r0, [sp, #56]	; 0x38
 80010a0:	b390      	cbz	r0, 8001108 <z_cbvprintf_impl+0x6a4>
				bps = encode_uint((uintptr_t)value->ptr, conv,
 80010a2:	f10d 0336 	add.w	r3, sp, #54	; 0x36
 80010a6:	9300      	str	r3, [sp, #0]
 80010a8:	aa10      	add	r2, sp, #64	; 0x40
 80010aa:	ab08      	add	r3, sp, #32
 80010ac:	2100      	movs	r1, #0
 80010ae:	f003 fcc6 	bl	8004a3e <encode_uint>
				conv->altform_0c = true;
 80010b2:	f8bd 3042 	ldrh.w	r3, [sp, #66]	; 0x42
 80010b6:	f003 03ef 	and.w	r3, r3, #239	; 0xef
 80010ba:	f443 43f0 	orr.w	r3, r3, #30720	; 0x7800
 80010be:	f043 0310 	orr.w	r3, r3, #16
			if (precision >= 0) {
 80010c2:	f1ba 0f00 	cmp.w	sl, #0
				bps = encode_uint((uintptr_t)value->ptr, conv,
 80010c6:	4607      	mov	r7, r0
				conv->altform_0c = true;
 80010c8:	f8ad 3042 	strh.w	r3, [sp, #66]	; 0x42
			if (precision >= 0) {
 80010cc:	dad6      	bge.n	800107c <z_cbvprintf_impl+0x618>
		if (bps == NULL) {
 80010ce:	2800      	cmp	r0, #0
 80010d0:	f43f aedb 	beq.w	8000e8a <z_cbvprintf_impl+0x426>
		size_t nj_len = (bpe - bps);
 80010d4:	f10d 0336 	add.w	r3, sp, #54	; 0x36
 80010d8:	1a18      	subs	r0, r3, r0
		char sign = 0;
 80010da:	2600      	movs	r6, #0
 80010dc:	469a      	mov	sl, r3
 80010de:	e77f      	b.n	8000fe0 <z_cbvprintf_impl+0x57c>
				store_count(conv, value->ptr, count);
 80010e0:	9b0e      	ldr	r3, [sp, #56]	; 0x38
	switch ((enum length_mod_enum)conv->length_mod) {
 80010e2:	2907      	cmp	r1, #7
 80010e4:	f63f aed1 	bhi.w	8000e8a <z_cbvprintf_impl+0x426>
 80010e8:	e8df f001 	tbb	[pc, r1]
 80010ec:	0c06040c 	.word	0x0c06040c
 80010f0:	0c0c0808 	.word	0x0c0c0808
		*(signed char *)dp = (signed char)count;
 80010f4:	701d      	strb	r5, [r3, #0]
		if (bps == NULL) {
 80010f6:	e6c8      	b.n	8000e8a <z_cbvprintf_impl+0x426>
		*(short *)dp = (short)count;
 80010f8:	801d      	strh	r5, [r3, #0]
		if (bps == NULL) {
 80010fa:	e6c6      	b.n	8000e8a <z_cbvprintf_impl+0x426>
		*(intmax_t *)dp = (intmax_t)count;
 80010fc:	17ea      	asrs	r2, r5, #31
 80010fe:	e9c3 5200 	strd	r5, r2, [r3]
		if (bps == NULL) {
 8001102:	e6c2      	b.n	8000e8a <z_cbvprintf_impl+0x426>
		*(ptrdiff_t *)dp = (ptrdiff_t)count;
 8001104:	601d      	str	r5, [r3, #0]
		if (bps == NULL) {
 8001106:	e6c0      	b.n	8000e8a <z_cbvprintf_impl+0x426>
 8001108:	4f2e      	ldr	r7, [pc, #184]	; (80011c4 <z_cbvprintf_impl+0x760>)
		char sign = 0;
 800110a:	4606      	mov	r6, r0
			bpe = bps + 5;
 800110c:	f107 0a05 	add.w	sl, r7, #5
		size_t nj_len = (bpe - bps);
 8001110:	2005      	movs	r0, #5
 8001112:	e765      	b.n	8000fe0 <z_cbvprintf_impl+0x57c>
		} else if (conv->altform_0) {
 8001114:	071a      	lsls	r2, r3, #28
			nj_len += 1U;
 8001116:	bf48      	it	mi
 8001118:	3001      	addmi	r0, #1
 800111a:	e769      	b.n	8000ff0 <z_cbvprintf_impl+0x58c>
 800111c:	9307      	str	r3, [sp, #28]
					OUTC(pad);
 800111e:	4610      	mov	r0, r2
 8001120:	9206      	str	r2, [sp, #24]
 8001122:	4659      	mov	r1, fp
 8001124:	47c8      	blx	r9
 8001126:	2800      	cmp	r0, #0
 8001128:	e9dd 2306 	ldrd	r2, r3, [sp, #24]
 800112c:	da04      	bge.n	8001138 <z_cbvprintf_impl+0x6d4>
#undef OUTS
#undef OUTC
}
 800112e:	b015      	add	sp, #84	; 0x54
 8001130:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
				char pad = ' ';
 8001134:	2220      	movs	r2, #32
					pad = '0';
 8001136:	4643      	mov	r3, r8
				while (width-- > 0) {
 8001138:	4619      	mov	r1, r3
 800113a:	2900      	cmp	r1, #0
 800113c:	f103 33ff 	add.w	r3, r3, #4294967295	; 0xffffffff
 8001140:	dcec      	bgt.n	800111c <z_cbvprintf_impl+0x6b8>
 8001142:	4445      	add	r5, r8
 8001144:	1a6d      	subs	r5, r5, r1
 8001146:	4698      	mov	r8, r3
		if (sign != 0) {
 8001148:	b12e      	cbz	r6, 8001156 <z_cbvprintf_impl+0x6f2>
			OUTC(sign);
 800114a:	4659      	mov	r1, fp
 800114c:	4630      	mov	r0, r6
 800114e:	47c8      	blx	r9
 8001150:	2800      	cmp	r0, #0
 8001152:	dbec      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 8001154:	3501      	adds	r5, #1
			if (conv->altform_0c | conv->altform_0) {
 8001156:	f89d 3042 	ldrb.w	r3, [sp, #66]	; 0x42
 800115a:	06da      	lsls	r2, r3, #27
 800115c:	d401      	bmi.n	8001162 <z_cbvprintf_impl+0x6fe>
 800115e:	071b      	lsls	r3, r3, #28
 8001160:	d505      	bpl.n	800116e <z_cbvprintf_impl+0x70a>
				OUTC('0');
 8001162:	4659      	mov	r1, fp
 8001164:	2030      	movs	r0, #48	; 0x30
 8001166:	47c8      	blx	r9
 8001168:	2800      	cmp	r0, #0
 800116a:	dbe0      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 800116c:	3501      	adds	r5, #1
			if (conv->altform_0c) {
 800116e:	9b05      	ldr	r3, [sp, #20]
 8001170:	b133      	cbz	r3, 8001180 <z_cbvprintf_impl+0x71c>
				OUTC(conv->specifier);
 8001172:	f89d 0043 	ldrb.w	r0, [sp, #67]	; 0x43
 8001176:	4659      	mov	r1, fp
 8001178:	47c8      	blx	r9
 800117a:	2800      	cmp	r0, #0
 800117c:	dbd7      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 800117e:	3501      	adds	r5, #1
			while (pad_len-- > 0) {
 8001180:	9e04      	ldr	r6, [sp, #16]
 8001182:	442e      	add	r6, r5
 8001184:	e005      	b.n	8001192 <z_cbvprintf_impl+0x72e>
				OUTC('0');
 8001186:	4659      	mov	r1, fp
 8001188:	2030      	movs	r0, #48	; 0x30
 800118a:	47c8      	blx	r9
 800118c:	2800      	cmp	r0, #0
 800118e:	dbce      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 8001190:	3501      	adds	r5, #1
			while (pad_len-- > 0) {
 8001192:	1b73      	subs	r3, r6, r5
 8001194:	2b00      	cmp	r3, #0
 8001196:	dcf6      	bgt.n	8001186 <z_cbvprintf_impl+0x722>
			OUTS(bps, bpe);
 8001198:	4653      	mov	r3, sl
 800119a:	463a      	mov	r2, r7
 800119c:	4659      	mov	r1, fp
 800119e:	4648      	mov	r0, r9
 80011a0:	f003 fc93 	bl	8004aca <outs>
 80011a4:	2800      	cmp	r0, #0
 80011a6:	dbc2      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 80011a8:	4405      	add	r5, r0
		while (width > 0) {
 80011aa:	44a8      	add	r8, r5
 80011ac:	eba8 0305 	sub.w	r3, r8, r5
 80011b0:	2b00      	cmp	r3, #0
 80011b2:	f77f ae6a 	ble.w	8000e8a <z_cbvprintf_impl+0x426>
			OUTC(' ');
 80011b6:	4659      	mov	r1, fp
 80011b8:	2020      	movs	r0, #32
 80011ba:	47c8      	blx	r9
 80011bc:	2800      	cmp	r0, #0
 80011be:	dbb6      	blt.n	800112e <z_cbvprintf_impl+0x6ca>
 80011c0:	3501      	adds	r5, #1
			--width;
 80011c2:	e7f3      	b.n	80011ac <z_cbvprintf_impl+0x748>
 80011c4:	08005cd7 	.word	0x08005cd7

080011c8 <st_stm32f4_init>:
  * @rmtoll FLASH_ACR    ICEN          LL_FLASH_EnableInstCache
  * @retval None
  */
__STATIC_INLINE void LL_FLASH_EnableInstCache(void)
{
  SET_BIT(FLASH->ACR, FLASH_ACR_ICEN);
 80011c8:	4b0c      	ldr	r3, [pc, #48]	; (80011fc <st_stm32f4_init+0x34>)
 80011ca:	681a      	ldr	r2, [r3, #0]
 80011cc:	f442 7200 	orr.w	r2, r2, #512	; 0x200
 80011d0:	601a      	str	r2, [r3, #0]
  * @rmtoll FLASH_ACR    DCEN          LL_FLASH_EnableDataCache
  * @retval None
  */
__STATIC_INLINE void LL_FLASH_EnableDataCache(void)
{
  SET_BIT(FLASH->ACR, FLASH_ACR_DCEN);
 80011d2:	681a      	ldr	r2, [r3, #0]
 80011d4:	f442 6280 	orr.w	r2, r2, #1024	; 0x400
 80011d8:	601a      	str	r2, [r3, #0]
		:
		: "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	unsigned int tmp;

	__asm__ volatile(
 80011da:	f04f 0210 	mov.w	r2, #16
 80011de:	f3ef 8311 	mrs	r3, BASEPRI
 80011e2:	f382 8812 	msr	BASEPRI_MAX, r2
 80011e6:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
		"cpsie i;"
		"isb"
		: : : "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__asm__ volatile(
 80011ea:	f383 8811 	msr	BASEPRI, r3
 80011ee:	f3bf 8f6f 	isb	sy

	irq_unlock(key);

	/* Update CMSIS SystemCoreClock variable (HCLK) */
	/* At reset, system core clock is set to 16 MHz from HSI */
	SystemCoreClock = 16000000;
 80011f2:	4b03      	ldr	r3, [pc, #12]	; (8001200 <st_stm32f4_init+0x38>)
 80011f4:	4a03      	ldr	r2, [pc, #12]	; (8001204 <st_stm32f4_init+0x3c>)
 80011f6:	601a      	str	r2, [r3, #0]

	return 0;
}
 80011f8:	2000      	movs	r0, #0
 80011fa:	4770      	bx	lr
 80011fc:	40023c00 	.word	0x40023c00
 8001200:	20000038 	.word	0x20000038
 8001204:	00f42400 	.word	0x00f42400

08001208 <z_arm_cpu_idle_init>:
 * void z_arm_cpu_idle_init(void);
 */

SECTION_FUNC(TEXT, z_arm_cpu_idle_init)
#if defined(CONFIG_CPU_CORTEX_M)
	ldr	r1, =_SCB_SCR
 8001208:	4901      	ldr	r1, [pc, #4]	; (8001210 <z_arm_cpu_idle_init+0x8>)
	movs.n	r2, #_SCR_INIT_BITS
 800120a:	2210      	movs	r2, #16
	str	r2, [r1]
 800120c:	600a      	str	r2, [r1, #0]
#endif
	bx	lr
 800120e:	4770      	bx	lr
	ldr	r1, =_SCB_SCR
 8001210:	e000ed10 	.word	0xe000ed10

08001214 <arch_cpu_idle>:
	 * before entering low power state.
	 *
	 * Set PRIMASK before configuring BASEPRI to prevent interruption
	 * before wake-up.
	 */
	cpsid	i
 8001214:	b672      	cpsid	i

	/*
	 * Set wake-up interrupt priority to the lowest and synchronise to
	 * ensure that this is visible to the WFI instruction.
	 */
	eors.n	r0, r0
 8001216:	4040      	eors	r0, r0
	msr	BASEPRI, r0
 8001218:	f380 8811 	msr	BASEPRI, r0
	isb
 800121c:	f3bf 8f6f 	isb	sy

	/*
	 * Wait for all memory transactions to complete before entering low
	 * power state.
	 */
	dsb
 8001220:	f3bf 8f4f 	dsb	sy

	/* Enter low power state */
	wfi
 8001224:	bf30      	wfi

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
 8001226:	b662      	cpsie	i
	isb
 8001228:	f3bf 8f6f 	isb	sy

	bx	lr
 800122c:	4770      	bx	lr
 800122e:	bf00      	nop

08001230 <arch_irq_enable>:
#define REG_FROM_IRQ(irq) (irq / NUM_IRQS_PER_REG)
#define BIT_FROM_IRQ(irq) (irq % NUM_IRQS_PER_REG)

void arch_irq_enable(unsigned int irq)
{
	NVIC_EnableIRQ((IRQn_Type)irq);
 8001230:	b240      	sxtb	r0, r0
  \param [in]      IRQn  Device specific interrupt number.
  \note    IRQn must not be negative.
 */
__STATIC_INLINE void __NVIC_EnableIRQ(IRQn_Type IRQn)
{
  if ((int32_t)(IRQn) >= 0)
 8001232:	2800      	cmp	r0, #0
 8001234:	db07      	blt.n	8001246 <arch_irq_enable+0x16>
  {
    __COMPILER_BARRIER();
    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
 8001236:	4a04      	ldr	r2, [pc, #16]	; (8001248 <arch_irq_enable+0x18>)
 8001238:	0941      	lsrs	r1, r0, #5
 800123a:	2301      	movs	r3, #1
 800123c:	f000 001f 	and.w	r0, r0, #31
 8001240:	4083      	lsls	r3, r0
 8001242:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
}
 8001246:	4770      	bx	lr
 8001248:	e000e100 	.word	0xe000e100

0800124c <z_arm_irq_priority_set>:
 * The priority is verified if ASSERT_ON is enabled. The maximum number
 * of priority levels is a little complex, as there are some hardware
 * priority levels which are reserved.
 */
void z_arm_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
 800124c:	b538      	push	{r3, r4, r5, lr}
			prio = _EXC_ZERO_LATENCY_IRQS_PRIO;
		} else {
			/* Use caller supplied prio level as-is */
		}
	} else {
		prio += _IRQ_PRIO_OFFSET;
 800124e:	1c4b      	adds	r3, r1, #1
	/* The last priority level is also used by PendSV exception, but
	 * allow other interrupts to use the same level, even if it ends up
	 * affecting performance (can still be useful on systems with a
	 * reduced set of priorities, like Cortex-M0/M0+).
	 */
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
 8001250:	2b0f      	cmp	r3, #15
{
 8001252:	4604      	mov	r4, r0
 8001254:	460d      	mov	r5, r1
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
 8001256:	d90f      	bls.n	8001278 <z_arm_irq_priority_set+0x2c>
 8001258:	4a11      	ldr	r2, [pc, #68]	; (80012a0 <z_arm_irq_priority_set+0x54>)
 800125a:	4912      	ldr	r1, [pc, #72]	; (80012a4 <z_arm_irq_priority_set+0x58>)
 800125c:	4812      	ldr	r0, [pc, #72]	; (80012a8 <z_arm_irq_priority_set+0x5c>)
 800125e:	235b      	movs	r3, #91	; 0x5b
 8001260:	f003 fc51 	bl	8004b06 <assert_print>
 8001264:	4811      	ldr	r0, [pc, #68]	; (80012ac <z_arm_irq_priority_set+0x60>)
 8001266:	4629      	mov	r1, r5
 8001268:	230f      	movs	r3, #15
 800126a:	4622      	mov	r2, r4
 800126c:	f003 fc4b 	bl	8004b06 <assert_print>
 8001270:	480b      	ldr	r0, [pc, #44]	; (80012a0 <z_arm_irq_priority_set+0x54>)
 8001272:	215b      	movs	r1, #91	; 0x5b
 8001274:	f003 fc40 	bl	8004af8 <assert_post_action>
		 "invalid priority %d for %d irq! values must be less than %lu\n",
		 prio - _IRQ_PRIO_OFFSET, irq,
		 BIT(NUM_IRQ_PRIO_BITS) - (_IRQ_PRIO_OFFSET));
	NVIC_SetPriority((IRQn_Type)irq, prio);
 8001278:	b240      	sxtb	r0, r0
  \param [in]  priority  Priority to set.
  \note    The priority cannot be set for every processor exception.
 */
__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
{
  if ((int32_t)(IRQn) >= 0)
 800127a:	2800      	cmp	r0, #0
  {
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 800127c:	bfac      	ite	ge
 800127e:	f100 4060 	addge.w	r0, r0, #3758096384	; 0xe0000000
  }
  else
  {
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 8001282:	4a0b      	ldrlt	r2, [pc, #44]	; (80012b0 <z_arm_irq_priority_set+0x64>)
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 8001284:	ea4f 1303 	mov.w	r3, r3, lsl #4
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 8001288:	bfb8      	it	lt
 800128a:	f000 000f 	andlt.w	r0, r0, #15
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 800128e:	b2db      	uxtb	r3, r3
 8001290:	bfaa      	itet	ge
 8001292:	f500 4061 	addge.w	r0, r0, #57600	; 0xe100
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 8001296:	5413      	strblt	r3, [r2, r0]
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 8001298:	f880 3300 	strbge.w	r3, [r0, #768]	; 0x300
}
 800129c:	bd38      	pop	{r3, r4, r5, pc}
 800129e:	bf00      	nop
 80012a0:	08005cdd 	.word	0x08005cdd
 80012a4:	08005d13 	.word	0x08005d13
 80012a8:	08005ca7 	.word	0x08005ca7
 80012ac:	08005d2e 	.word	0x08005d2e
 80012b0:	e000ed14 	.word	0xe000ed14

080012b4 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
 80012b4:	bf30      	wfi
    b z_SysNmiOnReset
 80012b6:	f7ff bffd 	b.w	80012b4 <z_SysNmiOnReset>
 80012ba:	bf00      	nop

080012bc <z_arm_prep_c>:

#define VECTOR_ADDRESS ((uintptr_t)_vector_start)

static inline void relocate_vector_table(void)
{
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
 80012bc:	4a0f      	ldr	r2, [pc, #60]	; (80012fc <z_arm_prep_c+0x40>)
 *
 * This routine prepares for the execution of and runs C code.
 *
 */
void z_arm_prep_c(void)
{
 80012be:	b508      	push	{r3, lr}
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
 80012c0:	4b0f      	ldr	r3, [pc, #60]	; (8001300 <z_arm_prep_c+0x44>)
 80012c2:	f022 027f 	bic.w	r2, r2, #127	; 0x7f
 80012c6:	609a      	str	r2, [r3, #8]
  \details Acts as a special kind of Data Memory Barrier.
           It completes when all explicit memory accesses before this instruction complete.
 */
__STATIC_FORCEINLINE void __DSB(void)
{
  __ASM volatile ("dsb 0xF":::"memory");
 80012c8:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
 80012cc:	f3bf 8f6f 	isb	sy
	SCB->CPACR &= (~(CPACR_CP10_Msk | CPACR_CP11_Msk));
 80012d0:	f8d3 2088 	ldr.w	r2, [r3, #136]	; 0x88
 80012d4:	f422 0270 	bic.w	r2, r2, #15728640	; 0xf00000
 80012d8:	f8c3 2088 	str.w	r2, [r3, #136]	; 0x88
 */
__STATIC_FORCEINLINE uint32_t __get_CONTROL(void)
{
  uint32_t result;

  __ASM volatile ("MRS %0, control" : "=r" (result) );
 80012dc:	f3ef 8314 	mrs	r3, CONTROL
	__set_CONTROL(__get_CONTROL() & (~(CONTROL_FPCA_Msk)));
 80012e0:	f023 0304 	bic.w	r3, r3, #4
  \details Writes the given value to the Control Register.
  \param [in]    control  Control Register value to set
 */
__STATIC_FORCEINLINE void __set_CONTROL(uint32_t control)
{
  __ASM volatile ("MSR control, %0" : : "r" (control) : "memory");
 80012e4:	f383 8814 	msr	CONTROL, r3
  __ASM volatile ("isb 0xF":::"memory");
 80012e8:	f3bf 8f6f 	isb	sy
	relocate_vector_table();
#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
 80012ec:	f001 face 	bl	800288c <z_bss_zero>
	z_data_copy();
 80012f0:	f002 ff3c 	bl	800416c <z_data_copy>
#if ((defined(CONFIG_ARMV7_R) || defined(CONFIG_ARMV7_A)) && defined(CONFIG_INIT_STACKS))
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
 80012f4:	f000 fa1e 	bl	8001734 <z_arm_interrupt_init>
	z_cstart();
 80012f8:	f001 fb10 	bl	800291c <z_cstart>
 80012fc:	08000000 	.word	0x08000000
 8001300:	e000ed00 	.word	0xe000ed00

08001304 <arch_swap>:
 * as BASEPRI is not available.
 */
int arch_swap(unsigned int key)
{
	/* store off key and return value */
	_current->arch.basepri = key;
 8001304:	4a0a      	ldr	r2, [pc, #40]	; (8001330 <arch_swap+0x2c>)
	_current->arch.swap_return_value = _k_neg_eagain;
 8001306:	490b      	ldr	r1, [pc, #44]	; (8001334 <arch_swap+0x30>)
	_current->arch.basepri = key;
 8001308:	6893      	ldr	r3, [r2, #8]
	_current->arch.swap_return_value = _k_neg_eagain;
 800130a:	6809      	ldr	r1, [r1, #0]
 800130c:	f8c3 10ac 	str.w	r1, [r3, #172]	; 0xac

#if defined(CONFIG_CPU_CORTEX_M)
	/* set pending bit to make sure we will take a PendSV exception */
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
 8001310:	4909      	ldr	r1, [pc, #36]	; (8001338 <arch_swap+0x34>)
	_current->arch.basepri = key;
 8001312:	f8c3 00a8 	str.w	r0, [r3, #168]	; 0xa8
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
 8001316:	684b      	ldr	r3, [r1, #4]
 8001318:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
 800131c:	604b      	str	r3, [r1, #4]
 800131e:	2300      	movs	r3, #0
 8001320:	f383 8811 	msr	BASEPRI, r3
 8001324:	f3bf 8f6f 	isb	sy
#endif

	/* Context switch is performed here. Returning implies the
	 * thread has been context-switched-in again.
	 */
	return _current->arch.swap_return_value;
 8001328:	6893      	ldr	r3, [r2, #8]
}
 800132a:	f8d3 00ac 	ldr.w	r0, [r3, #172]	; 0xac
 800132e:	4770      	bx	lr
 8001330:	200007b8 	.word	0x200007b8
 8001334:	08005a34 	.word	0x08005a34
 8001338:	e000ed00 	.word	0xe000ed00

0800133c <z_arm_pendsv>:
    pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /* load _kernel into r1 and current k_thread into r2 */
    ldr r1, =_kernel
 800133c:	4913      	ldr	r1, [pc, #76]	; (800138c <z_arm_pendsv+0x50>)
    ldr r2, [r1, #_kernel_offset_to_current]
 800133e:	688a      	ldr	r2, [r1, #8]
    /* Store LSB of LR (EXC_RETURN) to the thread's 'mode' word. */
    strb lr, [r2, #_thread_offset_to_mode_exc_return]
#endif

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
 8001340:	f04f 0030 	mov.w	r0, #48	; 0x30
    add r0, r2
 8001344:	4410      	add	r0, r2

    /* save callee-saved + psp in thread */
#if defined(CONFIG_CPU_CORTEX_M)
    mrs ip, PSP
 8001346:	f3ef 8c09 	mrs	ip, PSP
    mov r6, r11
    mov r7, ip
    /* store r8-12 */
    stmea r0!, {r3-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    stmia r0, {v1-v8, ip}
 800134a:	e880 1ff0 	stmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}

    /* Protect the kernel state while we play with the thread lists */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
 800134e:	2010      	movs	r0, #16
    msr BASEPRI_MAX, r0
 8001350:	f380 8812 	msr	BASEPRI_MAX, r0
    isb /* Make the effect of disabling interrupts be realized immediately */
 8001354:	f3bf 8f6f 	isb	sy
     * the new thread is context-switched in since all decisions
     * to pend PendSV have been taken with the current kernel
     * state and this is what we're handling currently.
     */
#if defined(CONFIG_CPU_CORTEX_M)
    ldr v4, =_SCS_ICSR
 8001358:	4f0d      	ldr	r7, [pc, #52]	; (8001390 <z_arm_pendsv+0x54>)
    ldr v3, =_SCS_ICSR_UNPENDSV
 800135a:	f04f 6600 	mov.w	r6, #134217728	; 0x8000000
#endif

    /* _kernel is still in r1 */

    /* fetch the thread to run from the ready queue cache */
    ldr r2, [r1, #_kernel_offset_to_ready_q_cache]
 800135e:	698a      	ldr	r2, [r1, #24]

    str r2, [r1, #_kernel_offset_to_current]
 8001360:	608a      	str	r2, [r1, #8]
     * has been handled.
     */

    /* _SCS_ICSR is still in v4 and _SCS_ICSR_UNPENDSV in v3 */
#if defined(CONFIG_CPU_CORTEX_M)
    str v3, [v4, #0]
 8001362:	603e      	str	r6, [r7, #0]

    ldr r0, [r4]
    movs.n r3, #0
    str r3, [r4]
#else
    ldr r0, [r2, #_thread_offset_to_basepri]
 8001364:	f8d2 00a8 	ldr.w	r0, [r2, #168]	; 0xa8
    movs r3, #0
 8001368:	2300      	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
 800136a:	f8c2 30a8 	str.w	r3, [r2, #168]	; 0xa8
    /* restore r4-r7, go back 9*4 bytes to the start of the stored block */
    subs r0, #36
    ldmia r0!, {r4-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* restore BASEPRI for the incoming thread */
    msr BASEPRI, r0
 800136e:	f380 8811 	msr	BASEPRI, r0
    isb
#endif

#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
    /* Re-program dynamic memory map */
    push {r2,lr}
 8001372:	b504      	push	{r2, lr}
    mov r0, r2 /* _current thread */
 8001374:	4610      	mov	r0, r2
    bl z_arm_configure_dynamic_mpu_regions
 8001376:	f000 fa25 	bl	80017c4 <z_arm_configure_dynamic_mpu_regions>
    pop {r2,lr}
 800137a:	e8bd 4004 	ldmia.w	sp!, {r2, lr}
    isb

#endif

    /* load callee-saved + psp from thread */
    add r0, r2, #_thread_offset_to_callee_saved
 800137e:	f102 0030 	add.w	r0, r2, #48	; 0x30
    ldmia r0, {v1-v8, ip}
 8001382:	e890 1ff0 	ldmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
    msr PSP, ip
 8001386:	f38c 8809 	msr	PSP, ip

    /*
     * Cortex-M: return from PendSV exception
     * Cortex-R: return to the caller (z_arm_{exc,int}_exit, or z_arm_svc)
     */
    bx lr
 800138a:	4770      	bx	lr
    ldr r1, =_kernel
 800138c:	200007b8 	.word	0x200007b8
    ldr v4, =_SCS_ICSR
 8001390:	e000ed04 	.word	0xe000ed04

08001394 <z_arm_svc>:
  bne _stack_frame_endif
_stack_frame_msp:
  mrs r0, MSP
_stack_frame_endif:
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst lr, #_EXC_RETURN_SPSEL_Msk /* did we come from thread mode ? */
 8001394:	f01e 0f04 	tst.w	lr, #4
    ite eq  /* if zero (equal), came from handler mode */
 8001398:	bf0c      	ite	eq
        mrseq r0, MSP   /* handler mode, stack frame is on MSP */
 800139a:	f3ef 8008 	mrseq	r0, MSP
        mrsne r0, PSP   /* thread mode, stack frame is on PSP */
 800139e:	f3ef 8009 	mrsne	r0, PSP
#endif


    /* Figure out what SVC call number was invoked */

    ldr r1, [r0, #24]   /* grab address of PC from stack frame */
 80013a2:	6981      	ldr	r1, [r0, #24]
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    subs r1, r1, #2
    ldrb r1, [r1]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldrb r1, [r1, #-2]
 80013a4:	f811 1c02 	ldrb.w	r1, [r1, #-2]
#endif
    bne _oops

#endif /* CONFIG_USERSPACE */

    cmp r1, #2
 80013a8:	2902      	cmp	r1, #2
    beq _oops
 80013aa:	d0ff      	beq.n	80013ac <_oops>

080013ac <_oops>:
    /* exception return is done in z_arm_int_exit() */
    b z_arm_int_exit
#endif

_oops:
    push {r0, lr}
 80013ac:	b501      	push	{r0, lr}
    push {r1, r2}
    push {r4-r11}
    mov  r1, sp /* pointer to _callee_saved_t */
#endif /* CONFIG_ARMV7_M_ARMV8_M_MAINLINE */
#endif /* CONFIG_EXTRA_EXCEPTION_INFO */
    bl z_do_kernel_oops
 80013ae:	f003 fbbc 	bl	8004b2a <z_do_kernel_oops>
     * the MSP to its value prior to entering the function
     */
    add sp, #40
#endif /* CONFIG_ARMV7_M_ARMV8_M_MAINLINE */
#endif /* CONFIG_EXTRA_EXCEPTION_INFO */
    pop {r0, pc}
 80013b2:	bd01      	pop	{r0, pc}

080013b4 <arch_new_thread>:

#if defined(CONFIG_CPU_CORTEX_M)
	/* force ARM mode by clearing LSB of address */
	iframe->pc &= 0xfffffffe;
#endif
	iframe->a1 = (uint32_t)entry;
 80013b4:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe->a2 = (uint32_t)p1;
 80013b8:	9b00      	ldr	r3, [sp, #0]
 80013ba:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->pc &= 0xfffffffe;
 80013be:	490a      	ldr	r1, [pc, #40]	; (80013e8 <arch_new_thread+0x34>)
	iframe->a3 = (uint32_t)p2;
 80013c0:	9b01      	ldr	r3, [sp, #4]
 80013c2:	f842 3c18 	str.w	r3, [r2, #-24]
	iframe->a4 = (uint32_t)p3;
 80013c6:	9b02      	ldr	r3, [sp, #8]
 80013c8:	f842 3c14 	str.w	r3, [r2, #-20]
	iframe->pc &= 0xfffffffe;
 80013cc:	f021 0101 	bic.w	r1, r1, #1

#if defined(CONFIG_CPU_CORTEX_M)
	iframe->xpsr =
 80013d0:	f04f 7380 	mov.w	r3, #16777216	; 0x1000000
 80013d4:	f842 3c04 	str.w	r3, [r2, #-4]
	iframe->pc &= 0xfffffffe;
 80013d8:	f842 1c08 	str.w	r1, [r2, #-8]
		((uintptr_t)iframe - sizeof(struct __fpu_sf));
	memset(iframe, 0, sizeof(struct __fpu_sf));
#endif

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
 80013dc:	2300      	movs	r3, #0
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
 80013de:	3a20      	subs	r2, #32
	thread->callee_saved.psp = (uint32_t)iframe;
 80013e0:	6502      	str	r2, [r0, #80]	; 0x50
	thread->arch.basepri = 0;
 80013e2:	f8c0 30a8 	str.w	r3, [r0, #168]	; 0xa8
#endif
	/*
	 * initial values in all other registers/thread entries are
	 * irrelevant.
	 */
}
 80013e6:	4770      	bx	lr
 80013e8:	08004a2b 	.word	0x08004a2b

080013ec <z_check_thread_stack_fail>:
 *         thread stack corruption, otherwise return 0.
 */
uint32_t z_check_thread_stack_fail(const uint32_t fault_addr, const uint32_t psp)
{
#if defined(CONFIG_MULTITHREADING)
	const struct k_thread *thread = _current;
 80013ec:	4a0a      	ldr	r2, [pc, #40]	; (8001418 <z_check_thread_stack_fail+0x2c>)
{
 80013ee:	4603      	mov	r3, r0
	const struct k_thread *thread = _current;
 80013f0:	6890      	ldr	r0, [r2, #8]

	if (thread == NULL) {
 80013f2:	b178      	cbz	r0, 8001414 <z_check_thread_stack_fail+0x28>
			return thread->stack_info.start;
		}
	}
#else /* CONFIG_USERSPACE */
#if defined(CONFIG_MULTITHREADING)
	if (IS_MPU_GUARD_VIOLATION(thread->stack_info.start - guard_len,
 80013f4:	f113 0f16 	cmn.w	r3, #22
 80013f8:	f8d0 0098 	ldr.w	r0, [r0, #152]	; 0x98
 80013fc:	d005      	beq.n	800140a <z_check_thread_stack_fail+0x1e>
 80013fe:	f1a0 0240 	sub.w	r2, r0, #64	; 0x40
 8001402:	429a      	cmp	r2, r3
 8001404:	d805      	bhi.n	8001412 <z_check_thread_stack_fail+0x26>
 8001406:	4283      	cmp	r3, r0
 8001408:	d203      	bcs.n	8001412 <z_check_thread_stack_fail+0x26>
		return 0;
 800140a:	4281      	cmp	r1, r0
 800140c:	bf28      	it	cs
 800140e:	2000      	movcs	r0, #0
 8001410:	4770      	bx	lr
 8001412:	2000      	movs	r0, #0
	}
#endif
#endif /* CONFIG_USERSPACE */

	return 0;
}
 8001414:	4770      	bx	lr
 8001416:	bf00      	nop
 8001418:	200007b8 	.word	0x200007b8

0800141c <arch_switch_to_main_thread>:
#endif /* CONFIG_FPU */
}

void arch_switch_to_main_thread(struct k_thread *main_thread, char *stack_ptr,
				k_thread_entry_t _main)
{
 800141c:	b508      	push	{r3, lr}
	z_arm_prepare_switch_to_main();

	_current = main_thread;
 800141e:	4b09      	ldr	r3, [pc, #36]	; (8001444 <arch_switch_to_main_thread+0x28>)
 8001420:	6098      	str	r0, [r3, #8]
{
 8001422:	460d      	mov	r5, r1
 8001424:	4614      	mov	r4, r2
#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
	/*
	 * If stack protection is enabled, make sure to set it
	 * before jumping to thread entry function
	 */
	z_arm_configure_dynamic_mpu_regions(main_thread);
 8001426:	f000 f9cd 	bl	80017c4 <z_arm_configure_dynamic_mpu_regions>

	/*
	 * Set PSP to the highest address of the main stack
	 * before enabling interrupts and jumping to main.
	 */
	__asm__ volatile (
 800142a:	4620      	mov	r0, r4
 800142c:	f385 8809 	msr	PSP, r5
 8001430:	2100      	movs	r1, #0
 8001432:	b663      	cpsie	if
 8001434:	f381 8811 	msr	BASEPRI, r1
 8001438:	f3bf 8f6f 	isb	sy
 800143c:	2200      	movs	r2, #0
 800143e:	2300      	movs	r3, #0
 8001440:	f003 faf3 	bl	8004a2a <z_thread_entry>
	:
	: "r" (_main), "r" (stack_ptr)
	: "r0" /* not to be overwritten by msr PSP, %1 */
	);

	CODE_UNREACHABLE;
 8001444:	200007b8 	.word	0x200007b8

08001448 <_isr_wrapper>:
 *
 */
SECTION_FUNC(TEXT, _isr_wrapper)

#if defined(CONFIG_CPU_CORTEX_M)
	push {r0,lr}		/* r0, lr are now the first items on the stack */
 8001448:	b501      	push	{r0, lr}
#endif

#endif /* CONFIG_PM */

#if defined(CONFIG_CPU_CORTEX_M)
	mrs r0, IPSR	/* get exception number */
 800144a:	f3ef 8005 	mrs	r0, IPSR
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	ldr r1, =16
	subs r0, r1	/* get IRQ number */
	lsls r0, #3	/* table is 8-byte wide */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	sub r0, r0, #16	/* get IRQ number */
 800144e:	f1a0 0010 	sub.w	r0, r0, #16
	lsl r0, r0, #3	/* table is 8-byte wide */
 8001452:	ea4f 00c0 	mov.w	r0, r0, lsl #3
	lsl r1, r1, #3
	cmp r0, r1
	bge spurious_continue
#endif /* !CONFIG_CPU_CORTEX_M */

	ldr r1, =_sw_isr_table
 8001456:	4904      	ldr	r1, [pc, #16]	; (8001468 <_isr_wrapper+0x20>)
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
 8001458:	4401      	add	r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
 800145a:	c909      	ldmia	r1!, {r0, r3}
	blx r3		/* call ISR */
 800145c:	4798      	blx	r3

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	pop {r0, r3}
	mov lr, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	pop {r0, lr}
 800145e:	e8bd 4001 	ldmia.w	sp!, {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
 8001462:	4902      	ldr	r1, [pc, #8]	; (800146c <_isr_wrapper+0x24>)
	bx r1
 8001464:	4708      	bx	r1
 8001466:	0000      	.short	0x0000
	ldr r1, =_sw_isr_table
 8001468:	080054cc 	.word	0x080054cc
	ldr r1, =z_arm_int_exit
 800146c:	08001471 	.word	0x08001471

08001470 <z_arm_exc_exit>:
 */

SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)

#ifdef CONFIG_PREEMPT_ENABLED
	ldr r3, =_kernel
 8001470:	4b04      	ldr	r3, [pc, #16]	; (8001484 <_EXIT_EXC+0x2>)

	ldr r1, [r3, #_kernel_offset_to_current]
 8001472:	6899      	ldr	r1, [r3, #8]
	ldr r0, [r3, #_kernel_offset_to_ready_q_cache]
 8001474:	6998      	ldr	r0, [r3, #24]
	cmp r0, r1
 8001476:	4288      	cmp	r0, r1
	beq _EXIT_EXC
 8001478:	d003      	beq.n	8001482 <_EXIT_EXC>

	/* context switch required, pend the PendSV exception */
	ldr r1, =_SCS_ICSR
 800147a:	4903      	ldr	r1, [pc, #12]	; (8001488 <_EXIT_EXC+0x6>)
	ldr r2, =_SCS_ICSR_PENDSV
 800147c:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
	str r2, [r1]
 8001480:	600a      	str	r2, [r1, #0]

08001482 <_EXIT_EXC>:
#else
	pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_STACK_SENTINEL */

	bx lr
 8001482:	4770      	bx	lr
	ldr r3, =_kernel
 8001484:	200007b8 	.word	0x200007b8
	ldr r1, =_SCS_ICSR
 8001488:	e000ed04 	.word	0xe000ed04

0800148c <mem_manage_fault>:
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t mem_manage_fault(z_arch_esf_t *esf, int from_hard_fault,
			      bool *recoverable)
{
 800148c:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	uint32_t mmfar = -EINVAL;

	PR_FAULT_INFO("***** MPU FAULT *****");

	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
 800148e:	4b25      	ldr	r3, [pc, #148]	; (8001524 <mem_manage_fault+0x98>)
{
 8001490:	4614      	mov	r4, r2
	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
 8001492:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Stacking error (context area might be"
			" not valid)");
	}
	if ((SCB->CFSR & SCB_CFSR_MUNSTKERR_Msk) != 0) {
 8001494:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unstacking error");
	}
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
 8001496:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001498:	0792      	lsls	r2, r2, #30
{
 800149a:	4605      	mov	r5, r0
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
 800149c:	d52a      	bpl.n	80014f4 <mem_manage_fault+0x68>
		 * The MMFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another higher
		 * priority exception might change the MMFAR value.
		 */
		uint32_t temp = SCB->MMFAR;
 800149e:	6b58      	ldr	r0, [r3, #52]	; 0x34

		if ((SCB->CFSR & SCB_CFSR_MMARVALID_Msk) != 0) {
 80014a0:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 80014a2:	0616      	lsls	r6, r2, #24
 80014a4:	d526      	bpl.n	80014f4 <mem_manage_fault+0x68>
			mmfar = temp;
			PR_EXC("  MMFAR Address: 0x%x", mmfar);
			if (from_hard_fault != 0) {
 80014a6:	b119      	cbz	r1, 80014b0 <mem_manage_fault+0x24>
				/* clear SCB_MMAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_MMARVALID_Msk;
 80014a8:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 80014aa:	f022 0280 	bic.w	r2, r2, #128	; 0x80
 80014ae:	629a      	str	r2, [r3, #40]	; 0x28
			}
		}
	}
	if ((SCB->CFSR & SCB_CFSR_IACCVIOL_Msk) != 0) {
 80014b0:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Instruction Access Violation");
	}
#if defined(CONFIG_ARMV7_M_ARMV8_M_FP)
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
 80014b2:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	 * crossed into an area beyond the thread stack.]
	 *
	 * Data Access Violation errors may or may not be caused by
	 * thread stack overflows.
	 */
	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) ||
 80014b4:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 80014b6:	06d1      	lsls	r1, r2, #27
 80014b8:	d402      	bmi.n	80014c0 <mem_manage_fault+0x34>
		(SCB->CFSR & SCB_CFSR_DACCVIOL_Msk)) {
 80014ba:	6a9b      	ldr	r3, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) ||
 80014bc:	079a      	lsls	r2, r3, #30
 80014be:	d52e      	bpl.n	800151e <mem_manage_fault+0x92>
		 * not accompanied by a data access violation error (i.e.
		 * when stack overflows due to the exception entry frame
		 * stacking): z_check_thread_stack_fail() shall be able to
		 * handle the case of 'mmfar' holding the -EINVAL value.
		 */
		if (SCB->ICSR & SCB_ICSR_RETTOBASE_Msk) {
 80014c0:	4e18      	ldr	r6, [pc, #96]	; (8001524 <mem_manage_fault+0x98>)
 80014c2:	6873      	ldr	r3, [r6, #4]
 80014c4:	051b      	lsls	r3, r3, #20
 80014c6:	d52a      	bpl.n	800151e <mem_manage_fault+0x92>
			uint32_t min_stack_ptr = z_check_thread_stack_fail(mmfar,
 80014c8:	4629      	mov	r1, r5
 80014ca:	f7ff ff8f 	bl	80013ec <z_check_thread_stack_fail>
				((uint32_t) &esf[0]));

			if (min_stack_ptr) {
 80014ce:	b1a0      	cbz	r0, 80014fa <mem_manage_fault+0x6e>
  \details Assigns the given value to the Process Stack Pointer (PSP).
  \param [in]    topOfProcStack  Process Stack Pointer value to set
 */
__STATIC_FORCEINLINE void __set_PSP(uint32_t topOfProcStack)
{
  __ASM volatile ("MSR psp, %0" : : "r" (topOfProcStack) : );
 80014d0:	f380 8809 	msr	PSP, r0
				 * fatal error and a thread that corrupted its
				 * stack needs to be aborted.
				 */
				__set_PSP(min_stack_ptr);

				reason = K_ERR_STACK_CHK_FAIL;
 80014d4:	2002      	movs	r0, #2
	 * lazy stacking Memory Manage fault. At the time of writing, this
	 * can happen when printing.  If that's true, we should clear the
	 * pending flag in addition to the clearing the reason for the fault
	 */
#if defined(CONFIG_ARMV7_M_ARMV8_M_FP)
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
 80014d6:	4b13      	ldr	r3, [pc, #76]	; (8001524 <mem_manage_fault+0x98>)
 80014d8:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 80014da:	0692      	lsls	r2, r2, #26
		SCB->SHCSR &= ~SCB_SHCSR_MEMFAULTPENDED_Msk;
 80014dc:	bf42      	ittt	mi
 80014de:	6a5a      	ldrmi	r2, [r3, #36]	; 0x24
 80014e0:	f422 5200 	bicmi.w	r2, r2, #8192	; 0x2000
 80014e4:	625a      	strmi	r2, [r3, #36]	; 0x24
	}
#endif /* CONFIG_ARMV7_M_ARMV8_M_FP */

	/* clear MMFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;
 80014e6:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 80014e8:	f042 02ff 	orr.w	r2, r2, #255	; 0xff
 80014ec:	629a      	str	r2, [r3, #40]	; 0x28

	/* Assess whether system shall ignore/recover from this MPU fault. */
	*recoverable = memory_fault_recoverable(esf, true);
 80014ee:	2300      	movs	r3, #0
 80014f0:	7023      	strb	r3, [r4, #0]

	return reason;
}
 80014f2:	bd70      	pop	{r4, r5, r6, pc}
	uint32_t mmfar = -EINVAL;
 80014f4:	f06f 0015 	mvn.w	r0, #21
 80014f8:	e7da      	b.n	80014b0 <mem_manage_fault+0x24>
				__ASSERT(!(SCB->CFSR & SCB_CFSR_MSTKERR_Msk),
 80014fa:	6ab3      	ldr	r3, [r6, #40]	; 0x28
 80014fc:	06d9      	lsls	r1, r3, #27
 80014fe:	d50e      	bpl.n	800151e <mem_manage_fault+0x92>
 8001500:	4909      	ldr	r1, [pc, #36]	; (8001528 <mem_manage_fault+0x9c>)
 8001502:	4a0a      	ldr	r2, [pc, #40]	; (800152c <mem_manage_fault+0xa0>)
 8001504:	480a      	ldr	r0, [pc, #40]	; (8001530 <mem_manage_fault+0xa4>)
 8001506:	f44f 73ab 	mov.w	r3, #342	; 0x156
 800150a:	f003 fafc 	bl	8004b06 <assert_print>
 800150e:	4809      	ldr	r0, [pc, #36]	; (8001534 <mem_manage_fault+0xa8>)
 8001510:	f003 faf9 	bl	8004b06 <assert_print>
 8001514:	4805      	ldr	r0, [pc, #20]	; (800152c <mem_manage_fault+0xa0>)
 8001516:	f44f 71ab 	mov.w	r1, #342	; 0x156
 800151a:	f003 faed 	bl	8004af8 <assert_post_action>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
 800151e:	2000      	movs	r0, #0
 8001520:	e7d9      	b.n	80014d6 <mem_manage_fault+0x4a>
 8001522:	bf00      	nop
 8001524:	e000ed00 	.word	0xe000ed00
 8001528:	08005da8 	.word	0x08005da8
 800152c:	08005d6e 	.word	0x08005d6e
 8001530:	08005ca7 	.word	0x08005ca7
 8001534:	08005df2 	.word	0x08005df2

08001538 <bus_fault.constprop.0>:
{
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** BUS FAULT *****");

	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
 8001538:	4b0d      	ldr	r3, [pc, #52]	; (8001570 <bus_fault.constprop.0+0x38>)
 800153a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Stacking error");
	}
	if (SCB->CFSR & SCB_CFSR_UNSTKERR_Msk) {
 800153c:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unstacking error");
	}
	if (SCB->CFSR & SCB_CFSR_PRECISERR_Msk) {
 800153e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001540:	0592      	lsls	r2, r2, #22
 8001542:	d508      	bpl.n	8001556 <bus_fault.constprop.0+0x1e>
		 * The BFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another
		 * higher priority exception might change the BFAR value.
		 */
		STORE_xFAR(bfar, SCB->BFAR);
 8001544:	6b9a      	ldr	r2, [r3, #56]	; 0x38

		if ((SCB->CFSR & SCB_CFSR_BFARVALID_Msk) != 0) {
 8001546:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001548:	0412      	lsls	r2, r2, #16
 800154a:	d504      	bpl.n	8001556 <bus_fault.constprop.0+0x1e>
			PR_EXC("  BFAR Address: 0x%x", bfar);
			if (from_hard_fault != 0) {
 800154c:	b118      	cbz	r0, 8001556 <bus_fault.constprop.0+0x1e>
				/* clear SCB_CFSR_BFAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_BFARVALID_Msk;
 800154e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001550:	f422 4200 	bic.w	r2, r2, #32768	; 0x8000
 8001554:	629a      	str	r2, [r3, #40]	; 0x28
			}
		}
	}
	if (SCB->CFSR & SCB_CFSR_IMPRECISERR_Msk) {
 8001556:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Imprecise data bus error");
	}
	if ((SCB->CFSR & SCB_CFSR_IBUSERR_Msk) != 0) {
 8001558:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 800155a:	05d2      	lsls	r2, r2, #23
		SYSMPU->CESR &= ~sperr;
	}
#endif /* defined(CONFIG_ARM_MPU) && defined(CONFIG_CPU_HAS_NXP_MPU) */

	/* clear BFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
 800155c:	4a04      	ldr	r2, [pc, #16]	; (8001570 <bus_fault.constprop.0+0x38>)
	} else if (SCB->CFSR & SCB_CFSR_LSPERR_Msk) {
 800155e:	bf58      	it	pl
 8001560:	6a9b      	ldrpl	r3, [r3, #40]	; 0x28
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
 8001562:	6a93      	ldr	r3, [r2, #40]	; 0x28

	*recoverable = memory_fault_recoverable(esf, true);
 8001564:	2000      	movs	r0, #0
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
 8001566:	f443 437f 	orr.w	r3, r3, #65280	; 0xff00
 800156a:	6293      	str	r3, [r2, #40]	; 0x28
	*recoverable = memory_fault_recoverable(esf, true);
 800156c:	7008      	strb	r0, [r1, #0]

	return reason;
}
 800156e:	4770      	bx	lr
 8001570:	e000ed00 	.word	0xe000ed00

08001574 <z_arm_fault>:
 * @param callee_regs Callee-saved registers (R4-R11, PSP)
 *
 */
void z_arm_fault(uint32_t msp, uint32_t psp, uint32_t exc_return,
	_callee_saved_t *callee_regs)
{
 8001574:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
 8001576:	4b5e      	ldr	r3, [pc, #376]	; (80016f0 <z_arm_fault+0x17c>)
 8001578:	685b      	ldr	r3, [r3, #4]
{
 800157a:	b08a      	sub	sp, #40	; 0x28
 800157c:	4605      	mov	r5, r0
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
 800157e:	f3c3 0308 	ubfx	r3, r3, #0, #9
 8001582:	2600      	movs	r6, #0
 8001584:	f386 8811 	msr	BASEPRI, r6
 8001588:	f3bf 8f6f 	isb	sy
	if ((exc_return & EXC_RETURN_INDICATOR_PREFIX) !=
 800158c:	f002 407f 	and.w	r0, r2, #4278190080	; 0xff000000
 8001590:	f1b0 4f7f 	cmp.w	r0, #4278190080	; 0xff000000
 8001594:	d108      	bne.n	80015a8 <z_arm_fault+0x34>
	if ((exc_return & EXC_RETURN_MODE_THREAD) &&
 8001596:	f002 000c 	and.w	r0, r2, #12
 800159a:	2808      	cmp	r0, #8
 800159c:	d004      	beq.n	80015a8 <z_arm_fault+0x34>
		if (exc_return & EXC_RETURN_MODE_THREAD) {
 800159e:	0710      	lsls	r0, r2, #28
			ptr_esf =  (z_arch_esf_t *)psp;
 80015a0:	bf4c      	ite	mi
 80015a2:	460d      	movmi	r5, r1
			*nested_exc = true;
 80015a4:	2601      	movpl	r6, #1

	/* Retrieve the Exception Stack Frame (ESF) to be supplied
	 * as argument to the remainder of the fault handling process.
	 */
	 esf = get_esf(msp, psp, exc_return, &nested_exc);
	__ASSERT(esf != NULL,
 80015a6:	b975      	cbnz	r5, 80015c6 <z_arm_fault+0x52>
 80015a8:	4952      	ldr	r1, [pc, #328]	; (80016f4 <z_arm_fault+0x180>)
 80015aa:	4a53      	ldr	r2, [pc, #332]	; (80016f8 <z_arm_fault+0x184>)
 80015ac:	4853      	ldr	r0, [pc, #332]	; (80016fc <z_arm_fault+0x188>)
 80015ae:	f44f 6384 	mov.w	r3, #1056	; 0x420
 80015b2:	f003 faa8 	bl	8004b06 <assert_print>
 80015b6:	4852      	ldr	r0, [pc, #328]	; (8001700 <z_arm_fault+0x18c>)
 80015b8:	f003 faa5 	bl	8004b06 <assert_print>
 80015bc:	f44f 6184 	mov.w	r1, #1056	; 0x420
			__ASSERT(0,
 80015c0:	484d      	ldr	r0, [pc, #308]	; (80016f8 <z_arm_fault+0x184>)
 80015c2:	f003 fa99 	bl	8004af8 <assert_post_action>
	*recoverable = false;
 80015c6:	2200      	movs	r2, #0
	switch (fault) {
 80015c8:	3b03      	subs	r3, #3
	*recoverable = false;
 80015ca:	f88d 2007 	strb.w	r2, [sp, #7]
	switch (fault) {
 80015ce:	2b03      	cmp	r3, #3
 80015d0:	d84b      	bhi.n	800166a <z_arm_fault+0xf6>
 80015d2:	e8df f003 	tbb	[pc, r3]
 80015d6:	7d02      	.short	0x7d02
 80015d8:	8581      	.short	0x8581
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
 80015da:	4b45      	ldr	r3, [pc, #276]	; (80016f0 <z_arm_fault+0x17c>)
 80015dc:	6ada      	ldr	r2, [r3, #44]	; 0x2c
 80015de:	0791      	lsls	r1, r2, #30
 80015e0:	d443      	bmi.n	800166a <z_arm_fault+0xf6>
	} else if ((SCB->HFSR & SCB_HFSR_DEBUGEVT_Msk) != 0) {
 80015e2:	6ada      	ldr	r2, [r3, #44]	; 0x2c
 80015e4:	2a00      	cmp	r2, #0
 80015e6:	db40      	blt.n	800166a <z_arm_fault+0xf6>
	} else if ((SCB->HFSR & SCB_HFSR_FORCED_Msk) != 0) {
 80015e8:	6ada      	ldr	r2, [r3, #44]	; 0x2c
 80015ea:	0052      	lsls	r2, r2, #1
 80015ec:	d563      	bpl.n	80016b6 <z_arm_fault+0x142>
	SCB->CCR |= SCB_CCR_BFHFNMIGN_Msk;
 80015ee:	695a      	ldr	r2, [r3, #20]
	uint16_t *ret_addr = (uint16_t *)esf->basic.pc;
 80015f0:	69a9      	ldr	r1, [r5, #24]
	SCB->CCR |= SCB_CCR_BFHFNMIGN_Msk;
 80015f2:	f442 7280 	orr.w	r2, r2, #256	; 0x100
 80015f6:	615a      	str	r2, [r3, #20]
  __ASM volatile ("dsb 0xF":::"memory");
 80015f8:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
 80015fc:	f3bf 8f6f 	isb	sy
	SCB->CCR &= ~SCB_CCR_BFHFNMIGN_Msk;
 8001600:	695a      	ldr	r2, [r3, #20]
	uint16_t fault_insn = *(ret_addr - 1);
 8001602:	f831 1c02 	ldrh.w	r1, [r1, #-2]
	SCB->CCR &= ~SCB_CCR_BFHFNMIGN_Msk;
 8001606:	f422 7280 	bic.w	r2, r2, #256	; 0x100
 800160a:	615a      	str	r2, [r3, #20]
  __ASM volatile ("dsb 0xF":::"memory");
 800160c:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
 8001610:	f3bf 8f6f 	isb	sy
	if (((fault_insn & 0xff00) == _SVC_OPCODE) &&
 8001614:	f64d 7202 	movw	r2, #57090	; 0xdf02
 8001618:	4291      	cmp	r1, r2
 800161a:	d101      	bne.n	8001620 <z_arm_fault+0xac>
			reason = esf->basic.r0;
 800161c:	682c      	ldr	r4, [r5, #0]
 800161e:	e025      	b.n	800166c <z_arm_fault+0xf8>
		} else if ((SCB->CFSR & SCB_CFSR_MEMFAULTSR_Msk) != 0) {
 8001620:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001622:	b2d2      	uxtb	r2, r2
 8001624:	b13a      	cbz	r2, 8001636 <z_arm_fault+0xc2>
			reason = mem_manage_fault(esf, 1, recoverable);
 8001626:	f10d 0207 	add.w	r2, sp, #7
 800162a:	2101      	movs	r1, #1
		reason = mem_manage_fault(esf, 0, recoverable);
 800162c:	4628      	mov	r0, r5
 800162e:	f7ff ff2d 	bl	800148c <mem_manage_fault>
 8001632:	4604      	mov	r4, r0
		break;
 8001634:	e01a      	b.n	800166c <z_arm_fault+0xf8>
		} else if ((SCB->CFSR & SCB_CFSR_BUSFAULTSR_Msk) != 0) {
 8001636:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001638:	f412 4f7f 	tst.w	r2, #65280	; 0xff00
 800163c:	d005      	beq.n	800164a <z_arm_fault+0xd6>
			reason = bus_fault(esf, 1, recoverable);
 800163e:	f10d 0107 	add.w	r1, sp, #7
 8001642:	2001      	movs	r0, #1
		reason = bus_fault(esf, 0, recoverable);
 8001644:	f7ff ff78 	bl	8001538 <bus_fault.constprop.0>
 8001648:	e7f3      	b.n	8001632 <z_arm_fault+0xbe>
		} else if ((SCB->CFSR & SCB_CFSR_USGFAULTSR_Msk) != 0) {
 800164a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 800164c:	f5b2 3f80 	cmp.w	r2, #65536	; 0x10000
 8001650:	d324      	bcc.n	800169c <z_arm_fault+0x128>
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
 8001652:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_UNALIGNED_Msk) != 0) {
 8001654:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_NOCP_Msk) != 0) {
 8001656:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_INVPC_Msk) != 0) {
 8001658:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_INVSTATE_Msk) != 0) {
 800165a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_UNDEFINSTR_Msk) != 0) {
 800165c:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
 800165e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
 8001660:	ea6f 4202 	mvn.w	r2, r2, lsl #16
 8001664:	ea6f 4212 	mvn.w	r2, r2, lsr #16
 8001668:	629a      	str	r2, [r3, #40]	; 0x28
	*nested_exc = false;
 800166a:	2400      	movs	r4, #0
#ifdef CONFIG_DEBUG_COREDUMP
	z_arm_coredump_fault_sp = POINTER_TO_UINT(esf);
#endif

	reason = fault_handle(esf, fault, &recoverable);
	if (recoverable) {
 800166c:	f89d 3007 	ldrb.w	r3, [sp, #7]
 8001670:	b993      	cbnz	r3, 8001698 <z_arm_fault+0x124>
		return;
	}

	/* Copy ESF */
#if !defined(CONFIG_EXTRA_EXCEPTION_INFO)
	memcpy(&esf_copy, esf, sizeof(z_arch_esf_t));
 8001672:	2220      	movs	r2, #32
 8001674:	4629      	mov	r1, r5
 8001676:	a802      	add	r0, sp, #8
 8001678:	f003 fa8a 	bl	8004b90 <memcpy>
	/* Overwrite stacked IPSR to mark a nested exception,
	 * or a return to Thread mode. Note that this may be
	 * required, if the retrieved ESF contents are invalid
	 * due to, for instance, a stacking error.
	 */
	if (nested_exc) {
 800167c:	9b09      	ldr	r3, [sp, #36]	; 0x24
 800167e:	b38e      	cbz	r6, 80016e4 <z_arm_fault+0x170>
		if ((esf_copy.basic.xpsr & IPSR_ISR_Msk) == 0) {
 8001680:	f3c3 0208 	ubfx	r2, r3, #0, #9
 8001684:	b922      	cbnz	r2, 8001690 <z_arm_fault+0x11c>
			esf_copy.basic.xpsr |= IPSR_ISR_Msk;
 8001686:	ea6f 2353 	mvn.w	r3, r3, lsr #9
 800168a:	ea6f 2343 	mvn.w	r3, r3, lsl #9
		}
	} else {
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
 800168e:	9309      	str	r3, [sp, #36]	; 0x24
	}

	z_arm_fatal_error(reason, &esf_copy);
 8001690:	a902      	add	r1, sp, #8
 8001692:	4620      	mov	r0, r4
 8001694:	f003 fa47 	bl	8004b26 <z_arm_fatal_error>
}
 8001698:	b00a      	add	sp, #40	; 0x28
 800169a:	bd70      	pop	{r4, r5, r6, pc}
			__ASSERT(0,
 800169c:	4919      	ldr	r1, [pc, #100]	; (8001704 <z_arm_fault+0x190>)
 800169e:	4a16      	ldr	r2, [pc, #88]	; (80016f8 <z_arm_fault+0x184>)
 80016a0:	4816      	ldr	r0, [pc, #88]	; (80016fc <z_arm_fault+0x188>)
 80016a2:	f240 23f2 	movw	r3, #754	; 0x2f2
 80016a6:	f003 fa2e 	bl	8004b06 <assert_print>
 80016aa:	4817      	ldr	r0, [pc, #92]	; (8001708 <z_arm_fault+0x194>)
 80016ac:	f003 fa2b 	bl	8004b06 <assert_print>
 80016b0:	f240 21f2 	movw	r1, #754	; 0x2f2
 80016b4:	e784      	b.n	80015c0 <z_arm_fault+0x4c>
		__ASSERT(0,
 80016b6:	4913      	ldr	r1, [pc, #76]	; (8001704 <z_arm_fault+0x190>)
 80016b8:	4a0f      	ldr	r2, [pc, #60]	; (80016f8 <z_arm_fault+0x184>)
 80016ba:	4810      	ldr	r0, [pc, #64]	; (80016fc <z_arm_fault+0x188>)
 80016bc:	f240 23f6 	movw	r3, #758	; 0x2f6
 80016c0:	f003 fa21 	bl	8004b06 <assert_print>
 80016c4:	4811      	ldr	r0, [pc, #68]	; (800170c <z_arm_fault+0x198>)
 80016c6:	f003 fa1e 	bl	8004b06 <assert_print>
 80016ca:	f240 21f6 	movw	r1, #758	; 0x2f6
 80016ce:	e777      	b.n	80015c0 <z_arm_fault+0x4c>
		reason = mem_manage_fault(esf, 0, recoverable);
 80016d0:	f10d 0207 	add.w	r2, sp, #7
 80016d4:	2100      	movs	r1, #0
 80016d6:	e7a9      	b.n	800162c <z_arm_fault+0xb8>
		reason = bus_fault(esf, 0, recoverable);
 80016d8:	f10d 0107 	add.w	r1, sp, #7
 80016dc:	2000      	movs	r0, #0
 80016de:	e7b1      	b.n	8001644 <z_arm_fault+0xd0>
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
 80016e0:	4b03      	ldr	r3, [pc, #12]	; (80016f0 <z_arm_fault+0x17c>)
 80016e2:	e7b6      	b.n	8001652 <z_arm_fault+0xde>
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
 80016e4:	f423 73ff 	bic.w	r3, r3, #510	; 0x1fe
 80016e8:	f023 0301 	bic.w	r3, r3, #1
 80016ec:	e7cf      	b.n	800168e <z_arm_fault+0x11a>
 80016ee:	bf00      	nop
 80016f0:	e000ed00 	.word	0xe000ed00
 80016f4:	08005e15 	.word	0x08005e15
 80016f8:	08005d6e 	.word	0x08005d6e
 80016fc:	08005ca7 	.word	0x08005ca7
 8001700:	08005e28 	.word	0x08005e28
 8001704:	080064f9 	.word	0x080064f9
 8001708:	08005e66 	.word	0x08005e66
 800170c:	08005e8a 	.word	0x08005e8a

08001710 <z_arm_fault_init>:
 */
void z_arm_fault_init(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	SCB->CCR |= SCB_CCR_DIV_0_TRP_Msk;
 8001710:	4a02      	ldr	r2, [pc, #8]	; (800171c <z_arm_fault_init+0xc>)
 8001712:	6953      	ldr	r3, [r2, #20]
 8001714:	f043 0310 	orr.w	r3, r3, #16
 8001718:	6153      	str	r3, [r2, #20]
	SCB->CCR |= SCB_CCR_STKOFHFNMIGN_Msk;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
#ifdef CONFIG_TRAP_UNALIGNED_ACCESS
	SCB->CCR |= SCB_CCR_UNALIGN_TRP_Msk;
#endif /* CONFIG_TRAP_UNALIGNED_ACCESS */
}
 800171a:	4770      	bx	lr
 800171c:	e000ed00 	.word	0xe000ed00

08001720 <z_arm_bus_fault>:
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
SECTION_SUBSEC_FUNC(TEXT,__fault,z_arm_exc_spurious)

	mrs r0, MSP
 8001720:	f3ef 8008 	mrs	r0, MSP
	mrs r1, PSP
 8001724:	f3ef 8109 	mrs	r1, PSP
	push {r0, lr}
 8001728:	b501      	push	{r0, lr}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	push {r4-r11}
#endif
	mov  r3, sp /* pointer to _callee_saved_t */
#endif /* CONFIG_EXTRA_EXCEPTION_INFO */
	mov r2, lr /* EXC_RETURN */
 800172a:	4672      	mov	r2, lr
	bl z_arm_fault
 800172c:	f7ff ff22 	bl	8001574 <z_arm_fault>
	 * in this routine. Therefore, we can just reset
	 * the MSP to its value prior to entering the function
	 */
	add sp, #40
#endif
	pop {r0, pc}
 8001730:	bd01      	pop	{r0, pc}
 8001732:	bf00      	nop

08001734 <z_arm_interrupt_init>:
 8001734:	4804      	ldr	r0, [pc, #16]	; (8001748 <z_arm_interrupt_init+0x14>)
 *
 */

void z_arm_interrupt_init(void)
{
	int irq = 0;
 8001736:	2300      	movs	r3, #0
 8001738:	2110      	movs	r1, #16
 800173a:	18c2      	adds	r2, r0, r3

	for (; irq < CONFIG_NUM_IRQS; irq++) {
 800173c:	3301      	adds	r3, #1
 800173e:	2b56      	cmp	r3, #86	; 0x56
 8001740:	f882 1300 	strb.w	r1, [r2, #768]	; 0x300
 8001744:	d1f9      	bne.n	800173a <z_arm_interrupt_init+0x6>
		NVIC_SetPriority((IRQn_Type)irq, _IRQ_PRIO_OFFSET);
	}
}
 8001746:	4770      	bx	lr
 8001748:	e000e100 	.word	0xe000e100

0800174c <__start>:
 */
SECTION_SUBSEC_FUNC(TEXT,_reset_section,__start)

#if defined(CONFIG_DEBUG_THREAD_INFO)
    /* Clear z_sys_post_kernel flag for RTOS aware debuggers */
    movs.n r0, #0
 800174c:	2000      	movs	r0, #0
    ldr r1, =z_sys_post_kernel
 800174e:	490a      	ldr	r1, [pc, #40]	; (8001778 <__start+0x2c>)
    strb r0, [r1]
 8001750:	7008      	strb	r0, [r1, #0]

    /* lock interrupts: will get unlocked when switch to main task */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
 8001752:	2010      	movs	r0, #16
    msr BASEPRI, r0
 8001754:	f380 8811 	msr	BASEPRI, r0

    /*
     * Set PSP and use it to boot without using MSP, so that it
     * gets set to z_interrupt_stacks during initialization.
     */
    ldr r0, =z_interrupt_stacks
 8001758:	4808      	ldr	r0, [pc, #32]	; (800177c <__start+0x30>)
    ldr r1, =CONFIG_ISR_STACK_SIZE + MPU_GUARD_ALIGN_AND_SIZE
 800175a:	f44f 6104 	mov.w	r1, #2112	; 0x840
    adds r0, r0, r1
 800175e:	1840      	adds	r0, r0, r1
    msr PSP, r0
 8001760:	f380 8809 	msr	PSP, r0
    mrs r0, CONTROL
 8001764:	f3ef 8014 	mrs	r0, CONTROL
    movs r1, #2
 8001768:	2102      	movs	r1, #2
    orrs r0, r1 /* CONTROL_SPSEL_Msk */
 800176a:	4308      	orrs	r0, r1
    msr CONTROL, r0
 800176c:	f380 8814 	msr	CONTROL, r0
    /*
     * When changing the stack pointer, software must use an ISB instruction
     * immediately after the MSR instruction. This ensures that instructions
     * after the ISB instruction execute using the new stack pointer.
     */
    isb
 8001770:	f3bf 8f6f 	isb	sy
    /*
     * 'bl' jumps the furthest of the branch instructions that are
     * supported on all platforms. So it is used when jumping to z_arm_prep_c
     * (even though we do not intend to return).
     */
    bl z_arm_prep_c
 8001774:	f7ff fda2 	bl	80012bc <z_arm_prep_c>
    ldr r1, =z_sys_post_kernel
 8001778:	20000809 	.word	0x20000809
    ldr r0, =z_interrupt_stacks
 800177c:	200039c0 	.word	0x200039c0

08001780 <z_impl_k_thread_abort>:
#include <zephyr/wait_q.h>
#include <zephyr/sys/__assert.h>

void z_impl_k_thread_abort(k_tid_t thread)
{
	if (_current == thread) {
 8001780:	4b08      	ldr	r3, [pc, #32]	; (80017a4 <z_impl_k_thread_abort+0x24>)
 8001782:	689b      	ldr	r3, [r3, #8]
 8001784:	4283      	cmp	r3, r0
 8001786:	d10b      	bne.n	80017a0 <z_impl_k_thread_abort+0x20>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
 8001788:	f3ef 8305 	mrs	r3, IPSR
		if (arch_is_in_isr()) {
 800178c:	b143      	cbz	r3, 80017a0 <z_impl_k_thread_abort+0x20>
			 * should no longer run after we return, so
			 * Trigger PendSV, in case we are in one of the
			 * situations where the isr check is true but there
			 * is not an implicit scheduler invocation.
			 */
			SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
 800178e:	4b06      	ldr	r3, [pc, #24]	; (80017a8 <z_impl_k_thread_abort+0x28>)
 8001790:	685a      	ldr	r2, [r3, #4]
 8001792:	f042 5280 	orr.w	r2, r2, #268435456	; 0x10000000
 8001796:	605a      	str	r2, [r3, #4]
			/* Clear any system calls that may be pending
			 * as they have a higher priority than the PendSV
			 * handler and will check the stack of the thread
			 * being aborted.
			 */
			SCB->SHCSR &= ~SCB_SHCSR_SVCALLPENDED_Msk;
 8001798:	6a5a      	ldr	r2, [r3, #36]	; 0x24
 800179a:	f422 4200 	bic.w	r2, r2, #32768	; 0x8000
 800179e:	625a      	str	r2, [r3, #36]	; 0x24
		}
	}

	z_thread_abort(thread);
 80017a0:	f002 bc18 	b.w	8003fd4 <z_thread_abort>
 80017a4:	200007b8 	.word	0x200007b8
 80017a8:	e000ed00 	.word	0xe000ed00

080017ac <z_arm_configure_static_mpu_regions>:
	 * into account the unused SRAM area, as well.
	 */
#ifdef CONFIG_AARCH32_ARMV8_R
	arm_core_mpu_disable();
#endif
	arm_core_mpu_configure_static_mpu_regions(static_regions,
 80017ac:	4b02      	ldr	r3, [pc, #8]	; (80017b8 <z_arm_configure_static_mpu_regions+0xc>)
 80017ae:	4a03      	ldr	r2, [pc, #12]	; (80017bc <z_arm_configure_static_mpu_regions+0x10>)
 80017b0:	4803      	ldr	r0, [pc, #12]	; (80017c0 <z_arm_configure_static_mpu_regions+0x14>)
 80017b2:	2101      	movs	r1, #1
 80017b4:	f000 b872 	b.w	800189c <arm_core_mpu_configure_static_mpu_regions>
 80017b8:	20020000 	.word	0x20020000
 80017bc:	20000000 	.word	0x20000000
 80017c0:	08005870 	.word	0x08005870

080017c4 <z_arm_configure_dynamic_mpu_regions>:
#endif /* CONFIG_USERSPACE */
	{
		/* A supervisor thread only has the normal thread stack to
		 * protect with a stack guard.
		 */
		guard_start = thread->stack_info.start - guard_size;
 80017c4:	f8d0 2098 	ldr.w	r2, [r0, #152]	; 0x98
	}

	__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
		"Out-of-bounds error for dynamic region map.");

	dynamic_regions[region_num].start = guard_start;
 80017c8:	4b05      	ldr	r3, [pc, #20]	; (80017e0 <z_arm_configure_dynamic_mpu_regions+0x1c>)
		guard_start = thread->stack_info.start - guard_size;
 80017ca:	3a40      	subs	r2, #64	; 0x40
	dynamic_regions[region_num].start = guard_start;
 80017cc:	601a      	str	r2, [r3, #0]
	dynamic_regions[region_num].size = guard_size;
	dynamic_regions[region_num].attr = K_MEM_PARTITION_P_RO_U_NA;
 80017ce:	4a05      	ldr	r2, [pc, #20]	; (80017e4 <z_arm_configure_dynamic_mpu_regions+0x20>)
 80017d0:	2140      	movs	r1, #64	; 0x40
 80017d2:	e9c3 1201 	strd	r1, r2, [r3, #4]

	/* Configure the dynamic MPU regions */
#ifdef CONFIG_AARCH32_ARMV8_R
	arm_core_mpu_disable();
#endif
	arm_core_mpu_configure_dynamic_mpu_regions(dynamic_regions,
 80017d6:	4618      	mov	r0, r3
 80017d8:	2101      	movs	r1, #1
 80017da:	f000 b885 	b.w	80018e8 <arm_core_mpu_configure_dynamic_mpu_regions>
 80017de:	bf00      	nop
 80017e0:	20000660 	.word	0x20000660
 80017e4:	150b0000 	.word	0x150b0000

080017e8 <mpu_configure_regions>:
 * sanity check of the memory regions to be programmed.
 */
static int mpu_configure_regions(const struct z_arm_mpu_partition
	regions[], uint8_t regions_num, uint8_t start_reg_index,
	bool do_sanity_check)
{
 80017e8:	b5f0      	push	{r4, r5, r6, r7, lr}
#endif /* CPU_CORTEX_M0PLUS | CPU_CORTEX_M3 | CPU_CORTEX_M4 */
}

static inline void set_region_number(uint32_t index)
{
	MPU->RNR = index;
 80017ea:	4e20      	ldr	r6, [pc, #128]	; (800186c <mpu_configure_regions+0x84>)
	int i;
	int reg_index = start_reg_index;

	for (i = 0; i < regions_num; i++) {
 80017ec:	2500      	movs	r5, #0
 80017ee:	428d      	cmp	r5, r1
 80017f0:	da39      	bge.n	8001866 <mpu_configure_regions+0x7e>
		if (regions[i].size == 0U) {
 80017f2:	6844      	ldr	r4, [r0, #4]
 80017f4:	b374      	cbz	r4, 8001854 <mpu_configure_regions+0x6c>
			continue;
		}
		/* Non-empty region. */

		if (do_sanity_check &&
 80017f6:	b153      	cbz	r3, 800180e <mpu_configure_regions+0x26>
	 * and greater or equal to the minimum
	 * MPU region size. Start address of the
	 * partition must align with size.
	 */
	int partition_is_valid =
		((part->size & (part->size - 1U)) == 0U)
 80017f8:	f104 3cff 	add.w	ip, r4, #4294967295	; 0xffffffff
		&&
		(part->size >= CONFIG_ARM_MPU_REGION_MIN_ALIGN_AND_SIZE)
		&&
 80017fc:	ea14 0f0c 	tst.w	r4, ip
 8001800:	d12f      	bne.n	8001862 <mpu_configure_regions+0x7a>
		&&
 8001802:	2c1f      	cmp	r4, #31
 8001804:	d92d      	bls.n	8001862 <mpu_configure_regions+0x7a>
		((part->start & (part->size - 1U)) == 0U);
 8001806:	6807      	ldr	r7, [r0, #0]
		&&
 8001808:	ea1c 0f07 	tst.w	ip, r7
 800180c:	d129      	bne.n	8001862 <mpu_configure_regions+0x7a>
 * to that power-of-two value.
 */
static inline uint32_t size_to_mpu_rasr_size(uint32_t size)
{
	/* The minimal supported region size is 32 bytes */
	if (size <= 32U) {
 800180e:	2c20      	cmp	r4, #32
	region_conf.base = new_region->start;
 8001810:	6807      	ldr	r7, [r0, #0]
#if defined(CONFIG_CPU_AARCH32_CORTEX_R)
	(void) size;

	p_attr->rasr = attr->rasr_attr;
#else
	p_attr->rasr = attr->rasr_attr | size_to_mpu_rasr_size(size);
 8001812:	f8d0 c008 	ldr.w	ip, [r0, #8]
				(!mpu_partition_is_valid(&regions[i]))) {
			LOG_ERR("Partition %u: sanity check failed.", i);
			return -EINVAL;
		}

		reg_index = mpu_configure_region(reg_index, &regions[i]);
 8001816:	fa5f fe82 	uxtb.w	lr, r2
	if (size <= 32U) {
 800181a:	d91e      	bls.n	800185a <mpu_configure_regions+0x72>
	if (size > (1UL << 31)) {
 800181c:	f1b4 4f00 	cmp.w	r4, #2147483648	; 0x80000000
 8001820:	d81d      	bhi.n	800185e <mpu_configure_regions+0x76>
	return ((32 - __builtin_clz(size - 1U) - 2 + 1) << MPU_RASR_SIZE_Pos) &
 8001822:	3c01      	subs	r4, #1
 8001824:	fab4 f484 	clz	r4, r4
 8001828:	f1c4 041f 	rsb	r4, r4, #31
 800182c:	0064      	lsls	r4, r4, #1
	if (index > (get_num_regions() - 1U)) {
 800182e:	f1be 0f07 	cmp.w	lr, #7
	p_attr->rasr = attr->rasr_attr | size_to_mpu_rasr_size(size);
 8001832:	ea4c 0c04 	orr.w	ip, ip, r4
 8001836:	d814      	bhi.n	8001862 <mpu_configure_regions+0x7a>
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
 8001838:	f027 041f 	bic.w	r4, r7, #31
				| MPU_RBAR_VALID_Msk | index;
 800183c:	4314      	orrs	r4, r2
 800183e:	f044 0410 	orr.w	r4, r4, #16
 8001842:	f8c6 2098 	str.w	r2, [r6, #152]	; 0x98
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
 8001846:	f8c6 409c 	str.w	r4, [r6, #156]	; 0x9c
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
 800184a:	f04c 0401 	orr.w	r4, ip, #1
 800184e:	f8c6 40a0 	str.w	r4, [r6, #160]	; 0xa0
		if (reg_index == -EINVAL) {
			return reg_index;
		}

		/* Increment number of programmed MPU indices. */
		reg_index++;
 8001852:	3201      	adds	r2, #1
	for (i = 0; i < regions_num; i++) {
 8001854:	3501      	adds	r5, #1
 8001856:	300c      	adds	r0, #12
 8001858:	e7c9      	b.n	80017ee <mpu_configure_regions+0x6>
		return REGION_32B;
 800185a:	2408      	movs	r4, #8
 800185c:	e7e7      	b.n	800182e <mpu_configure_regions+0x46>
		return REGION_4G;
 800185e:	243e      	movs	r4, #62	; 0x3e
 8001860:	e7e5      	b.n	800182e <mpu_configure_regions+0x46>
			return -EINVAL;
 8001862:	f06f 0215 	mvn.w	r2, #21
	}

	return reg_index;
}
 8001866:	4610      	mov	r0, r2
 8001868:	bdf0      	pop	{r4, r5, r6, r7, pc}
 800186a:	bf00      	nop
 800186c:	e000ed00 	.word	0xe000ed00

08001870 <arm_core_mpu_enable>:
	 * background region for privileged software access if desired.
	 */
#if defined(CONFIG_MPU_DISABLE_BACKGROUND_MAP)
	MPU->CTRL = MPU_CTRL_ENABLE_Msk;
#else
	MPU->CTRL = MPU_CTRL_ENABLE_Msk | MPU_CTRL_PRIVDEFENA_Msk;
 8001870:	4b04      	ldr	r3, [pc, #16]	; (8001884 <arm_core_mpu_enable+0x14>)
 8001872:	2205      	movs	r2, #5
 8001874:	f8c3 2094 	str.w	r2, [r3, #148]	; 0x94
  __ASM volatile ("dsb 0xF":::"memory");
 8001878:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
 800187c:	f3bf 8f6f 	isb	sy
#endif

	/* Make sure that all the registers are set before proceeding */
	__DSB();
	__ISB();
}
 8001880:	4770      	bx	lr
 8001882:	bf00      	nop
 8001884:	e000ed00 	.word	0xe000ed00

08001888 <arm_core_mpu_disable>:
  __ASM volatile ("dmb 0xF":::"memory");
 8001888:	f3bf 8f5f 	dmb	sy
{
	/* Force any outstanding transfers to complete before disabling MPU */
	__DMB();

	/* Disable MPU */
	MPU->CTRL = 0;
 800188c:	4b02      	ldr	r3, [pc, #8]	; (8001898 <arm_core_mpu_disable+0x10>)
 800188e:	2200      	movs	r2, #0
 8001890:	f8c3 2094 	str.w	r2, [r3, #148]	; 0x94
}
 8001894:	4770      	bx	lr
 8001896:	bf00      	nop
 8001898:	e000ed00 	.word	0xe000ed00

0800189c <arm_core_mpu_configure_static_mpu_regions>:
 * @brief configure fixed (static) MPU regions.
 */
void arm_core_mpu_configure_static_mpu_regions(const struct z_arm_mpu_partition
	*static_regions, const uint8_t regions_num,
	const uint32_t background_area_start, const uint32_t background_area_end)
{
 800189c:	b538      	push	{r3, r4, r5, lr}
static int mpu_configure_static_mpu_regions(const struct z_arm_mpu_partition
	static_regions[], const uint8_t regions_num,
	const uint32_t background_area_base,
	const uint32_t background_area_end)
{
	int mpu_reg_index = static_regions_num;
 800189e:	4d0d      	ldr	r5, [pc, #52]	; (80018d4 <arm_core_mpu_configure_static_mpu_regions+0x38>)
	 * programmed on top of SRAM region configuration.
	 */
	ARG_UNUSED(background_area_base);
	ARG_UNUSED(background_area_end);

	mpu_reg_index = mpu_configure_regions(static_regions,
 80018a0:	2301      	movs	r3, #1
 80018a2:	782a      	ldrb	r2, [r5, #0]
 80018a4:	f7ff ffa0 	bl	80017e8 <mpu_configure_regions>
		regions_num, mpu_reg_index, true);

	static_regions_num = mpu_reg_index;
 80018a8:	7028      	strb	r0, [r5, #0]
	if (mpu_configure_static_mpu_regions(static_regions, regions_num,
 80018aa:	3016      	adds	r0, #22
{
 80018ac:	460c      	mov	r4, r1
	if (mpu_configure_static_mpu_regions(static_regions, regions_num,
 80018ae:	d10f      	bne.n	80018d0 <arm_core_mpu_configure_static_mpu_regions+0x34>
					       background_area_start, background_area_end) == -EINVAL) {

		__ASSERT(0, "Configuring %u static MPU regions failed\n",
 80018b0:	4a09      	ldr	r2, [pc, #36]	; (80018d8 <arm_core_mpu_configure_static_mpu_regions+0x3c>)
 80018b2:	490a      	ldr	r1, [pc, #40]	; (80018dc <arm_core_mpu_configure_static_mpu_regions+0x40>)
 80018b4:	480a      	ldr	r0, [pc, #40]	; (80018e0 <arm_core_mpu_configure_static_mpu_regions+0x44>)
 80018b6:	f44f 738d 	mov.w	r3, #282	; 0x11a
 80018ba:	f003 f924 	bl	8004b06 <assert_print>
 80018be:	4809      	ldr	r0, [pc, #36]	; (80018e4 <arm_core_mpu_configure_static_mpu_regions+0x48>)
 80018c0:	4621      	mov	r1, r4
 80018c2:	f003 f920 	bl	8004b06 <assert_print>
 80018c6:	4804      	ldr	r0, [pc, #16]	; (80018d8 <arm_core_mpu_configure_static_mpu_regions+0x3c>)
 80018c8:	f44f 718d 	mov.w	r1, #282	; 0x11a
 80018cc:	f003 f914 	bl	8004af8 <assert_post_action>
			regions_num);
	}
}
 80018d0:	bd38      	pop	{r3, r4, r5, pc}
 80018d2:	bf00      	nop
 80018d4:	20000808 	.word	0x20000808
 80018d8:	08005ebe 	.word	0x08005ebe
 80018dc:	080064f9 	.word	0x080064f9
 80018e0:	08005ca7 	.word	0x08005ca7
 80018e4:	08005ef5 	.word	0x08005ef5

080018e8 <arm_core_mpu_configure_dynamic_mpu_regions>:
/**
 * @brief configure dynamic MPU regions.
 */
void arm_core_mpu_configure_dynamic_mpu_regions(const struct z_arm_mpu_partition
	*dynamic_regions, uint8_t regions_num)
{
 80018e8:	b510      	push	{r4, lr}

	/* In ARMv7-M architecture the dynamic regions are
	 * programmed on top of existing SRAM region configuration.
	 */

	mpu_reg_index = mpu_configure_regions(dynamic_regions,
 80018ea:	4a11      	ldr	r2, [pc, #68]	; (8001930 <arm_core_mpu_configure_dynamic_mpu_regions+0x48>)
 80018ec:	2300      	movs	r3, #0
 80018ee:	7812      	ldrb	r2, [r2, #0]
 80018f0:	f7ff ff7a 	bl	80017e8 <mpu_configure_regions>
		regions_num, mpu_reg_index, false);

	if (mpu_reg_index != -EINVAL) {
 80018f4:	f110 0f16 	cmn.w	r0, #22
 80018f8:	460c      	mov	r4, r1
 80018fa:	d003      	beq.n	8001904 <arm_core_mpu_configure_dynamic_mpu_regions+0x1c>
/** Clear and disable the given MPU region.
* \param rnr Region number to be cleared.
*/
__STATIC_INLINE void ARM_MPU_ClrRegion(uint32_t rnr)
{
  MPU->RNR = rnr;
 80018fc:	4a0d      	ldr	r2, [pc, #52]	; (8001934 <arm_core_mpu_configure_dynamic_mpu_regions+0x4c>)

		/* Disable the non-programmed MPU regions. */
		for (int i = mpu_reg_index; i < get_num_regions(); i++) {
 80018fe:	2807      	cmp	r0, #7
 8001900:	dd10      	ble.n	8001924 <arm_core_mpu_configure_dynamic_mpu_regions+0x3c>
		== -EINVAL) {

		__ASSERT(0, "Configuring %u dynamic MPU regions failed\n",
			regions_num);
	}
}
 8001902:	bd10      	pop	{r4, pc}
		__ASSERT(0, "Configuring %u dynamic MPU regions failed\n",
 8001904:	4a0c      	ldr	r2, [pc, #48]	; (8001938 <arm_core_mpu_configure_dynamic_mpu_regions+0x50>)
 8001906:	490d      	ldr	r1, [pc, #52]	; (800193c <arm_core_mpu_configure_dynamic_mpu_regions+0x54>)
 8001908:	480d      	ldr	r0, [pc, #52]	; (8001940 <arm_core_mpu_configure_dynamic_mpu_regions+0x58>)
 800190a:	f240 1339 	movw	r3, #313	; 0x139
 800190e:	f003 f8fa 	bl	8004b06 <assert_print>
 8001912:	480c      	ldr	r0, [pc, #48]	; (8001944 <arm_core_mpu_configure_dynamic_mpu_regions+0x5c>)
 8001914:	4621      	mov	r1, r4
 8001916:	f003 f8f6 	bl	8004b06 <assert_print>
 800191a:	4807      	ldr	r0, [pc, #28]	; (8001938 <arm_core_mpu_configure_dynamic_mpu_regions+0x50>)
 800191c:	f240 1139 	movw	r1, #313	; 0x139
 8001920:	f003 f8ea 	bl	8004af8 <assert_post_action>
 8001924:	f8c2 0098 	str.w	r0, [r2, #152]	; 0x98
  MPU->RASR = 0U;
 8001928:	f8c2 30a0 	str.w	r3, [r2, #160]	; 0xa0
 800192c:	3001      	adds	r0, #1
 800192e:	e7e6      	b.n	80018fe <arm_core_mpu_configure_dynamic_mpu_regions+0x16>
 8001930:	20000808 	.word	0x20000808
 8001934:	e000ed00 	.word	0xe000ed00
 8001938:	08005ebe 	.word	0x08005ebe
 800193c:	080064f9 	.word	0x080064f9
 8001940:	08005ca7 	.word	0x08005ca7
 8001944:	08005f21 	.word	0x08005f21

08001948 <z_arm_mpu_init>:
 */
int z_arm_mpu_init(void)
{
	uint32_t r_index;

	if (mpu_config.num_regions > get_num_regions()) {
 8001948:	4925      	ldr	r1, [pc, #148]	; (80019e0 <z_arm_mpu_init+0x98>)
{
 800194a:	b510      	push	{r4, lr}
	if (mpu_config.num_regions > get_num_regions()) {
 800194c:	680c      	ldr	r4, [r1, #0]
 800194e:	2c08      	cmp	r4, #8
 8001950:	d910      	bls.n	8001974 <z_arm_mpu_init+0x2c>
		 * what is supported by hardware. As this operation
		 * is executed during system (pre-kernel) initialization,
		 * we want to ensure we can detect an attempt to
		 * perform invalid configuration.
		 */
		__ASSERT(0,
 8001952:	4a24      	ldr	r2, [pc, #144]	; (80019e4 <z_arm_mpu_init+0x9c>)
 8001954:	4924      	ldr	r1, [pc, #144]	; (80019e8 <z_arm_mpu_init+0xa0>)
 8001956:	4825      	ldr	r0, [pc, #148]	; (80019ec <z_arm_mpu_init+0xa4>)
 8001958:	f240 1351 	movw	r3, #337	; 0x151
 800195c:	f003 f8d3 	bl	8004b06 <assert_print>
 8001960:	4621      	mov	r1, r4
 8001962:	4823      	ldr	r0, [pc, #140]	; (80019f0 <z_arm_mpu_init+0xa8>)
 8001964:	2208      	movs	r2, #8
 8001966:	f003 f8ce 	bl	8004b06 <assert_print>
 800196a:	f240 1151 	movw	r1, #337	; 0x151

	/* Sanity check for number of regions in Cortex-M0+, M3, and M4. */
#if defined(CONFIG_CPU_CORTEX_M0PLUS) || \
	defined(CONFIG_CPU_CORTEX_M3) || \
	defined(CONFIG_CPU_CORTEX_M4)
	__ASSERT(
 800196e:	481d      	ldr	r0, [pc, #116]	; (80019e4 <z_arm_mpu_init+0x9c>)
 8001970:	f003 f8c2 	bl	8004af8 <assert_post_action>
	arm_core_mpu_disable();
 8001974:	f7ff ff88 	bl	8001888 <arm_core_mpu_disable>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
 8001978:	6848      	ldr	r0, [r1, #4]
 800197a:	491e      	ldr	r1, [pc, #120]	; (80019f4 <z_arm_mpu_init+0xac>)
 800197c:	2200      	movs	r2, #0
 800197e:	4294      	cmp	r4, r2
 8001980:	f100 000c 	add.w	r0, r0, #12
 8001984:	d116      	bne.n	80019b4 <z_arm_mpu_init+0x6c>
	static_regions_num = mpu_config.num_regions;
 8001986:	4b1c      	ldr	r3, [pc, #112]	; (80019f8 <z_arm_mpu_init+0xb0>)
 8001988:	701c      	strb	r4, [r3, #0]
	arm_core_mpu_enable();
 800198a:	f7ff ff71 	bl	8001870 <arm_core_mpu_enable>
	__ASSERT(
 800198e:	f8d1 3090 	ldr.w	r3, [r1, #144]	; 0x90
 8001992:	f3c3 2307 	ubfx	r3, r3, #8, #8
 8001996:	2b08      	cmp	r3, #8
 8001998:	d01f      	beq.n	80019da <z_arm_mpu_init+0x92>
 800199a:	4918      	ldr	r1, [pc, #96]	; (80019fc <z_arm_mpu_init+0xb4>)
 800199c:	4a11      	ldr	r2, [pc, #68]	; (80019e4 <z_arm_mpu_init+0x9c>)
 800199e:	4813      	ldr	r0, [pc, #76]	; (80019ec <z_arm_mpu_init+0xa4>)
 80019a0:	f240 13b7 	movw	r3, #439	; 0x1b7
 80019a4:	f003 f8af 	bl	8004b06 <assert_print>
 80019a8:	4815      	ldr	r0, [pc, #84]	; (8001a00 <z_arm_mpu_init+0xb8>)
 80019aa:	f003 f8ac 	bl	8004b06 <assert_print>
 80019ae:	f240 11b7 	movw	r1, #439	; 0x1b7
 80019b2:	e7dc      	b.n	800196e <z_arm_mpu_init+0x26>
 80019b4:	f8c1 2098 	str.w	r2, [r1, #152]	; 0x98
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
 80019b8:	f850 3c0c 	ldr.w	r3, [r0, #-12]
 80019bc:	f023 031f 	bic.w	r3, r3, #31
				| MPU_RBAR_VALID_Msk | index;
 80019c0:	4313      	orrs	r3, r2
 80019c2:	f043 0310 	orr.w	r3, r3, #16
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
 80019c6:	f8c1 309c 	str.w	r3, [r1, #156]	; 0x9c
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
 80019ca:	f850 3c04 	ldr.w	r3, [r0, #-4]
 80019ce:	f043 0301 	orr.w	r3, r3, #1
 80019d2:	f8c1 30a0 	str.w	r3, [r1, #160]	; 0xa0
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
 80019d6:	3201      	adds	r2, #1
 80019d8:	e7d1      	b.n	800197e <z_arm_mpu_init+0x36>
		NUM_MPU_REGIONS,
		"Invalid number of MPU regions\n");
#endif /* CORTEX_M0PLUS || CPU_CORTEX_M3 || CPU_CORTEX_M4 */

	return 0;
}
 80019da:	2000      	movs	r0, #0
 80019dc:	bd10      	pop	{r4, pc}
 80019de:	bf00      	nop
 80019e0:	0800587c 	.word	0x0800587c
 80019e4:	08005ebe 	.word	0x08005ebe
 80019e8:	080064f9 	.word	0x080064f9
 80019ec:	08005ca7 	.word	0x08005ca7
 80019f0:	08005f4e 	.word	0x08005f4e
 80019f4:	e000ed00 	.word	0xe000ed00
 80019f8:	20000808 	.word	0x20000808
 80019fc:	08005f82 	.word	0x08005f82
 8001a00:	08005fd2 	.word	0x08005fd2

08001a04 <__stm32_exti_isr.isra.0>:
 *
 * @param arg isr argument
 * @param min low end of EXTI# range
 * @param max low end of EXTI# range
 */
static void __stm32_exti_isr(int min, int max, const struct device *dev)
 8001a04:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
  * @note   Please check each device line mapping for EXTI Line availability
  * @retval State of bit (1 or 0).
  */
__STATIC_INLINE uint32_t LL_EXTI_IsActiveFlag_0_31(uint32_t ExtiLine)
{
  return (READ_BIT(EXTI->PR, ExtiLine) == (ExtiLine));
 8001a08:	4f0d      	ldr	r7, [pc, #52]	; (8001a40 <__stm32_exti_isr.isra.0+0x3c>)
 8001a0a:	4604      	mov	r4, r0
 8001a0c:	460e      	mov	r6, r1
 8001a0e:	4615      	mov	r5, r2
		return LL_EXTI_IsActiveFlag_0_31(1 << line);
 8001a10:	f04f 0801 	mov.w	r8, #1
			/* run callback only if one is registered */
			if (!data->cb[line].cb) {
				continue;
			}

			data->cb[line].cb(line, data->cb[line].data);
 8001a14:	f102 0904 	add.w	r9, r2, #4
	for (line = min; line < max; line++) {
 8001a18:	42b4      	cmp	r4, r6
 8001a1a:	db01      	blt.n	8001a20 <__stm32_exti_isr.isra.0+0x1c>
		}
	}
}
 8001a1c:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
 8001a20:	697a      	ldr	r2, [r7, #20]
		return LL_EXTI_IsActiveFlag_0_31(1 << line);
 8001a22:	fa08 f304 	lsl.w	r3, r8, r4
		if (stm32_exti_is_pending(line)) {
 8001a26:	ea33 0202 	bics.w	r2, r3, r2
 8001a2a:	d107      	bne.n	8001a3c <__stm32_exti_isr.isra.0+0x38>
  * @note   Please check each device line mapping for EXTI Line availability
  * @retval None
  */
__STATIC_INLINE void LL_EXTI_ClearFlag_0_31(uint32_t ExtiLine)
{
  WRITE_REG(EXTI->PR, ExtiLine);
 8001a2c:	617b      	str	r3, [r7, #20]
			if (!data->cb[line].cb) {
 8001a2e:	f855 3034 	ldr.w	r3, [r5, r4, lsl #3]
 8001a32:	b11b      	cbz	r3, 8001a3c <__stm32_exti_isr.isra.0+0x38>
			data->cb[line].cb(line, data->cb[line].data);
 8001a34:	f859 1034 	ldr.w	r1, [r9, r4, lsl #3]
 8001a38:	4620      	mov	r0, r4
 8001a3a:	4798      	blx	r3
	for (line = min; line < max; line++) {
 8001a3c:	3401      	adds	r4, #1
 8001a3e:	e7eb      	b.n	8001a18 <__stm32_exti_isr.isra.0+0x14>
 8001a40:	40013c00 	.word	0x40013c00

08001a44 <stm32_exti_enable>:
  SET_BIT(EXTI->IMR, ExtiLine);
 8001a44:	4a04      	ldr	r2, [pc, #16]	; (8001a58 <stm32_exti_enable+0x14>)
	LL_EXTI_EnableIT_0_31(1 << line);
 8001a46:	2301      	movs	r3, #1
 8001a48:	6811      	ldr	r1, [r2, #0]
 8001a4a:	4083      	lsls	r3, r0
 8001a4c:	430b      	orrs	r3, r1
 8001a4e:	6013      	str	r3, [r2, #0]
	irq_enable(irqnum);
 8001a50:	4b02      	ldr	r3, [pc, #8]	; (8001a5c <stm32_exti_enable+0x18>)
 8001a52:	5618      	ldrsb	r0, [r3, r0]
 8001a54:	f7ff bbec 	b.w	8001230 <arch_irq_enable>
 8001a58:	40013c00 	.word	0x40013c00
 8001a5c:	08006020 	.word	0x08006020

08001a60 <stm32_exti_disable>:
	if (line < 32) {
 8001a60:	281f      	cmp	r0, #31
 8001a62:	dc06      	bgt.n	8001a72 <stm32_exti_disable+0x12>
  CLEAR_BIT(EXTI->IMR, ExtiLine);
 8001a64:	4903      	ldr	r1, [pc, #12]	; (8001a74 <stm32_exti_disable+0x14>)
		LL_EXTI_DisableIT_0_31(1 << line);
 8001a66:	2201      	movs	r2, #1
 8001a68:	680b      	ldr	r3, [r1, #0]
 8001a6a:	4082      	lsls	r2, r0
 8001a6c:	ea23 0302 	bic.w	r3, r3, r2
 8001a70:	600b      	str	r3, [r1, #0]
}
 8001a72:	4770      	bx	lr
 8001a74:	40013c00 	.word	0x40013c00

08001a78 <stm32_exti_trigger>:
	switch (trigger) {
 8001a78:	2903      	cmp	r1, #3
 8001a7a:	d82a      	bhi.n	8001ad2 <stm32_exti_trigger+0x5a>
 8001a7c:	e8df f001 	tbb	[pc, r1]
 8001a80:	1f140e02 	.word	0x1f140e02
  CLEAR_BIT(EXTI->RTSR, ExtiLine);
 8001a84:	4b13      	ldr	r3, [pc, #76]	; (8001ad4 <stm32_exti_trigger+0x5c>)
		LL_EXTI_DisableRisingTrig_0_31(1 << line);
 8001a86:	2201      	movs	r2, #1
 8001a88:	6899      	ldr	r1, [r3, #8]
 8001a8a:	4082      	lsls	r2, r0
 8001a8c:	ea21 0102 	bic.w	r1, r1, r2
  SET_BIT(EXTI->RTSR, ExtiLine);
 8001a90:	6099      	str	r1, [r3, #8]
  CLEAR_BIT(EXTI->FTSR, ExtiLine);
 8001a92:	68d9      	ldr	r1, [r3, #12]
 8001a94:	ea21 0202 	bic.w	r2, r1, r2
 8001a98:	60da      	str	r2, [r3, #12]
}
 8001a9a:	4770      	bx	lr
  SET_BIT(EXTI->RTSR, ExtiLine);
 8001a9c:	4b0d      	ldr	r3, [pc, #52]	; (8001ad4 <stm32_exti_trigger+0x5c>)
		LL_EXTI_EnableRisingTrig_0_31(1 << line);
 8001a9e:	2201      	movs	r2, #1
 8001aa0:	6899      	ldr	r1, [r3, #8]
 8001aa2:	4082      	lsls	r2, r0
 8001aa4:	4311      	orrs	r1, r2
 8001aa6:	e7f3      	b.n	8001a90 <stm32_exti_trigger+0x18>
  SET_BIT(EXTI->FTSR, ExtiLine);
 8001aa8:	4b0a      	ldr	r3, [pc, #40]	; (8001ad4 <stm32_exti_trigger+0x5c>)
		LL_EXTI_EnableFallingTrig_0_31(1 << line);
 8001aaa:	2201      	movs	r2, #1
 8001aac:	68d9      	ldr	r1, [r3, #12]
 8001aae:	4082      	lsls	r2, r0
 8001ab0:	4311      	orrs	r1, r2
 8001ab2:	60d9      	str	r1, [r3, #12]
  CLEAR_BIT(EXTI->RTSR, ExtiLine);
 8001ab4:	6899      	ldr	r1, [r3, #8]
 8001ab6:	ea21 0202 	bic.w	r2, r1, r2
 8001aba:	609a      	str	r2, [r3, #8]
}
 8001abc:	4770      	bx	lr
		LL_EXTI_EnableRisingTrig_0_31(1 << line);
 8001abe:	2301      	movs	r3, #1
 8001ac0:	fa03 f000 	lsl.w	r0, r3, r0
  SET_BIT(EXTI->RTSR, ExtiLine);
 8001ac4:	4b03      	ldr	r3, [pc, #12]	; (8001ad4 <stm32_exti_trigger+0x5c>)
 8001ac6:	689a      	ldr	r2, [r3, #8]
 8001ac8:	4302      	orrs	r2, r0
 8001aca:	609a      	str	r2, [r3, #8]
  SET_BIT(EXTI->FTSR, ExtiLine);
 8001acc:	68da      	ldr	r2, [r3, #12]
 8001ace:	4310      	orrs	r0, r2
 8001ad0:	60d8      	str	r0, [r3, #12]
}
 8001ad2:	4770      	bx	lr
 8001ad4:	40013c00 	.word	0x40013c00

08001ad8 <stm32_exti_set_callback>:

/**
 * @brief set & unset for the interrupt callbacks
 */
int stm32_exti_set_callback(int line, stm32_exti_callback_t cb, void *arg)
{
 8001ad8:	b510      	push	{r4, lr}
	const struct device *const dev = DEVICE_DT_GET(EXTI_NODE);
	struct stm32_exti_data *data = dev->data;

	if (data->cb[line].cb) {
 8001ada:	4b07      	ldr	r3, [pc, #28]	; (8001af8 <stm32_exti_set_callback+0x20>)
{
 8001adc:	4604      	mov	r4, r0
	if (data->cb[line].cb) {
 8001ade:	f853 0030 	ldr.w	r0, [r3, r0, lsl #3]
 8001ae2:	b928      	cbnz	r0, 8001af0 <stm32_exti_set_callback+0x18>
		return -EBUSY;
	}

	data->cb[line].cb = cb;
 8001ae4:	f843 1034 	str.w	r1, [r3, r4, lsl #3]
	data->cb[line].data = arg;
 8001ae8:	eb03 03c4 	add.w	r3, r3, r4, lsl #3
 8001aec:	605a      	str	r2, [r3, #4]

	return 0;
}
 8001aee:	bd10      	pop	{r4, pc}
		return -EBUSY;
 8001af0:	f06f 000f 	mvn.w	r0, #15
 8001af4:	e7fb      	b.n	8001aee <stm32_exti_set_callback+0x16>
 8001af6:	bf00      	nop
 8001af8:	2000066c 	.word	0x2000066c

08001afc <stm32_exti_unset_callback>:
void stm32_exti_unset_callback(int line)
{
	const struct device *const dev = DEVICE_DT_GET(EXTI_NODE);
	struct stm32_exti_data *data = dev->data;

	data->cb[line].cb = NULL;
 8001afc:	4b03      	ldr	r3, [pc, #12]	; (8001b0c <stm32_exti_unset_callback+0x10>)
 8001afe:	2200      	movs	r2, #0
 8001b00:	f843 2030 	str.w	r2, [r3, r0, lsl #3]
	data->cb[line].data = NULL;
 8001b04:	eb03 03c0 	add.w	r3, r3, r0, lsl #3
 8001b08:	605a      	str	r2, [r3, #4]
}
 8001b0a:	4770      	bx	lr
 8001b0c:	2000066c 	.word	0x2000066c

08001b10 <stm32_clock_control_get_subsys_rate>:
}

static int stm32_clock_control_get_subsys_rate(const struct device *clock,
						clock_control_subsys_t sub_system,
						uint32_t *rate)
{
 8001b10:	b510      	push	{r4, lr}
	 * Get AHB Clock (= SystemCoreClock = SYSCLK/prescaler)
	 * SystemCoreClock is preferred to CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC
	 * since it will be updated after clock configuration and hence
	 * more likely to contain actual clock speed
	 */
	uint32_t ahb_clock = SystemCoreClock;
 8001b12:	4b20      	ldr	r3, [pc, #128]	; (8001b94 <stm32_clock_control_get_subsys_rate+0x84>)
 8001b14:	6818      	ldr	r0, [r3, #0]
	}
#endif

	ARG_UNUSED(clock);

	switch (pclken->bus) {
 8001b16:	680b      	ldr	r3, [r1, #0]
 8001b18:	2b44      	cmp	r3, #68	; 0x44
{
 8001b1a:	4614      	mov	r4, r2
	switch (pclken->bus) {
 8001b1c:	d828      	bhi.n	8001b70 <stm32_clock_control_get_subsys_rate+0x60>
 8001b1e:	2b2f      	cmp	r3, #47	; 0x2f
 8001b20:	d805      	bhi.n	8001b2e <stm32_clock_control_get_subsys_rate+0x1e>
 8001b22:	3b01      	subs	r3, #1
 8001b24:	2b05      	cmp	r3, #5
 8001b26:	d90d      	bls.n	8001b44 <stm32_clock_control_get_subsys_rate+0x34>
 8001b28:	f06f 0085 	mvn.w	r0, #133	; 0x85
 8001b2c:	e01f      	b.n	8001b6e <stm32_clock_control_get_subsys_rate+0x5e>
 8001b2e:	f1a3 0130 	sub.w	r1, r3, #48	; 0x30
 8001b32:	2201      	movs	r2, #1
 8001b34:	408a      	lsls	r2, r1
 8001b36:	4918      	ldr	r1, [pc, #96]	; (8001b98 <stm32_clock_control_get_subsys_rate+0x88>)
 8001b38:	420a      	tst	r2, r1
 8001b3a:	d116      	bne.n	8001b6a <stm32_clock_control_get_subsys_rate+0x5a>
 8001b3c:	2b40      	cmp	r3, #64	; 0x40
 8001b3e:	d1f3      	bne.n	8001b28 <stm32_clock_control_get_subsys_rate+0x18>
	return clock / prescaler;
 8001b40:	0840      	lsrs	r0, r0, #1
	case STM32_CLOCK_BUS_APB1:
#if defined(STM32_CLOCK_BUS_APB1_2)
	case STM32_CLOCK_BUS_APB1_2:
#endif
		*rate = apb1_clock;
		break;
 8001b42:	e012      	b.n	8001b6a <stm32_clock_control_get_subsys_rate+0x5a>
	switch (pclken->bus) {
 8001b44:	2b05      	cmp	r3, #5
 8001b46:	d8ef      	bhi.n	8001b28 <stm32_clock_control_get_subsys_rate+0x18>
 8001b48:	a201      	add	r2, pc, #4	; (adr r2, 8001b50 <stm32_clock_control_get_subsys_rate+0x40>)
 8001b4a:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
 8001b4e:	bf00      	nop
 8001b50:	08001b77 	.word	0x08001b77
 8001b54:	08001b83 	.word	0x08001b83
 8001b58:	08001b29 	.word	0x08001b29
 8001b5c:	08001b69 	.word	0x08001b69
 8001b60:	08001b8f 	.word	0x08001b8f
 8001b64:	08001b6b 	.word	0x08001b6b
 8001b68:	2000      	movs	r0, #0
		*rate = STM32_LSE_FREQ;
		break;
#endif
#if defined(STM32_SRC_LSI)
	case STM32_SRC_LSI:
		*rate = STM32_LSI_FREQ;
 8001b6a:	6020      	str	r0, [r4, #0]
#endif
	default:
		return -ENOTSUP;
	}

	return 0;
 8001b6c:	2000      	movs	r0, #0
}
 8001b6e:	bd10      	pop	{r4, pc}
	switch (pclken->bus) {
 8001b70:	2ba8      	cmp	r3, #168	; 0xa8
 8001b72:	d0fa      	beq.n	8001b6a <stm32_clock_control_get_subsys_rate+0x5a>
 8001b74:	e7d8      	b.n	8001b28 <stm32_clock_control_get_subsys_rate+0x18>
		*rate = get_pll_div_frequency(get_pllsrc_frequency(),
 8001b76:	f000 f897 	bl	8001ca8 <get_pllsrc_frequency>
	return (pllsrc_freq * plln_mul) /
 8001b7a:	2360      	movs	r3, #96	; 0x60
 8001b7c:	4358      	muls	r0, r3
 8001b7e:	08c0      	lsrs	r0, r0, #3
		break;
 8001b80:	e7f3      	b.n	8001b6a <stm32_clock_control_get_subsys_rate+0x5a>
		*rate = get_pll_div_frequency(get_pllsrc_frequency(),
 8001b82:	f000 f891 	bl	8001ca8 <get_pllsrc_frequency>
	return (pllsrc_freq * plln_mul) /
 8001b86:	2360      	movs	r3, #96	; 0x60
 8001b88:	4358      	muls	r0, r3
 8001b8a:	0900      	lsrs	r0, r0, #4
		break;
 8001b8c:	e7ed      	b.n	8001b6a <stm32_clock_control_get_subsys_rate+0x5a>
		break;
 8001b8e:	f44f 40fa 	mov.w	r0, #32000	; 0x7d00
 8001b92:	e7ea      	b.n	8001b6a <stm32_clock_control_get_subsys_rate+0x5a>
 8001b94:	20000038 	.word	0x20000038
 8001b98:	00100111 	.word	0x00100111

08001b9c <stm32_clock_control_init>:
 * @param dev clock device struct
 *
 * @return 0
 */
int stm32_clock_control_init(const struct device *dev)
{
 8001b9c:	b570      	push	{r4, r5, r6, lr}
  *         @arg @ref LL_RCC_SYSCLK_DIV_256
  *         @arg @ref LL_RCC_SYSCLK_DIV_512
  */
__STATIC_INLINE uint32_t LL_RCC_GetAHBPrescaler(void)
{
  return (uint32_t)(READ_BIT(RCC->CFGR, RCC_CFGR_HPRE));
 8001b9e:	4c3e      	ldr	r4, [pc, #248]	; (8001c98 <stm32_clock_control_init+0xfc>)
	ARG_UNUSED(dev);

	/* Some clocks would be activated by default */
	config_enable_default_clocks();
 8001ba0:	f000 f898 	bl	8001cd4 <config_enable_default_clocks>

#if defined(FLASH_ACR_LATENCY)
	uint32_t old_flash_freq;
	uint32_t new_flash_freq;

	old_flash_freq = RCC_CALC_FLASH_FREQ(HAL_RCC_GetSysClockFreq(),
 8001ba4:	f000 fd50 	bl	8002648 <HAL_RCC_GetSysClockFreq>
 8001ba8:	68a3      	ldr	r3, [r4, #8]
 8001baa:	4a3c      	ldr	r2, [pc, #240]	; (8001c9c <stm32_clock_control_init+0x100>)
 8001bac:	f3c3 1303 	ubfx	r3, r3, #4, #4
 8001bb0:	5cd3      	ldrb	r3, [r2, r3]
 8001bb2:	fa20 f503 	lsr.w	r5, r0, r3

	new_flash_freq = RCC_CALC_FLASH_FREQ(CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC,
				      STM32_FLASH_PRESCALER);

	/* If freq increases, set flash latency before any clock setting */
	if (old_flash_freq < CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC) {
 8001bb6:	483a      	ldr	r0, [pc, #232]	; (8001ca0 <stm32_clock_control_init+0x104>)
 8001bb8:	4285      	cmp	r5, r0
 8001bba:	d201      	bcs.n	8001bc0 <stm32_clock_control_init+0x24>
		LL_SetFlashLatency(CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC);
 8001bbc:	f000 fd72 	bl	80026a4 <LL_SetFlashLatency>
  CLEAR_BIT(RCC->CR, RCC_CR_HSEBYP);
 8001bc0:	6823      	ldr	r3, [r4, #0]
 8001bc2:	f423 2380 	bic.w	r3, r3, #262144	; 0x40000
 8001bc6:	6023      	str	r3, [r4, #0]
  SET_BIT(RCC->CR, RCC_CR_HSEON);
 8001bc8:	6823      	ldr	r3, [r4, #0]
 8001bca:	f443 3380 	orr.w	r3, r3, #65536	; 0x10000
 8001bce:	6023      	str	r3, [r4, #0]
  return (READ_BIT(RCC->CR, RCC_CR_HSERDY) == (RCC_CR_HSERDY));
 8001bd0:	4b31      	ldr	r3, [pc, #196]	; (8001c98 <stm32_clock_control_init+0xfc>)
 8001bd2:	681a      	ldr	r2, [r3, #0]
		while (LL_RCC_HSE_IsReady() != 1) {
 8001bd4:	0396      	lsls	r6, r2, #14
 8001bd6:	d5fc      	bpl.n	8001bd2 <stm32_clock_control_init+0x36>
  SET_BIT(RCC->CSR, RCC_CSR_LSION);
 8001bd8:	6f5a      	ldr	r2, [r3, #116]	; 0x74
 8001bda:	f042 0201 	orr.w	r2, r2, #1
 8001bde:	675a      	str	r2, [r3, #116]	; 0x74
  return (READ_BIT(RCC->CSR, RCC_CSR_LSIRDY) == (RCC_CSR_LSIRDY));
 8001be0:	6f5a      	ldr	r2, [r3, #116]	; 0x74
		while (LL_RCC_LSI_IsReady() != 1) {
 8001be2:	0794      	lsls	r4, r2, #30
 8001be4:	d5fc      	bpl.n	8001be0 <stm32_clock_control_init+0x44>
  return (uint32_t)(READ_BIT(RCC->CFGR, RCC_CFGR_SWS));
 8001be6:	689a      	ldr	r2, [r3, #8]
 8001be8:	f002 020c 	and.w	r2, r2, #12
	if (LL_RCC_GetSysClkSource() == LL_RCC_SYS_CLKSOURCE_STATUS_PLL) {
 8001bec:	2a08      	cmp	r2, #8
 8001bee:	d117      	bne.n	8001c20 <stm32_clock_control_init+0x84>
  MODIFY_REG(RCC->CFGR, RCC_CFGR_HPRE, Prescaler);
 8001bf0:	689a      	ldr	r2, [r3, #8]
 8001bf2:	f022 02f0 	bic.w	r2, r2, #240	; 0xf0
 8001bf6:	609a      	str	r2, [r3, #8]
  return (READ_BIT(RCC->CR, RCC_CR_HSIRDY) == (RCC_CR_HSIRDY));
 8001bf8:	681a      	ldr	r2, [r3, #0]
	if (LL_RCC_HSI_IsReady() != 1) {
 8001bfa:	0790      	lsls	r0, r2, #30
 8001bfc:	d407      	bmi.n	8001c0e <stm32_clock_control_init+0x72>
  SET_BIT(RCC->CR, RCC_CR_HSION);
 8001bfe:	681a      	ldr	r2, [r3, #0]
 8001c00:	f042 0201 	orr.w	r2, r2, #1
 8001c04:	601a      	str	r2, [r3, #0]
  return (READ_BIT(RCC->CR, RCC_CR_HSIRDY) == (RCC_CR_HSIRDY));
 8001c06:	4a24      	ldr	r2, [pc, #144]	; (8001c98 <stm32_clock_control_init+0xfc>)
 8001c08:	6813      	ldr	r3, [r2, #0]
		while (LL_RCC_HSI_IsReady() != 1) {
 8001c0a:	0799      	lsls	r1, r3, #30
 8001c0c:	d5fc      	bpl.n	8001c08 <stm32_clock_control_init+0x6c>
  MODIFY_REG(RCC->CFGR, RCC_CFGR_SW, Source);
 8001c0e:	4b22      	ldr	r3, [pc, #136]	; (8001c98 <stm32_clock_control_init+0xfc>)
 8001c10:	689a      	ldr	r2, [r3, #8]
 8001c12:	f022 0203 	bic.w	r2, r2, #3
 8001c16:	609a      	str	r2, [r3, #8]
  return (uint32_t)(READ_BIT(RCC->CFGR, RCC_CFGR_SWS));
 8001c18:	689a      	ldr	r2, [r3, #8]
	while (LL_RCC_GetSysClkSource() != LL_RCC_SYS_CLKSOURCE_STATUS_HSI) {
 8001c1a:	f012 0f0c 	tst.w	r2, #12
 8001c1e:	d1fb      	bne.n	8001c18 <stm32_clock_control_init+0x7c>
  * @rmtoll CR           PLLON         LL_RCC_PLL_Disable
  * @retval None
  */
__STATIC_INLINE void LL_RCC_PLL_Disable(void)
{
  CLEAR_BIT(RCC->CR, RCC_CR_PLLON);
 8001c20:	4c1d      	ldr	r4, [pc, #116]	; (8001c98 <stm32_clock_control_init+0xfc>)
 8001c22:	6823      	ldr	r3, [r4, #0]
 8001c24:	f023 7380 	bic.w	r3, r3, #16777216	; 0x1000000
 8001c28:	6023      	str	r3, [r4, #0]
	MODIFY_REG(RCC->PLLCFGR, RCC_PLLCFGR_PLLP, pllp(STM32_PLL_P_DIVISOR));
 8001c2a:	6863      	ldr	r3, [r4, #4]
 8001c2c:	f423 3340 	bic.w	r3, r3, #196608	; 0x30000
 8001c30:	6063      	str	r3, [r4, #4]
	MODIFY_REG(RCC->PLLCFGR, RCC_PLLCFGR_PLLQ, pllq(STM32_PLL_Q_DIVISOR));
 8001c32:	6863      	ldr	r3, [r4, #4]
 8001c34:	f023 6370 	bic.w	r3, r3, #251658240	; 0xf000000
 8001c38:	f043 6380 	orr.w	r3, r3, #67108864	; 0x4000000
 8001c3c:	6063      	str	r3, [r4, #4]
	config_pll_sysclock();
 8001c3e:	f000 f837 	bl	8001cb0 <config_pll_sysclock>
  SET_BIT(RCC->CR, RCC_CR_PLLON);
 8001c42:	6823      	ldr	r3, [r4, #0]
 8001c44:	f043 7380 	orr.w	r3, r3, #16777216	; 0x1000000
 8001c48:	6023      	str	r3, [r4, #0]
  * @rmtoll CR           PLLRDY        LL_RCC_PLL_IsReady
  * @retval State of bit (1 or 0).
  */
__STATIC_INLINE uint32_t LL_RCC_PLL_IsReady(void)
{
  return (READ_BIT(RCC->CR, RCC_CR_PLLRDY) == (RCC_CR_PLLRDY));
 8001c4a:	6823      	ldr	r3, [r4, #0]
	while (LL_RCC_PLL_IsReady() != 1U) {
 8001c4c:	019b      	lsls	r3, r3, #6
 8001c4e:	d5fc      	bpl.n	8001c4a <stm32_clock_control_init+0xae>
  MODIFY_REG(RCC->CFGR, RCC_CFGR_HPRE, Prescaler);
 8001c50:	68a3      	ldr	r3, [r4, #8]
 8001c52:	f023 03f0 	bic.w	r3, r3, #240	; 0xf0
 8001c56:	60a3      	str	r3, [r4, #8]
  MODIFY_REG(RCC->CFGR, RCC_CFGR_SW, Source);
 8001c58:	68a3      	ldr	r3, [r4, #8]
 8001c5a:	f023 0303 	bic.w	r3, r3, #3
 8001c5e:	f043 0302 	orr.w	r3, r3, #2
 8001c62:	60a3      	str	r3, [r4, #8]
  return (uint32_t)(READ_BIT(RCC->CFGR, RCC_CFGR_SWS));
 8001c64:	4c0c      	ldr	r4, [pc, #48]	; (8001c98 <stm32_clock_control_init+0xfc>)
 8001c66:	68a3      	ldr	r3, [r4, #8]
 8001c68:	f003 030c 	and.w	r3, r3, #12
	}

#if STM32_SYSCLK_SRC_PLL
	/* Set PLL as System Clock Source */
	LL_RCC_SetSysClkSource(LL_RCC_SYS_CLKSOURCE_PLL);
	while (LL_RCC_GetSysClkSource() != LL_RCC_SYS_CLKSOURCE_STATUS_PLL) {
 8001c6c:	2b08      	cmp	r3, #8
 8001c6e:	d1fa      	bne.n	8001c66 <stm32_clock_control_init+0xca>
		LL_RCC_SetAHBPrescaler(ahb_prescaler(STM32_CORE_PRESCALER));
	}

#if defined(FLASH_ACR_LATENCY)
	/* If freq not increased, set flash latency after all clock setting */
	if (old_flash_freq >= CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC) {
 8001c70:	4e0b      	ldr	r6, [pc, #44]	; (8001ca0 <stm32_clock_control_init+0x104>)
 8001c72:	42b5      	cmp	r5, r6
 8001c74:	d302      	bcc.n	8001c7c <stm32_clock_control_init+0xe0>
		LL_SetFlashLatency(CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC);
 8001c76:	4630      	mov	r0, r6
 8001c78:	f000 fd14 	bl	80026a4 <LL_SetFlashLatency>
	}
#endif /* FLASH_ACR_LATENCY */

	SystemCoreClock = CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC;
 8001c7c:	4b09      	ldr	r3, [pc, #36]	; (8001ca4 <stm32_clock_control_init+0x108>)
 8001c7e:	601e      	str	r6, [r3, #0]
  MODIFY_REG(RCC->CFGR, RCC_CFGR_PPRE1, Prescaler);
 8001c80:	68a3      	ldr	r3, [r4, #8]
 8001c82:	f423 53e0 	bic.w	r3, r3, #7168	; 0x1c00
 8001c86:	f443 5380 	orr.w	r3, r3, #4096	; 0x1000
 8001c8a:	60a3      	str	r3, [r4, #8]
  MODIFY_REG(RCC->CFGR, RCC_CFGR_PPRE2, Prescaler);
 8001c8c:	68a3      	ldr	r3, [r4, #8]
 8001c8e:	f423 4360 	bic.w	r3, r3, #57344	; 0xe000
 8001c92:	60a3      	str	r3, [r4, #8]

	/* configure MCO1/MCO2 based on Kconfig */
	stm32_clock_control_mco_init();

	return 0;
}
 8001c94:	2000      	movs	r0, #0
 8001c96:	bd70      	pop	{r4, r5, r6, pc}
 8001c98:	40023800 	.word	0x40023800
 8001c9c:	08006299 	.word	0x08006299
 8001ca0:	05b8d800 	.word	0x05b8d800
 8001ca4:	20000038 	.word	0x20000038

08001ca8 <get_pllsrc_frequency>:
		return STM32_HSE_FREQ;
	}

	__ASSERT(0, "Invalid source");
	return 0;
}
 8001ca8:	4800      	ldr	r0, [pc, #0]	; (8001cac <get_pllsrc_frequency+0x4>)
 8001caa:	4770      	bx	lr
 8001cac:	007a1200 	.word	0x007a1200

08001cb0 <config_pll_sysclock>:
  *         (*) value not defined in all devices.
  * @retval None
  */
__STATIC_INLINE void LL_RCC_PLL_ConfigDomain_SYS(uint32_t Source, uint32_t PLLM, uint32_t PLLN, uint32_t PLLP_R)
{
  MODIFY_REG(RCC->PLLCFGR, RCC_PLLCFGR_PLLSRC | RCC_PLLCFGR_PLLM | RCC_PLLCFGR_PLLN,
 8001cb0:	4b05      	ldr	r3, [pc, #20]	; (8001cc8 <config_pll_sysclock+0x18>)
 8001cb2:	4906      	ldr	r1, [pc, #24]	; (8001ccc <config_pll_sysclock+0x1c>)
 8001cb4:	685a      	ldr	r2, [r3, #4]
 8001cb6:	4011      	ands	r1, r2
 8001cb8:	4a05      	ldr	r2, [pc, #20]	; (8001cd0 <config_pll_sysclock+0x20>)
 8001cba:	430a      	orrs	r2, r1
 8001cbc:	605a      	str	r2, [r3, #4]
             Source | PLLM | PLLN << RCC_PLLCFGR_PLLN_Pos);
  MODIFY_REG(RCC->PLLCFGR, RCC_PLLCFGR_PLLP, PLLP_R);
 8001cbe:	685a      	ldr	r2, [r3, #4]
 8001cc0:	f422 3240 	bic.w	r2, r2, #196608	; 0x30000
 8001cc4:	605a      	str	r2, [r3, #4]
{
	LL_RCC_PLL_ConfigDomain_SYS(get_pll_source(),
				    pllm(STM32_PLL_M_DIVISOR),
				    STM32_PLL_N_MULTIPLIER,
				    pllp(STM32_PLL_P_DIVISOR));
}
 8001cc6:	4770      	bx	lr
 8001cc8:	40023800 	.word	0x40023800
 8001ccc:	ffbf8000 	.word	0xffbf8000
 8001cd0:	00401804 	.word	0x00401804

08001cd4 <config_enable_default_clocks>:
  * @retval None
*/
__STATIC_INLINE void LL_APB1_GRP1_EnableClock(uint32_t Periphs)
{
  __IO uint32_t tmpreg;
  SET_BIT(RCC->APB1ENR, Periphs);
 8001cd4:	4b06      	ldr	r3, [pc, #24]	; (8001cf0 <config_enable_default_clocks+0x1c>)
 8001cd6:	6c1a      	ldr	r2, [r3, #64]	; 0x40
 8001cd8:	f042 5280 	orr.w	r2, r2, #268435456	; 0x10000000
 8001cdc:	641a      	str	r2, [r3, #64]	; 0x40
  /* Delay after an RCC peripheral clock enabling */
  tmpreg = READ_BIT(RCC->APB1ENR, Periphs);
 8001cde:	6c1b      	ldr	r3, [r3, #64]	; 0x40

/**
 * @brief Activate default clocks
 */
void config_enable_default_clocks(void)
{
 8001ce0:	b082      	sub	sp, #8
 8001ce2:	f003 5380 	and.w	r3, r3, #268435456	; 0x10000000
 8001ce6:	9301      	str	r3, [sp, #4]
  (void)tmpreg;
 8001ce8:	9b01      	ldr	r3, [sp, #4]
	/* Power Interface clock enabled by default */
	LL_APB1_GRP1_EnableClock(LL_APB1_GRP1_PERIPH_PWR);
}
 8001cea:	b002      	add	sp, #8
 8001cec:	4770      	bx	lr
 8001cee:	bf00      	nop
 8001cf0:	40023800 	.word	0x40023800

08001cf4 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(const struct device *arg)
{
 8001cf4:	b508      	push	{r3, lr}
 */
__syscall bool device_is_ready(const struct device *dev);

static inline bool z_impl_device_is_ready(const struct device *dev)
{
	return z_device_is_ready(dev);
 8001cf6:	4806      	ldr	r0, [pc, #24]	; (8001d10 <uart_console_init+0x1c>)
 8001cf8:	f003 fab7 	bl	800526a <z_device_is_ready>

	ARG_UNUSED(arg);

	if (!device_is_ready(uart_console_dev)) {
 8001cfc:	b120      	cbz	r0, 8001d08 <uart_console_init+0x14>
	__printk_hook_install(console_out);
 8001cfe:	4805      	ldr	r0, [pc, #20]	; (8001d14 <uart_console_init+0x20>)
 8001d00:	f7fe fcca 	bl	8000698 <__printk_hook_install>
		return -ENODEV;
	}

	uart_console_hook_install();

	return 0;
 8001d04:	2000      	movs	r0, #0
}
 8001d06:	bd08      	pop	{r3, pc}
		return -ENODEV;
 8001d08:	f06f 0012 	mvn.w	r0, #18
 8001d0c:	e7fb      	b.n	8001d06 <uart_console_init+0x12>
 8001d0e:	bf00      	nop
 8001d10:	080054b4 	.word	0x080054b4
 8001d14:	08001d19 	.word	0x08001d19

08001d18 <console_out>:
	if ('\n' == c) {
 8001d18:	280a      	cmp	r0, #10
{
 8001d1a:	b538      	push	{r3, r4, r5, lr}
 8001d1c:	4d07      	ldr	r5, [pc, #28]	; (8001d3c <console_out+0x24>)
 8001d1e:	4604      	mov	r4, r0
	if ('\n' == c) {
 8001d20:	d104      	bne.n	8001d2c <console_out+0x14>
					unsigned char out_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
 8001d22:	68ab      	ldr	r3, [r5, #8]
 8001d24:	210d      	movs	r1, #13
 8001d26:	685b      	ldr	r3, [r3, #4]
 8001d28:	4628      	mov	r0, r5
 8001d2a:	4798      	blx	r3
 8001d2c:	68ab      	ldr	r3, [r5, #8]
 8001d2e:	4803      	ldr	r0, [pc, #12]	; (8001d3c <console_out+0x24>)
 8001d30:	685b      	ldr	r3, [r3, #4]
 8001d32:	b2e1      	uxtb	r1, r4
 8001d34:	4798      	blx	r3
}
 8001d36:	4620      	mov	r0, r4
 8001d38:	bd38      	pop	{r3, r4, r5, pc}
 8001d3a:	bf00      	nop
 8001d3c:	080054b4 	.word	0x080054b4

08001d40 <gpio_stm32_manage_callback>:
}

static int gpio_stm32_manage_callback(const struct device *dev,
				      struct gpio_callback *callback,
				      bool set)
{
 8001d40:	b510      	push	{r4, lr}
	struct gpio_stm32_data *data = dev->data;
 8001d42:	6903      	ldr	r3, [r0, #16]
 */
static inline int gpio_manage_callback(sys_slist_t *callbacks,
					struct gpio_callback *callback,
					bool set)
{
	__ASSERT(callback, "No callback!");
 8001d44:	b961      	cbnz	r1, 8001d60 <gpio_stm32_manage_callback+0x20>
 8001d46:	4920      	ldr	r1, [pc, #128]	; (8001dc8 <gpio_stm32_manage_callback+0x88>)
 8001d48:	4a20      	ldr	r2, [pc, #128]	; (8001dcc <gpio_stm32_manage_callback+0x8c>)
 8001d4a:	4821      	ldr	r0, [pc, #132]	; (8001dd0 <gpio_stm32_manage_callback+0x90>)
 8001d4c:	232a      	movs	r3, #42	; 0x2a
 8001d4e:	f002 feda 	bl	8004b06 <assert_print>
 8001d52:	4820      	ldr	r0, [pc, #128]	; (8001dd4 <gpio_stm32_manage_callback+0x94>)
 8001d54:	f002 fed7 	bl	8004b06 <assert_print>
 8001d58:	212a      	movs	r1, #42	; 0x2a
	__ASSERT(callback->handler, "No callback handler!");
 8001d5a:	481c      	ldr	r0, [pc, #112]	; (8001dcc <gpio_stm32_manage_callback+0x8c>)
 8001d5c:	f002 fecc 	bl	8004af8 <assert_post_action>
 8001d60:	6848      	ldr	r0, [r1, #4]
 8001d62:	b950      	cbnz	r0, 8001d7a <gpio_stm32_manage_callback+0x3a>
 8001d64:	491c      	ldr	r1, [pc, #112]	; (8001dd8 <gpio_stm32_manage_callback+0x98>)
 8001d66:	4a19      	ldr	r2, [pc, #100]	; (8001dcc <gpio_stm32_manage_callback+0x8c>)
 8001d68:	4819      	ldr	r0, [pc, #100]	; (8001dd0 <gpio_stm32_manage_callback+0x90>)
 8001d6a:	232b      	movs	r3, #43	; 0x2b
 8001d6c:	f002 fecb 	bl	8004b06 <assert_print>
 8001d70:	481a      	ldr	r0, [pc, #104]	; (8001ddc <gpio_stm32_manage_callback+0x9c>)
 8001d72:	f002 fec8 	bl	8004b06 <assert_print>
 8001d76:	212b      	movs	r1, #43	; 0x2b
 8001d78:	e7ef      	b.n	8001d5a <gpio_stm32_manage_callback+0x1a>
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
 8001d7a:	6898      	ldr	r0, [r3, #8]

	if (!sys_slist_is_empty(callbacks)) {
 8001d7c:	b1f8      	cbz	r0, 8001dbe <gpio_stm32_manage_callback+0x7e>
 */
static inline bool sys_slist_find_and_remove(sys_slist_t *list,
					     sys_snode_t *node);

/** @} */
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
 8001d7e:	4288      	cmp	r0, r1
 8001d80:	d119      	bne.n	8001db6 <gpio_stm32_manage_callback+0x76>
Z_GENLIST_REMOVE(slist, snode)
 8001d82:	68dc      	ldr	r4, [r3, #12]
	return node->next;
 8001d84:	6808      	ldr	r0, [r1, #0]
	list->head = node;
 8001d86:	6098      	str	r0, [r3, #8]
Z_GENLIST_REMOVE(slist, snode)
 8001d88:	42a1      	cmp	r1, r4
 8001d8a:	d100      	bne.n	8001d8e <gpio_stm32_manage_callback+0x4e>
	list->tail = node;
 8001d8c:	60d8      	str	r0, [r3, #12]
	parent->next = child;
 8001d8e:	2000      	movs	r0, #0
 8001d90:	6008      	str	r0, [r1, #0]
		}
	} else if (!set) {
		return -EINVAL;
	}

	if (set) {
 8001d92:	b12a      	cbz	r2, 8001da0 <gpio_stm32_manage_callback+0x60>
	return list->head;
 8001d94:	689a      	ldr	r2, [r3, #8]
	parent->next = child;
 8001d96:	600a      	str	r2, [r1, #0]
Z_GENLIST_PREPEND(slist, snode)
 8001d98:	68da      	ldr	r2, [r3, #12]
	list->head = node;
 8001d9a:	6099      	str	r1, [r3, #8]
Z_GENLIST_PREPEND(slist, snode)
 8001d9c:	b902      	cbnz	r2, 8001da0 <gpio_stm32_manage_callback+0x60>
	list->tail = node;
 8001d9e:	60d9      	str	r1, [r3, #12]
		sys_slist_prepend(callbacks, &callback->node);
	}

	return 0;
 8001da0:	2000      	movs	r0, #0

	return gpio_manage_callback(&data->cb, callback, set);
 8001da2:	e010      	b.n	8001dc6 <gpio_stm32_manage_callback+0x86>
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
 8001da4:	4281      	cmp	r1, r0
 8001da6:	d106      	bne.n	8001db6 <gpio_stm32_manage_callback+0x76>
	return node->next;
 8001da8:	6808      	ldr	r0, [r1, #0]
	parent->next = child;
 8001daa:	6020      	str	r0, [r4, #0]
Z_GENLIST_REMOVE(slist, snode)
 8001dac:	68d8      	ldr	r0, [r3, #12]
 8001dae:	4281      	cmp	r1, r0
 8001db0:	d1ed      	bne.n	8001d8e <gpio_stm32_manage_callback+0x4e>
	list->tail = node;
 8001db2:	60dc      	str	r4, [r3, #12]
}
 8001db4:	e7eb      	b.n	8001d8e <gpio_stm32_manage_callback+0x4e>
	return node->next;
 8001db6:	4604      	mov	r4, r0
 8001db8:	6800      	ldr	r0, [r0, #0]
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
 8001dba:	2800      	cmp	r0, #0
 8001dbc:	d1f2      	bne.n	8001da4 <gpio_stm32_manage_callback+0x64>
			if (!set) {
 8001dbe:	2a00      	cmp	r2, #0
 8001dc0:	d1e8      	bne.n	8001d94 <gpio_stm32_manage_callback+0x54>
				return -EINVAL;
 8001dc2:	f06f 0015 	mvn.w	r0, #21
}
 8001dc6:	bd10      	pop	{r4, pc}
 8001dc8:	08006080 	.word	0x08006080
 8001dcc:	08006044 	.word	0x08006044
 8001dd0:	08005ca7 	.word	0x08005ca7
 8001dd4:	08006089 	.word	0x08006089
 8001dd8:	08006098 	.word	0x08006098
 8001ddc:	080060aa 	.word	0x080060aa

08001de0 <gpio_stm32_init>:
 * @param dev GPIO device struct
 *
 * @return 0
 */
static int gpio_stm32_init(const struct device *dev)
{
 8001de0:	b538      	push	{r3, r4, r5, lr}
	struct gpio_stm32_data *data = dev->data;
 8001de2:	6903      	ldr	r3, [r0, #16]
{
 8001de4:	4604      	mov	r4, r0
	int ret;

	data->dev = dev;
 8001de6:	6058      	str	r0, [r3, #4]
 8001de8:	4d08      	ldr	r5, [pc, #32]	; (8001e0c <gpio_stm32_init+0x2c>)
 8001dea:	4628      	mov	r0, r5
 8001dec:	f003 fa3d 	bl	800526a <z_device_is_ready>

	if (!device_is_ready(DEVICE_DT_GET(STM32_CLOCK_CONTROL_NODE))) {
 8001df0:	b140      	cbz	r0, 8001e04 <gpio_stm32_init+0x24>
					(clock_control_subsys_t *)&cfg->pclken);
 8001df2:	6861      	ldr	r1, [r4, #4]
				   clock_control_subsys_t sys)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	return api->on(dev, sys);
 8001df4:	68ab      	ldr	r3, [r5, #8]
 8001df6:	310c      	adds	r1, #12
 8001df8:	681b      	ldr	r3, [r3, #0]
 8001dfa:	4628      	mov	r0, r5
 8001dfc:	4798      	blx	r3
	LL_PWR_EnableVddIO2();
	z_stm32_hsem_unlock(CFG_HW_RCC_SEMID);
#endif
	/* enable port clock (if runtime PM is not enabled) */
	ret = gpio_stm32_clock_request(dev, !IS_ENABLED(CONFIG_PM_DEVICE_RUNTIME));
	if (ret < 0) {
 8001dfe:	ea00 70e0 	and.w	r0, r0, r0, asr #31

	pm_device_init_suspended(dev);
	(void)pm_device_runtime_enable(dev);

	return 0;
}
 8001e02:	bd38      	pop	{r3, r4, r5, pc}
		return -ENODEV;
 8001e04:	f06f 0012 	mvn.w	r0, #18
 8001e08:	e7fb      	b.n	8001e02 <gpio_stm32_init+0x22>
 8001e0a:	bf00      	nop
 8001e0c:	080053ac 	.word	0x080053ac

08001e10 <gpio_stm32_isr>:
{
 8001e10:	b570      	push	{r4, r5, r6, lr}
 8001e12:	e9d1 6101 	ldrd	r6, r1, [r1, #4]
					const struct device *port,
					uint32_t pins)
{
	struct gpio_callback *cb, *tmp;

	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
 8001e16:	b119      	cbz	r1, 8001e20 <gpio_stm32_isr+0x10>
	gpio_fire_callbacks(&data->cb, data->dev, BIT(line));
 8001e18:	2501      	movs	r5, #1
	return node->next;
 8001e1a:	680c      	ldr	r4, [r1, #0]
 8001e1c:	4085      	lsls	r5, r0
 8001e1e:	b901      	cbnz	r1, 8001e22 <gpio_stm32_isr+0x12>
}
 8001e20:	bd70      	pop	{r4, r5, r6, pc}
		if (cb->pin_mask & pins) {
 8001e22:	688a      	ldr	r2, [r1, #8]
 8001e24:	402a      	ands	r2, r5
 8001e26:	d010      	beq.n	8001e4a <gpio_stm32_isr+0x3a>
			__ASSERT(cb->handler, "No callback handler!");
 8001e28:	684b      	ldr	r3, [r1, #4]
 8001e2a:	b963      	cbnz	r3, 8001e46 <gpio_stm32_isr+0x36>
 8001e2c:	490a      	ldr	r1, [pc, #40]	; (8001e58 <gpio_stm32_isr+0x48>)
 8001e2e:	4a0b      	ldr	r2, [pc, #44]	; (8001e5c <gpio_stm32_isr+0x4c>)
 8001e30:	480b      	ldr	r0, [pc, #44]	; (8001e60 <gpio_stm32_isr+0x50>)
 8001e32:	234d      	movs	r3, #77	; 0x4d
 8001e34:	f002 fe67 	bl	8004b06 <assert_print>
 8001e38:	480a      	ldr	r0, [pc, #40]	; (8001e64 <gpio_stm32_isr+0x54>)
 8001e3a:	f002 fe64 	bl	8004b06 <assert_print>
 8001e3e:	4807      	ldr	r0, [pc, #28]	; (8001e5c <gpio_stm32_isr+0x4c>)
 8001e40:	214d      	movs	r1, #77	; 0x4d
 8001e42:	f002 fe59 	bl	8004af8 <assert_post_action>
			cb->handler(port, cb, cb->pin_mask & pins);
 8001e46:	4630      	mov	r0, r6
 8001e48:	4798      	blx	r3
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
 8001e4a:	b11c      	cbz	r4, 8001e54 <gpio_stm32_isr+0x44>
 8001e4c:	6823      	ldr	r3, [r4, #0]
 8001e4e:	4621      	mov	r1, r4
 8001e50:	461c      	mov	r4, r3
 8001e52:	e7e4      	b.n	8001e1e <gpio_stm32_isr+0xe>
 8001e54:	4623      	mov	r3, r4
 8001e56:	e7fa      	b.n	8001e4e <gpio_stm32_isr+0x3e>
 8001e58:	080060c1 	.word	0x080060c1
 8001e5c:	08006044 	.word	0x08006044
 8001e60:	08005ca7 	.word	0x08005ca7
 8001e64:	080060aa 	.word	0x080060aa

08001e68 <gpio_stm32_pin_interrupt_configure>:
{
 8001e68:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
 8001e6a:	4617      	mov	r7, r2
	if (mode == GPIO_INT_MODE_DISABLED) {
 8001e6c:	f5b7 1f00 	cmp.w	r7, #2097152	; 0x200000
	const struct gpio_stm32_config *cfg = dev->config;
 8001e70:	6846      	ldr	r6, [r0, #4]
	struct gpio_stm32_data *data = dev->data;
 8001e72:	6902      	ldr	r2, [r0, #16]
{
 8001e74:	460c      	mov	r4, r1
 8001e76:	461d      	mov	r5, r3
	if (mode == GPIO_INT_MODE_DISABLED) {
 8001e78:	d124      	bne.n	8001ec4 <gpio_stm32_pin_interrupt_configure+0x5c>
	return (0xF << ((pin % 4 * 4) + 16)) | (pin / 4);
 8001e7a:	f001 0203 	and.w	r2, r1, #3
 8001e7e:	3204      	adds	r2, #4
 8001e80:	0092      	lsls	r2, r2, #2
 8001e82:	230f      	movs	r3, #15
 8001e84:	4093      	lsls	r3, r2
 8001e86:	ea43 0391 	orr.w	r3, r3, r1, lsr #2
  return (uint32_t)(READ_BIT(SYSCFG->EXTICR[Line & 0xFF], (Line >> 16)) >> POSITION_VAL(Line >> 16));
 8001e8a:	b2da      	uxtb	r2, r3
 8001e8c:	4933      	ldr	r1, [pc, #204]	; (8001f5c <gpio_stm32_pin_interrupt_configure+0xf4>)
 8001e8e:	3202      	adds	r2, #2
 8001e90:	f851 2022 	ldr.w	r2, [r1, r2, lsl #2]
 8001e94:	0c19      	lsrs	r1, r3, #16
 8001e96:	ea02 4313 	and.w	r3, r2, r3, lsr #16
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8001e9a:	fa91 f2a1 	rbit	r2, r1
  return __builtin_clz(value);
 8001e9e:	fab2 f282 	clz	r2, r2
 8001ea2:	40d3      	lsrs	r3, r2
		if (gpio_stm32_get_exti_source(pin) == cfg->port) {
 8001ea4:	68b2      	ldr	r2, [r6, #8]
 8001ea6:	429a      	cmp	r2, r3
 8001ea8:	d109      	bne.n	8001ebe <gpio_stm32_pin_interrupt_configure+0x56>
			stm32_exti_disable(pin);
 8001eaa:	4620      	mov	r0, r4
 8001eac:	f7ff fdd8 	bl	8001a60 <stm32_exti_disable>
			stm32_exti_unset_callback(pin);
 8001eb0:	4620      	mov	r0, r4
 8001eb2:	f7ff fe23 	bl	8001afc <stm32_exti_unset_callback>
			stm32_exti_trigger(pin, STM32_EXTI_TRIG_NONE);
 8001eb6:	2100      	movs	r1, #0
 8001eb8:	4620      	mov	r0, r4
 8001eba:	f7ff fddd 	bl	8001a78 <stm32_exti_trigger>
	int err = 0;
 8001ebe:	2000      	movs	r0, #0
}
 8001ec0:	b003      	add	sp, #12
 8001ec2:	bdf0      	pop	{r4, r5, r6, r7, pc}
	if (mode == GPIO_INT_MODE_LEVEL) {
 8001ec4:	f5b7 0f80 	cmp.w	r7, #4194304	; 0x400000
 8001ec8:	d041      	beq.n	8001f4e <gpio_stm32_pin_interrupt_configure+0xe6>
	if (stm32_exti_set_callback(pin, gpio_stm32_isr, data) != 0) {
 8001eca:	4925      	ldr	r1, [pc, #148]	; (8001f60 <gpio_stm32_pin_interrupt_configure+0xf8>)
 8001ecc:	4620      	mov	r0, r4
 8001ece:	f7ff fe03 	bl	8001ad8 <stm32_exti_set_callback>
 8001ed2:	2800      	cmp	r0, #0
 8001ed4:	d13e      	bne.n	8001f54 <gpio_stm32_pin_interrupt_configure+0xec>
	struct stm32_pclken pclken = {
 8001ed6:	4a23      	ldr	r2, [pc, #140]	; (8001f64 <gpio_stm32_pin_interrupt_configure+0xfc>)
	gpio_stm32_enable_int(cfg->port, pin);
 8001ed8:	68b6      	ldr	r6, [r6, #8]
	struct stm32_pclken pclken = {
 8001eda:	e892 0003 	ldmia.w	r2, {r0, r1}
 8001ede:	466b      	mov	r3, sp
 8001ee0:	e883 0003 	stmia.w	r3, {r0, r1}
 8001ee4:	4820      	ldr	r0, [pc, #128]	; (8001f68 <gpio_stm32_pin_interrupt_configure+0x100>)
 8001ee6:	6882      	ldr	r2, [r0, #8]
 8001ee8:	4619      	mov	r1, r3
 8001eea:	6812      	ldr	r2, [r2, #0]
 8001eec:	4790      	blx	r2
	if (ret != 0) {
 8001eee:	b9c0      	cbnz	r0, 8001f22 <gpio_stm32_pin_interrupt_configure+0xba>
	return (0xF << ((pin % 4 * 4) + 16)) | (pin / 4);
 8001ef0:	f004 0303 	and.w	r3, r4, #3
 8001ef4:	3304      	adds	r3, #4
 8001ef6:	009b      	lsls	r3, r3, #2
 8001ef8:	220f      	movs	r2, #15
 8001efa:	409a      	lsls	r2, r3
 8001efc:	ea42 0294 	orr.w	r2, r2, r4, lsr #2
  MODIFY_REG(SYSCFG->EXTICR[Line & 0xFF], (Line >> 16), Port << POSITION_VAL((Line >> 16)));
 8001f00:	b2d3      	uxtb	r3, r2
 8001f02:	009b      	lsls	r3, r3, #2
 8001f04:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
 8001f08:	f503 339c 	add.w	r3, r3, #79872	; 0x13800
 8001f0c:	0c11      	lsrs	r1, r2, #16
 8001f0e:	6898      	ldr	r0, [r3, #8]
 8001f10:	ea20 4012 	bic.w	r0, r0, r2, lsr #16
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8001f14:	fa91 f2a1 	rbit	r2, r1
  return __builtin_clz(value);
 8001f18:	fab2 f282 	clz	r2, r2
 8001f1c:	4096      	lsls	r6, r2
 8001f1e:	4306      	orrs	r6, r0
 8001f20:	609e      	str	r6, [r3, #8]
	switch (trig) {
 8001f22:	f1b5 6f80 	cmp.w	r5, #67108864	; 0x4000000
 8001f26:	d00e      	beq.n	8001f46 <gpio_stm32_pin_interrupt_configure+0xde>
 8001f28:	f1b5 6fc0 	cmp.w	r5, #100663296	; 0x6000000
 8001f2c:	d00d      	beq.n	8001f4a <gpio_stm32_pin_interrupt_configure+0xe2>
 8001f2e:	f105 437e 	add.w	r3, r5, #4261412864	; 0xfe000000
 8001f32:	4259      	negs	r1, r3
 8001f34:	4159      	adcs	r1, r3
 8001f36:	0049      	lsls	r1, r1, #1
	stm32_exti_trigger(pin, edge);
 8001f38:	4620      	mov	r0, r4
 8001f3a:	f7ff fd9d 	bl	8001a78 <stm32_exti_trigger>
	stm32_exti_enable(pin);
 8001f3e:	4620      	mov	r0, r4
 8001f40:	f7ff fd80 	bl	8001a44 <stm32_exti_enable>
 8001f44:	e7bb      	b.n	8001ebe <gpio_stm32_pin_interrupt_configure+0x56>
		edge = STM32_EXTI_TRIG_RISING;
 8001f46:	2101      	movs	r1, #1
 8001f48:	e7f6      	b.n	8001f38 <gpio_stm32_pin_interrupt_configure+0xd0>
		edge = STM32_EXTI_TRIG_BOTH;
 8001f4a:	2103      	movs	r1, #3
 8001f4c:	e7f4      	b.n	8001f38 <gpio_stm32_pin_interrupt_configure+0xd0>
		err = -ENOTSUP;
 8001f4e:	f06f 0085 	mvn.w	r0, #133	; 0x85
 8001f52:	e7b5      	b.n	8001ec0 <gpio_stm32_pin_interrupt_configure+0x58>
		err = -EBUSY;
 8001f54:	f06f 000f 	mvn.w	r0, #15
	return err;
 8001f58:	e7b2      	b.n	8001ec0 <gpio_stm32_pin_interrupt_configure+0x58>
 8001f5a:	bf00      	nop
 8001f5c:	40013800 	.word	0x40013800
 8001f60:	08001e11 	.word	0x08001e11
 8001f64:	08005850 	.word	0x08005850
 8001f68:	080053ac 	.word	0x080053ac

08001f6c <uart_stm32_irq_err_enable>:
	return LL_USART_IsActiveFlag_RXNE(config->usart);
}

static void uart_stm32_irq_err_enable(const struct device *dev)
{
	const struct uart_stm32_config *config = dev->config;
 8001f6c:	6842      	ldr	r2, [r0, #4]

	/* Enable FE, ORE interruptions */
	LL_USART_EnableIT_ERROR(config->usart);
 8001f6e:	6811      	ldr	r1, [r2, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 8001f70:	f101 0314 	add.w	r3, r1, #20
 8001f74:	e853 3f00 	ldrex	r3, [r3]
  * @param  USARTx USART Instance
  * @retval None
  */
__STATIC_INLINE void LL_USART_EnableIT_ERROR(USART_TypeDef *USARTx)
{
  ATOMIC_SET_BIT(USARTx->CR3, USART_CR3_EIE);
 8001f78:	f043 0301 	orr.w	r3, r3, #1
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 8001f7c:	f101 0c14 	add.w	ip, r1, #20
 8001f80:	e84c 3000 	strex	r0, r3, [ip]
 8001f84:	2800      	cmp	r0, #0
 8001f86:	d1f3      	bne.n	8001f70 <uart_stm32_irq_err_enable+0x4>
#if !defined(CONFIG_SOC_SERIES_STM32F0X) || defined(USART_LIN_SUPPORT)
	/* Enable Line break detection */
	if (IS_UART_LIN_INSTANCE(config->usart)) {
 8001f88:	6813      	ldr	r3, [r2, #0]
 8001f8a:	490e      	ldr	r1, [pc, #56]	; (8001fc4 <uart_stm32_irq_err_enable+0x58>)
 8001f8c:	428b      	cmp	r3, r1
 8001f8e:	d007      	beq.n	8001fa0 <uart_stm32_irq_err_enable+0x34>
 8001f90:	f5a1 414c 	sub.w	r1, r1, #52224	; 0xcc00
 8001f94:	428b      	cmp	r3, r1
 8001f96:	d003      	beq.n	8001fa0 <uart_stm32_irq_err_enable+0x34>
 8001f98:	f501 4150 	add.w	r1, r1, #53248	; 0xd000
 8001f9c:	428b      	cmp	r3, r1
 8001f9e:	d103      	bne.n	8001fa8 <uart_stm32_irq_err_enable+0x3c>
  SET_BIT(USARTx->CR2, USART_CR2_LBDIE);
 8001fa0:	6919      	ldr	r1, [r3, #16]
 8001fa2:	f041 0140 	orr.w	r1, r1, #64	; 0x40
 8001fa6:	6119      	str	r1, [r3, #16]
		LL_USART_EnableIT_LBD(config->usart);
	}
#endif
	/* Enable parity error interruption */
	LL_USART_EnableIT_PE(config->usart);
 8001fa8:	6812      	ldr	r2, [r2, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 8001faa:	f102 030c 	add.w	r3, r2, #12
 8001fae:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_SET_BIT(USARTx->CR1, USART_CR1_PEIE);
 8001fb2:	f443 7380 	orr.w	r3, r3, #256	; 0x100
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 8001fb6:	f102 000c 	add.w	r0, r2, #12
 8001fba:	e840 3100 	strex	r1, r3, [r0]
 8001fbe:	2900      	cmp	r1, #0
 8001fc0:	d1f3      	bne.n	8001faa <uart_stm32_irq_err_enable+0x3e>
}
 8001fc2:	4770      	bx	lr
 8001fc4:	40011000 	.word	0x40011000

08001fc8 <uart_stm32_irq_err_disable>:

static void uart_stm32_irq_err_disable(const struct device *dev)
{
	const struct uart_stm32_config *config = dev->config;
 8001fc8:	6842      	ldr	r2, [r0, #4]

	/* Disable FE, ORE interruptions */
	LL_USART_DisableIT_ERROR(config->usart);
 8001fca:	6811      	ldr	r1, [r2, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 8001fcc:	f101 0314 	add.w	r3, r1, #20
 8001fd0:	e853 3f00 	ldrex	r3, [r3]
  * @param  USARTx USART Instance
  * @retval None
  */
__STATIC_INLINE void LL_USART_DisableIT_ERROR(USART_TypeDef *USARTx)
{
  ATOMIC_CLEAR_BIT(USARTx->CR3, USART_CR3_EIE);
 8001fd4:	f023 0301 	bic.w	r3, r3, #1
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 8001fd8:	f101 0c14 	add.w	ip, r1, #20
 8001fdc:	e84c 3000 	strex	r0, r3, [ip]
 8001fe0:	2800      	cmp	r0, #0
 8001fe2:	d1f3      	bne.n	8001fcc <uart_stm32_irq_err_disable+0x4>
#if !defined(CONFIG_SOC_SERIES_STM32F0X) || defined(USART_LIN_SUPPORT)
	/* Disable Line break detection */
	if (IS_UART_LIN_INSTANCE(config->usart)) {
 8001fe4:	6813      	ldr	r3, [r2, #0]
 8001fe6:	490e      	ldr	r1, [pc, #56]	; (8002020 <uart_stm32_irq_err_disable+0x58>)
 8001fe8:	428b      	cmp	r3, r1
 8001fea:	d007      	beq.n	8001ffc <uart_stm32_irq_err_disable+0x34>
 8001fec:	f5a1 414c 	sub.w	r1, r1, #52224	; 0xcc00
 8001ff0:	428b      	cmp	r3, r1
 8001ff2:	d003      	beq.n	8001ffc <uart_stm32_irq_err_disable+0x34>
 8001ff4:	f501 4150 	add.w	r1, r1, #53248	; 0xd000
 8001ff8:	428b      	cmp	r3, r1
 8001ffa:	d103      	bne.n	8002004 <uart_stm32_irq_err_disable+0x3c>
  CLEAR_BIT(USARTx->CR2, USART_CR2_LBDIE);
 8001ffc:	6919      	ldr	r1, [r3, #16]
 8001ffe:	f021 0140 	bic.w	r1, r1, #64	; 0x40
 8002002:	6119      	str	r1, [r3, #16]
		LL_USART_DisableIT_LBD(config->usart);
	}
#endif
	/* Disable parity error interruption */
	LL_USART_DisableIT_PE(config->usart);
 8002004:	6812      	ldr	r2, [r2, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 8002006:	f102 030c 	add.w	r3, r2, #12
 800200a:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_CLEAR_BIT(USARTx->CR1, USART_CR1_PEIE);
 800200e:	f423 7380 	bic.w	r3, r3, #256	; 0x100
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 8002012:	f102 000c 	add.w	r0, r2, #12
 8002016:	e840 3100 	strex	r1, r3, [r0]
 800201a:	2900      	cmp	r1, #0
 800201c:	d1f3      	bne.n	8002006 <uart_stm32_irq_err_disable+0x3e>
}
 800201e:	4770      	bx	lr
 8002020:	40011000 	.word	0x40011000

08002024 <uart_stm32_set_baudrate>:
{
 8002024:	b573      	push	{r0, r1, r4, r5, r6, lr}
		if (clock_control_get_rate(data->clock,
 8002026:	6903      	ldr	r3, [r0, #16]
	const struct uart_stm32_config *config = dev->config;
 8002028:	6844      	ldr	r4, [r0, #4]
		if (clock_control_get_rate(data->clock,
 800202a:	6858      	ldr	r0, [r3, #4]
					 uint32_t *rate)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	if (api->get_rate == NULL) {
 800202c:	6883      	ldr	r3, [r0, #8]
 800202e:	68db      	ldr	r3, [r3, #12]
{
 8002030:	460e      	mov	r6, r1
					   (clock_control_subsys_t)&config->pclken[0],
 8002032:	6861      	ldr	r1, [r4, #4]
 8002034:	b37b      	cbz	r3, 8002096 <uart_stm32_set_baudrate+0x72>
		return -ENOSYS;
	}

	return api->get_rate(dev, sys, rate);
 8002036:	aa01      	add	r2, sp, #4
 8002038:	4798      	blx	r3
		if (clock_control_get_rate(data->clock,
 800203a:	2800      	cmp	r0, #0
 800203c:	db2b      	blt.n	8002096 <uart_stm32_set_baudrate+0x72>
		LL_USART_SetOverSampling(config->usart,
 800203e:	6822      	ldr	r2, [r4, #0]
    USARTx->BRR = (uint16_t)(__LL_USART_DIV_SAMPLING16(PeriphClk, BaudRate));
 8002040:	9801      	ldr	r0, [sp, #4]
  MODIFY_REG(USARTx->CR1, USART_CR1_OVER8, OverSampling);
 8002042:	68d3      	ldr	r3, [r2, #12]
    USARTx->BRR = (uint16_t)(__LL_USART_DIV_SAMPLING16(PeriphClk, BaudRate));
 8002044:	2119      	movs	r1, #25
  MODIFY_REG(USARTx->CR1, USART_CR1_OVER8, OverSampling);
 8002046:	f423 4300 	bic.w	r3, r3, #32768	; 0x8000
 800204a:	60d3      	str	r3, [r2, #12]
    USARTx->BRR = (uint16_t)(__LL_USART_DIV_SAMPLING16(PeriphClk, BaudRate));
 800204c:	fba0 0101 	umull	r0, r1, r0, r1
 8002050:	00b2      	lsls	r2, r6, #2
 8002052:	0fb3      	lsrs	r3, r6, #30
 8002054:	f7fe f8a0 	bl	8000198 <__aeabi_uldivmod>
 8002058:	2264      	movs	r2, #100	; 0x64
 800205a:	fbb0 f1f2 	udiv	r1, r0, r2
 800205e:	fb02 0311 	mls	r3, r2, r1, r0
 8002062:	011b      	lsls	r3, r3, #4
		LL_USART_SetBaudRate(config->usart,
 8002064:	6825      	ldr	r5, [r4, #0]
 8002066:	3332      	adds	r3, #50	; 0x32
 8002068:	fbb3 f3f2 	udiv	r3, r3, r2
 800206c:	eb03 1301 	add.w	r3, r3, r1, lsl #4
 8002070:	b29b      	uxth	r3, r3
 8002072:	60ab      	str	r3, [r5, #8]
		__ASSERT(LL_USART_ReadReg(config->usart, BRR) > 16,
 8002074:	6823      	ldr	r3, [r4, #0]
 8002076:	689b      	ldr	r3, [r3, #8]
 8002078:	2b10      	cmp	r3, #16
 800207a:	d80c      	bhi.n	8002096 <uart_stm32_set_baudrate+0x72>
 800207c:	4907      	ldr	r1, [pc, #28]	; (800209c <uart_stm32_set_baudrate+0x78>)
 800207e:	4a08      	ldr	r2, [pc, #32]	; (80020a0 <uart_stm32_set_baudrate+0x7c>)
 8002080:	4808      	ldr	r0, [pc, #32]	; (80020a4 <uart_stm32_set_baudrate+0x80>)
 8002082:	23be      	movs	r3, #190	; 0xbe
 8002084:	f002 fd3f 	bl	8004b06 <assert_print>
 8002088:	4807      	ldr	r0, [pc, #28]	; (80020a8 <uart_stm32_set_baudrate+0x84>)
 800208a:	f002 fd3c 	bl	8004b06 <assert_print>
 800208e:	4804      	ldr	r0, [pc, #16]	; (80020a0 <uart_stm32_set_baudrate+0x7c>)
 8002090:	21be      	movs	r1, #190	; 0xbe
 8002092:	f002 fd31 	bl	8004af8 <assert_post_action>
}
 8002096:	b002      	add	sp, #8
 8002098:	bd70      	pop	{r4, r5, r6, pc}
 800209a:	bf00      	nop
 800209c:	0800616c 	.word	0x0800616c
 80020a0:	0800613d 	.word	0x0800613d
 80020a4:	08005ca7 	.word	0x08005ca7
 80020a8:	08006188 	.word	0x08006188

080020ac <uart_stm32_init>:
 * @param dev UART device struct
 *
 * @return 0
 */
static int uart_stm32_init(const struct device *dev)
{
 80020ac:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
	const struct uart_stm32_config *config = dev->config;
	struct uart_stm32_data *data = dev->data;
 80020ae:	6907      	ldr	r7, [r0, #16]
	const struct uart_stm32_config *config = dev->config;
 80020b0:	6844      	ldr	r4, [r0, #4]
{
 80020b2:	4606      	mov	r6, r0
	data->clock = clk;
 80020b4:	483a      	ldr	r0, [pc, #232]	; (80021a0 <uart_stm32_init+0xf4>)
 80020b6:	6078      	str	r0, [r7, #4]
 80020b8:	f003 f8d7 	bl	800526a <z_device_is_ready>
	uint32_t ll_datawidth;
	int err;

	__uart_stm32_get_clock(dev);

	if (!device_is_ready(data->clock)) {
 80020bc:	b920      	cbnz	r0, 80020c8 <uart_stm32_init+0x1c>
		LOG_ERR("clock control device not ready");
		return -ENODEV;
 80020be:	f06f 0512 	mvn.w	r5, #18
#ifdef CONFIG_UART_ASYNC_API
	return uart_stm32_async_init(dev);
#else
	return 0;
#endif
}
 80020c2:	4628      	mov	r0, r5
 80020c4:	b003      	add	sp, #12
 80020c6:	bdf0      	pop	{r4, r5, r6, r7, pc}
	err = clock_control_on(data->clock, (clock_control_subsys_t)&config->pclken[0]);
 80020c8:	6878      	ldr	r0, [r7, #4]
	return api->on(dev, sys);
 80020ca:	6861      	ldr	r1, [r4, #4]
 80020cc:	6883      	ldr	r3, [r0, #8]
 80020ce:	681b      	ldr	r3, [r3, #0]
 80020d0:	4798      	blx	r3
	if (err != 0) {
 80020d2:	4605      	mov	r5, r0
 80020d4:	2800      	cmp	r0, #0
 80020d6:	d1f4      	bne.n	80020c2 <uart_stm32_init+0x16>
				      uint8_t id)
{
	int ret;
	const struct pinctrl_state *state;

	ret = pinctrl_lookup_state(config, id, &state);
 80020d8:	4601      	mov	r1, r0
 80020da:	aa01      	add	r2, sp, #4
 80020dc:	69a0      	ldr	r0, [r4, #24]
 80020de:	f003 f876 	bl	80051ce <pinctrl_lookup_state>
	if (ret < 0) {
 80020e2:	2800      	cmp	r0, #0
 80020e4:	da01      	bge.n	80020ea <uart_stm32_init+0x3e>
 80020e6:	4605      	mov	r5, r0
 80020e8:	e7eb      	b.n	80020c2 <uart_stm32_init+0x16>
		return ret;
	}

	return pinctrl_apply_state_direct(config, state);
 80020ea:	9b01      	ldr	r3, [sp, #4]
	return pinctrl_configure_pins(state->pins, state->pin_cnt, reg);
 80020ec:	462a      	mov	r2, r5
 80020ee:	7919      	ldrb	r1, [r3, #4]
 80020f0:	6818      	ldr	r0, [r3, #0]
 80020f2:	f000 fa53 	bl	800259c <pinctrl_configure_pins>
	if (err < 0) {
 80020f6:	2800      	cmp	r0, #0
 80020f8:	dbf5      	blt.n	80020e6 <uart_stm32_init+0x3a>
	LL_USART_Disable(config->usart);
 80020fa:	6822      	ldr	r2, [r4, #0]
  CLEAR_BIT(USARTx->CR1, USART_CR1_UE);
 80020fc:	68d3      	ldr	r3, [r2, #12]
 80020fe:	f423 5300 	bic.w	r3, r3, #8192	; 0x2000
 8002102:	60d3      	str	r3, [r2, #12]
	if (!device_is_ready(data->reset.dev)) {
 8002104:	68b8      	ldr	r0, [r7, #8]
 8002106:	f003 f8b0 	bl	800526a <z_device_is_ready>
 800210a:	2800      	cmp	r0, #0
 800210c:	d0d7      	beq.n	80020be <uart_stm32_init+0x12>
 *
 * @return a value from reset_line_toggle()
 */
static inline int reset_line_toggle_dt(const struct reset_dt_spec *spec)
{
	return reset_line_toggle(spec->dev, spec->id);
 800210e:	e9d7 0102 	ldrd	r0, r1, [r7, #8]
	if (api->line_toggle == NULL) {
 8002112:	6883      	ldr	r3, [r0, #8]
 8002114:	68db      	ldr	r3, [r3, #12]
 8002116:	b103      	cbz	r3, 800211a <uart_stm32_init+0x6e>
	return api->line_toggle(dev, id);
 8002118:	4798      	blx	r3
	LL_USART_SetTransferDirection(config->usart,
 800211a:	6821      	ldr	r1, [r4, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 800211c:	f101 030c 	add.w	r3, r1, #12
 8002120:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_MODIFY_REG(USARTx->CR1, USART_CR1_RE | USART_CR1_TE, TransferDirection);
 8002124:	f043 030c 	orr.w	r3, r3, #12
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 8002128:	f101 000c 	add.w	r0, r1, #12
 800212c:	e840 3200 	strex	r2, r3, [r0]
 8002130:	2a00      	cmp	r2, #0
 8002132:	d1f3      	bne.n	800211c <uart_stm32_init+0x70>
	if (config->parity == 2) {
 8002134:	6923      	ldr	r3, [r4, #16]
 8002136:	2b02      	cmp	r3, #2
 8002138:	d02d      	beq.n	8002196 <uart_stm32_init+0xea>
		ll_datawidth = LL_USART_DATAWIDTH_9B;
 800213a:	2b01      	cmp	r3, #1
 800213c:	bf12      	itee	ne
 800213e:	2000      	movne	r0, #0
 8002140:	f44f 5080 	moveq.w	r0, #4096	; 0x1000
 8002144:	f44f 62c0 	moveq.w	r2, #1536	; 0x600
	LL_USART_ConfigCharacter(config->usart,
 8002148:	6821      	ldr	r1, [r4, #0]
  MODIFY_REG(USARTx->CR1, USART_CR1_PS | USART_CR1_PCE | USART_CR1_M, Parity | DataWidth);
 800214a:	68cb      	ldr	r3, [r1, #12]
 800214c:	4310      	orrs	r0, r2
 800214e:	f423 53b0 	bic.w	r3, r3, #5632	; 0x1600
 8002152:	4303      	orrs	r3, r0
 8002154:	60cb      	str	r3, [r1, #12]
  MODIFY_REG(USARTx->CR2, USART_CR2_STOP, StopBits);
 8002156:	690b      	ldr	r3, [r1, #16]
 8002158:	f423 5340 	bic.w	r3, r3, #12288	; 0x3000
 800215c:	610b      	str	r3, [r1, #16]
	if (config->hw_flow_control) {
 800215e:	7b23      	ldrb	r3, [r4, #12]
 8002160:	b12b      	cbz	r3, 800216e <uart_stm32_init+0xc2>
	LL_USART_SetHWFlowCtrl(config->usart, hwctrl);
 8002162:	6873      	ldr	r3, [r6, #4]
 8002164:	681a      	ldr	r2, [r3, #0]
  MODIFY_REG(USARTx->CR3, USART_CR3_RTSE | USART_CR3_CTSE, HardwareFlowControl);
 8002166:	6953      	ldr	r3, [r2, #20]
 8002168:	f443 7340 	orr.w	r3, r3, #768	; 0x300
 800216c:	6153      	str	r3, [r2, #20]
	uart_stm32_set_baudrate(dev, data->baud_rate);
 800216e:	6839      	ldr	r1, [r7, #0]
 8002170:	4630      	mov	r0, r6
 8002172:	f7ff ff57 	bl	8002024 <uart_stm32_set_baudrate>
	if (config->single_wire) {
 8002176:	7d23      	ldrb	r3, [r4, #20]
 8002178:	b123      	cbz	r3, 8002184 <uart_stm32_init+0xd8>
		LL_USART_EnableHalfDuplex(config->usart);
 800217a:	6822      	ldr	r2, [r4, #0]
  SET_BIT(USARTx->CR3, USART_CR3_HDSEL);
 800217c:	6953      	ldr	r3, [r2, #20]
 800217e:	f043 0308 	orr.w	r3, r3, #8
 8002182:	6153      	str	r3, [r2, #20]
	LL_USART_Enable(config->usart);
 8002184:	6822      	ldr	r2, [r4, #0]
  SET_BIT(USARTx->CR1, USART_CR1_UE);
 8002186:	68d3      	ldr	r3, [r2, #12]
 8002188:	f443 5300 	orr.w	r3, r3, #8192	; 0x2000
 800218c:	60d3      	str	r3, [r2, #12]
	config->irq_config_func(dev);
 800218e:	69e3      	ldr	r3, [r4, #28]
 8002190:	4630      	mov	r0, r6
 8002192:	4798      	blx	r3
	return 0;
 8002194:	e795      	b.n	80020c2 <uart_stm32_init+0x16>
		ll_datawidth = LL_USART_DATAWIDTH_9B;
 8002196:	f44f 5080 	mov.w	r0, #4096	; 0x1000
		ll_parity = LL_USART_PARITY_EVEN;
 800219a:	f44f 6280 	mov.w	r2, #1024	; 0x400
 800219e:	e7d3      	b.n	8002148 <uart_stm32_init+0x9c>
 80021a0:	080053ac 	.word	0x080053ac

080021a4 <uart_stm32_configure>:
{
 80021a4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	const uint32_t parity = uart_stm32_cfg2ll_parity(cfg->parity);
 80021a8:	790b      	ldrb	r3, [r1, #4]
	const struct uart_stm32_config *config = dev->config;
 80021aa:	6845      	ldr	r5, [r0, #4]
	struct uart_stm32_data *data = dev->data;
 80021ac:	6906      	ldr	r6, [r0, #16]
	switch (parity) {
 80021ae:	2b01      	cmp	r3, #1
{
 80021b0:	460c      	mov	r4, r1
	switch (parity) {
 80021b2:	d07d      	beq.n	80022b0 <uart_stm32_configure+0x10c>
 80021b4:	1e9a      	subs	r2, r3, #2
 80021b6:	4257      	negs	r7, r2
 80021b8:	4157      	adcs	r7, r2
 80021ba:	02bf      	lsls	r7, r7, #10
	const uint32_t stopbits = uart_stm32_cfg2ll_stopbits(cfg->stop_bits);
 80021bc:	7962      	ldrb	r2, [r4, #5]
	const uint32_t databits = uart_stm32_cfg2ll_databits(cfg->data_bits,
 80021be:	f894 8006 	ldrb.w	r8, [r4, #6]
 80021c2:	2a02      	cmp	r2, #2
 80021c4:	bf96      	itet	ls
 80021c6:	494c      	ldrls	r1, [pc, #304]	; (80022f8 <uart_stm32_configure+0x154>)
	const uint32_t stopbits = uart_stm32_cfg2ll_stopbits(cfg->stop_bits);
 80021c8:	f44f 5c00 	movhi.w	ip, #8192	; 0x2000
 80021cc:	f831 c012 	ldrhls.w	ip, [r1, r2, lsl #1]
	switch (db) {
 80021d0:	f1b8 0f04 	cmp.w	r8, #4
 80021d4:	d07b      	beq.n	80022ce <uart_stm32_configure+0x12a>
	const uint32_t flowctrl = uart_stm32_cfg2ll_hwctrl(cfg->flow_ctrl);
 80021d6:	f894 e007 	ldrb.w	lr, [r4, #7]
		if (p == UART_CFG_PARITY_NONE) {
 80021da:	2b00      	cmp	r3, #0
 80021dc:	d16b      	bne.n	80022b6 <uart_stm32_configure+0x112>
	if (fc == UART_CFG_FLOW_CTRL_RTS_CTS) {
 80021de:	f1be 0f01 	cmp.w	lr, #1
 80021e2:	f022 0202 	bic.w	r2, r2, #2
 80021e6:	d07f      	beq.n	80022e8 <uart_stm32_configure+0x144>
	if (cfg->stop_bits == UART_CFG_STOP_BITS_0_5) {
 80021e8:	2a00      	cmp	r2, #0
 80021ea:	d070      	beq.n	80022ce <uart_stm32_configure+0x12a>
	if ((cfg->data_bits == UART_CFG_DATA_BITS_5) ||
 80021ec:	f1b8 0f02 	cmp.w	r8, #2
 80021f0:	d96d      	bls.n	80022ce <uart_stm32_configure+0x12a>
	return LL_USART_HWCONTROL_NONE;
 80021f2:	4619      	mov	r1, r3
		if (!IS_UART_HWFLOW_INSTANCE(config->usart) ||
 80021f4:	f8d5 8000 	ldr.w	r8, [r5]
	if (cfg->flow_ctrl != UART_CFG_FLOW_CTRL_NONE) {
 80021f8:	f1be 0f00 	cmp.w	lr, #0
 80021fc:	d00d      	beq.n	800221a <uart_stm32_configure+0x76>
		if (!IS_UART_HWFLOW_INSTANCE(config->usart) ||
 80021fe:	4a3f      	ldr	r2, [pc, #252]	; (80022fc <uart_stm32_configure+0x158>)
 8002200:	4590      	cmp	r8, r2
 8002202:	d007      	beq.n	8002214 <uart_stm32_configure+0x70>
 8002204:	f5a2 424c 	sub.w	r2, r2, #52224	; 0xcc00
 8002208:	4590      	cmp	r8, r2
 800220a:	d003      	beq.n	8002214 <uart_stm32_configure+0x70>
 800220c:	f502 4250 	add.w	r2, r2, #53248	; 0xd000
 8002210:	4590      	cmp	r8, r2
 8002212:	d15c      	bne.n	80022ce <uart_stm32_configure+0x12a>
 8002214:	f1be 0f01 	cmp.w	lr, #1
 8002218:	d159      	bne.n	80022ce <uart_stm32_configure+0x12a>
  CLEAR_BIT(USARTx->CR1, USART_CR1_UE);
 800221a:	f8d8 200c 	ldr.w	r2, [r8, #12]
 800221e:	f422 5200 	bic.w	r2, r2, #8192	; 0x2000
 8002222:	f8c8 200c 	str.w	r2, [r8, #12]
	return LL_USART_GetParity(config->usart);
 8002226:	6842      	ldr	r2, [r0, #4]
 8002228:	f8d2 e000 	ldr.w	lr, [r2]
  return (uint32_t)(READ_BIT(USARTx->CR1, USART_CR1_PS | USART_CR1_PCE));
 800222c:	f8de 200c 	ldr.w	r2, [lr, #12]
 8002230:	f402 62c0 	and.w	r2, r2, #1536	; 0x600
	if (parity != uart_stm32_get_parity(dev)) {
 8002234:	4297      	cmp	r7, r2
  MODIFY_REG(USARTx->CR1, USART_CR1_PS | USART_CR1_PCE, Parity);
 8002236:	bf1f      	itttt	ne
 8002238:	f8de 200c 	ldrne.w	r2, [lr, #12]
 800223c:	f422 62c0 	bicne.w	r2, r2, #1536	; 0x600
 8002240:	433a      	orrne	r2, r7
 8002242:	f8ce 200c 	strne.w	r2, [lr, #12]
	return LL_USART_GetStopBitsLength(config->usart);
 8002246:	6842      	ldr	r2, [r0, #4]
 8002248:	6817      	ldr	r7, [r2, #0]
  return (uint32_t)(READ_BIT(USARTx->CR2, USART_CR2_STOP));
 800224a:	693a      	ldr	r2, [r7, #16]
 800224c:	f402 5240 	and.w	r2, r2, #12288	; 0x3000
	if (stopbits != uart_stm32_get_stopbits(dev)) {
 8002250:	4594      	cmp	ip, r2
  MODIFY_REG(USARTx->CR2, USART_CR2_STOP, StopBits);
 8002252:	bf1f      	itttt	ne
 8002254:	693a      	ldrne	r2, [r7, #16]
 8002256:	f422 5240 	bicne.w	r2, r2, #12288	; 0x3000
 800225a:	ea42 020c 	orrne.w	r2, r2, ip
 800225e:	613a      	strne	r2, [r7, #16]
	return LL_USART_GetDataWidth(config->usart);
 8002260:	6842      	ldr	r2, [r0, #4]
 8002262:	6817      	ldr	r7, [r2, #0]
  return (uint32_t)(READ_BIT(USARTx->CR1, USART_CR1_M));
 8002264:	68fa      	ldr	r2, [r7, #12]
 8002266:	f402 5280 	and.w	r2, r2, #4096	; 0x1000
	if (databits != uart_stm32_get_databits(dev)) {
 800226a:	429a      	cmp	r2, r3
  MODIFY_REG(USARTx->CR1, USART_CR1_M, DataWidth);
 800226c:	bf1f      	itttt	ne
 800226e:	68fa      	ldrne	r2, [r7, #12]
 8002270:	f422 5280 	bicne.w	r2, r2, #4096	; 0x1000
 8002274:	4313      	orrne	r3, r2
 8002276:	60fb      	strne	r3, [r7, #12]
	return LL_USART_GetHWFlowCtrl(config->usart);
 8002278:	6843      	ldr	r3, [r0, #4]
 800227a:	681a      	ldr	r2, [r3, #0]
  return (uint32_t)(READ_BIT(USARTx->CR3, USART_CR3_RTSE | USART_CR3_CTSE));
 800227c:	6953      	ldr	r3, [r2, #20]
 800227e:	f403 7340 	and.w	r3, r3, #768	; 0x300
	if (flowctrl != uart_stm32_get_hwctrl(dev)) {
 8002282:	4299      	cmp	r1, r3
  MODIFY_REG(USARTx->CR3, USART_CR3_RTSE | USART_CR3_CTSE, HardwareFlowControl);
 8002284:	bf1f      	itttt	ne
 8002286:	6953      	ldrne	r3, [r2, #20]
 8002288:	f423 7340 	bicne.w	r3, r3, #768	; 0x300
 800228c:	430b      	orrne	r3, r1
 800228e:	6153      	strne	r3, [r2, #20]
	if (cfg->baudrate != data->baud_rate) {
 8002290:	6821      	ldr	r1, [r4, #0]
 8002292:	6833      	ldr	r3, [r6, #0]
 8002294:	4299      	cmp	r1, r3
 8002296:	d003      	beq.n	80022a0 <uart_stm32_configure+0xfc>
		uart_stm32_set_baudrate(dev, cfg->baudrate);
 8002298:	f7ff fec4 	bl	8002024 <uart_stm32_set_baudrate>
		data->baud_rate = cfg->baudrate;
 800229c:	6823      	ldr	r3, [r4, #0]
 800229e:	6033      	str	r3, [r6, #0]
	LL_USART_Enable(config->usart);
 80022a0:	682a      	ldr	r2, [r5, #0]
  SET_BIT(USARTx->CR1, USART_CR1_UE);
 80022a2:	68d3      	ldr	r3, [r2, #12]
 80022a4:	f443 5300 	orr.w	r3, r3, #8192	; 0x2000
 80022a8:	60d3      	str	r3, [r2, #12]
	return 0;
 80022aa:	2000      	movs	r0, #0
};
 80022ac:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	switch (parity) {
 80022b0:	f44f 67c0 	mov.w	r7, #1536	; 0x600
 80022b4:	e782      	b.n	80021bc <uart_stm32_configure+0x18>
	if (fc == UART_CFG_FLOW_CTRL_RTS_CTS) {
 80022b6:	3b03      	subs	r3, #3
 80022b8:	f1be 0f01 	cmp.w	lr, #1
	if ((cfg->parity == UART_CFG_PARITY_MARK) ||
 80022bc:	b2db      	uxtb	r3, r3
	if (fc == UART_CFG_FLOW_CTRL_RTS_CTS) {
 80022be:	d109      	bne.n	80022d4 <uart_stm32_configure+0x130>
	if ((cfg->parity == UART_CFG_PARITY_MARK) ||
 80022c0:	2b01      	cmp	r3, #1
 80022c2:	d904      	bls.n	80022ce <uart_stm32_configure+0x12a>
		return LL_USART_HWCONTROL_RTS_CTS;
 80022c4:	f44f 7140 	mov.w	r1, #768	; 0x300
	if (cfg->stop_bits == UART_CFG_STOP_BITS_0_5) {
 80022c8:	f012 0ffd 	tst.w	r2, #253	; 0xfd
 80022cc:	d106      	bne.n	80022dc <uart_stm32_configure+0x138>
		return -ENOTSUP;
 80022ce:	f06f 0085 	mvn.w	r0, #133	; 0x85
 80022d2:	e7eb      	b.n	80022ac <uart_stm32_configure+0x108>
	if ((cfg->parity == UART_CFG_PARITY_MARK) ||
 80022d4:	2b01      	cmp	r3, #1
 80022d6:	d9fa      	bls.n	80022ce <uart_stm32_configure+0x12a>
	return LL_USART_HWCONTROL_NONE;
 80022d8:	2100      	movs	r1, #0
 80022da:	e7f5      	b.n	80022c8 <uart_stm32_configure+0x124>
	if ((cfg->data_bits == UART_CFG_DATA_BITS_5) ||
 80022dc:	f1b8 0f02 	cmp.w	r8, #2
 80022e0:	d9f5      	bls.n	80022ce <uart_stm32_configure+0x12a>
		return LL_USART_DATAWIDTH_9B;
 80022e2:	f44f 5380 	mov.w	r3, #4096	; 0x1000
 80022e6:	e785      	b.n	80021f4 <uart_stm32_configure+0x50>
	if (cfg->stop_bits == UART_CFG_STOP_BITS_0_5) {
 80022e8:	2a00      	cmp	r2, #0
 80022ea:	d0f0      	beq.n	80022ce <uart_stm32_configure+0x12a>
	if ((cfg->data_bits == UART_CFG_DATA_BITS_5) ||
 80022ec:	f1b8 0f02 	cmp.w	r8, #2
 80022f0:	d9ed      	bls.n	80022ce <uart_stm32_configure+0x12a>
		return LL_USART_HWCONTROL_RTS_CTS;
 80022f2:	f44f 7140 	mov.w	r1, #768	; 0x300
 80022f6:	e77d      	b.n	80021f4 <uart_stm32_configure+0x50>
 80022f8:	08005a50 	.word	0x08005a50
 80022fc:	40011000 	.word	0x40011000

08002300 <elapsed>:
 *     - the timer reset or the last time the function was called
 *     - and until the current call of the function is completed.
 * - the function is invoked with interrupts disabled.
 */
static uint32_t elapsed(void)
{
 8002300:	b510      	push	{r4, lr}
	uint32_t val1 = SysTick->VAL;	/* A */
 8002302:	f04f 23e0 	mov.w	r3, #3758153728	; 0xe000e000
 8002306:	699a      	ldr	r2, [r3, #24]
	uint32_t ctrl = SysTick->CTRL;	/* B */
 8002308:	6919      	ldr	r1, [r3, #16]
	uint32_t val2 = SysTick->VAL;	/* C */
 800230a:	6998      	ldr	r0, [r3, #24]
	 * 4) After C we'll see it next time
	 *
	 * So the count in val2 is post-wrap and last_load needs to be
	 * added if and only if COUNTFLAG is set or val1 < val2.
	 */
	if ((ctrl & SysTick_CTRL_COUNTFLAG_Msk)
 800230c:	4b09      	ldr	r3, [pc, #36]	; (8002334 <elapsed+0x34>)
 800230e:	f411 3f80 	tst.w	r1, #65536	; 0x10000
 8002312:	4909      	ldr	r1, [pc, #36]	; (8002338 <elapsed+0x38>)
 8002314:	d101      	bne.n	800231a <elapsed+0x1a>
	    || (val1 < val2)) {
 8002316:	4282      	cmp	r2, r0
 8002318:	d206      	bcs.n	8002328 <elapsed+0x28>
		overflow_cyc += last_load;
 800231a:	681a      	ldr	r2, [r3, #0]
 800231c:	680c      	ldr	r4, [r1, #0]
 800231e:	4422      	add	r2, r4
 8002320:	601a      	str	r2, [r3, #0]

		/* We know there was a wrap, but we might not have
		 * seen it in CTRL, so clear it. */
		(void)SysTick->CTRL;
 8002322:	f04f 22e0 	mov.w	r2, #3758153728	; 0xe000e000
 8002326:	6912      	ldr	r2, [r2, #16]
	}

	return (last_load - val2) + overflow_cyc;
 8002328:	681b      	ldr	r3, [r3, #0]
 800232a:	680a      	ldr	r2, [r1, #0]
 800232c:	4413      	add	r3, r2
}
 800232e:	1a18      	subs	r0, r3, r0
 8002330:	bd10      	pop	{r4, pc}
 8002332:	bf00      	nop
 8002334:	200007a4 	.word	0x200007a4
 8002338:	200007b0 	.word	0x200007b0

0800233c <sys_clock_driver_init>:
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
 800233c:	4b09      	ldr	r3, [pc, #36]	; (8002364 <sys_clock_driver_init+0x28>)
 800233e:	2210      	movs	r2, #16
 8002340:	f883 2023 	strb.w	r2, [r3, #35]	; 0x23
static int sys_clock_driver_init(const struct device *dev)
{
	ARG_UNUSED(dev);

	NVIC_SetPriority(SysTick_IRQn, _IRQ_PRIO_OFFSET);
	last_load = CYC_PER_TICK - 1;
 8002344:	4b08      	ldr	r3, [pc, #32]	; (8002368 <sys_clock_driver_init+0x2c>)
 8002346:	f242 527f 	movw	r2, #9599	; 0x257f
 800234a:	601a      	str	r2, [r3, #0]
	overflow_cyc = 0U;
 800234c:	4b07      	ldr	r3, [pc, #28]	; (800236c <sys_clock_driver_init+0x30>)
 800234e:	2000      	movs	r0, #0
 8002350:	6018      	str	r0, [r3, #0]
	SysTick->LOAD = last_load;
 8002352:	f04f 23e0 	mov.w	r3, #3758153728	; 0xe000e000
 8002356:	615a      	str	r2, [r3, #20]
	SysTick->VAL = 0; /* resets timer to last_load */
 8002358:	6198      	str	r0, [r3, #24]
	SysTick->CTRL |= (SysTick_CTRL_ENABLE_Msk |
 800235a:	691a      	ldr	r2, [r3, #16]
 800235c:	f042 0207 	orr.w	r2, r2, #7
 8002360:	611a      	str	r2, [r3, #16]
			  SysTick_CTRL_TICKINT_Msk |
			  SysTick_CTRL_CLKSOURCE_Msk);
	return 0;
}
 8002362:	4770      	bx	lr
 8002364:	e000ed00 	.word	0xe000ed00
 8002368:	200007b0 	.word	0x200007b0
 800236c:	200007a4 	.word	0x200007a4

08002370 <sys_clock_isr>:
{
 8002370:	b508      	push	{r3, lr}
	elapsed();
 8002372:	f7ff ffc5 	bl	8002300 <elapsed>
	cycle_count += overflow_cyc;
 8002376:	4b0c      	ldr	r3, [pc, #48]	; (80023a8 <sys_clock_isr+0x38>)
 8002378:	4a0c      	ldr	r2, [pc, #48]	; (80023ac <sys_clock_isr+0x3c>)
 800237a:	6818      	ldr	r0, [r3, #0]
 800237c:	6811      	ldr	r1, [r2, #0]
 800237e:	4408      	add	r0, r1
 8002380:	6010      	str	r0, [r2, #0]
	overflow_cyc = 0;
 8002382:	2200      	movs	r2, #0
 8002384:	601a      	str	r2, [r3, #0]
		dticks = (cycle_count - announced_cycles) / CYC_PER_TICK;
 8002386:	4a0a      	ldr	r2, [pc, #40]	; (80023b0 <sys_clock_isr+0x40>)
 8002388:	6813      	ldr	r3, [r2, #0]
 800238a:	f44f 5116 	mov.w	r1, #9600	; 0x2580
 800238e:	1ac0      	subs	r0, r0, r3
 8002390:	fbb0 f0f1 	udiv	r0, r0, r1
		announced_cycles += dticks * CYC_PER_TICK;
 8002394:	fb01 3300 	mla	r3, r1, r0, r3
 8002398:	6013      	str	r3, [r2, #0]
		sys_clock_announce(dticks);
 800239a:	f002 f8b1 	bl	8004500 <sys_clock_announce>
}
 800239e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
 80023a2:	f7ff b865 	b.w	8001470 <z_arm_exc_exit>
 80023a6:	bf00      	nop
 80023a8:	200007a4 	.word	0x200007a4
 80023ac:	200007ac 	.word	0x200007ac
 80023b0:	200007a8 	.word	0x200007a8

080023b4 <sys_clock_set_timeout>:
{
 80023b4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 80023b8:	4e43      	ldr	r6, [pc, #268]	; (80024c8 <sys_clock_set_timeout+0x114>)
	if (IS_ENABLED(CONFIG_TICKLESS_KERNEL) && idle && ticks == K_TICKS_FOREVER) {
 80023ba:	b379      	cbz	r1, 800241c <sys_clock_set_timeout+0x68>
 80023bc:	1c42      	adds	r2, r0, #1
 80023be:	d10a      	bne.n	80023d6 <sys_clock_set_timeout+0x22>
		SysTick->CTRL &= ~SysTick_CTRL_ENABLE_Msk;
 80023c0:	f04f 22e0 	mov.w	r2, #3758153728	; 0xe000e000
 80023c4:	6913      	ldr	r3, [r2, #16]
 80023c6:	f023 0301 	bic.w	r3, r3, #1
 80023ca:	6113      	str	r3, [r2, #16]
		last_load = TIMER_STOPPED;
 80023cc:	f04f 437f 	mov.w	r3, #4278190080	; 0xff000000
 80023d0:	6033      	str	r3, [r6, #0]
}
 80023d2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	uint32_t last_load_ = last_load;
 80023d6:	6834      	ldr	r4, [r6, #0]
	ticks = CLAMP(ticks - 1, 0, (int32_t)MAX_TICKS);
 80023d8:	2801      	cmp	r0, #1
 80023da:	dd25      	ble.n	8002428 <sys_clock_set_timeout+0x74>
 80023dc:	f240 68d2 	movw	r8, #1746	; 0x6d2
 80023e0:	4540      	cmp	r0, r8
 80023e2:	dc01      	bgt.n	80023e8 <sys_clock_set_timeout+0x34>
 80023e4:	f100 38ff 	add.w	r8, r0, #4294967295	; 0xffffffff
	__asm__ volatile(
 80023e8:	f04f 0310 	mov.w	r3, #16
 80023ec:	f3ef 8511 	mrs	r5, BASEPRI
 80023f0:	f383 8812 	msr	BASEPRI_MAX, r3
 80023f4:	f3bf 8f6f 	isb	sy
	 * actually a wrapper for a global spinlock!
	 */
	k.key = arch_irq_lock();

#ifdef CONFIG_SPIN_VALIDATE
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 80023f8:	4834      	ldr	r0, [pc, #208]	; (80024cc <sys_clock_set_timeout+0x118>)
 80023fa:	f000 fb0b 	bl	8002a14 <z_spin_lock_valid>
 80023fe:	b9b0      	cbnz	r0, 800242e <sys_clock_set_timeout+0x7a>
 8002400:	4a33      	ldr	r2, [pc, #204]	; (80024d0 <sys_clock_set_timeout+0x11c>)
 8002402:	4934      	ldr	r1, [pc, #208]	; (80024d4 <sys_clock_set_timeout+0x120>)
 8002404:	4834      	ldr	r0, [pc, #208]	; (80024d8 <sys_clock_set_timeout+0x124>)
 8002406:	2394      	movs	r3, #148	; 0x94
 8002408:	f002 fb7d 	bl	8004b06 <assert_print>
 800240c:	492f      	ldr	r1, [pc, #188]	; (80024cc <sys_clock_set_timeout+0x118>)
 800240e:	4833      	ldr	r0, [pc, #204]	; (80024dc <sys_clock_set_timeout+0x128>)
 8002410:	f002 fb79 	bl	8004b06 <assert_print>
 8002414:	2194      	movs	r1, #148	; 0x94
static ALWAYS_INLINE void k_spin_unlock(struct k_spinlock *l,
					k_spinlock_key_t key)
{
	ARG_UNUSED(l);
#ifdef CONFIG_SPIN_VALIDATE
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002416:	482e      	ldr	r0, [pc, #184]	; (80024d0 <sys_clock_set_timeout+0x11c>)
 8002418:	f002 fb6e 	bl	8004af8 <assert_post_action>
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
 800241c:	1c43      	adds	r3, r0, #1
	uint32_t last_load_ = last_load;
 800241e:	6834      	ldr	r4, [r6, #0]
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
 8002420:	d1da      	bne.n	80023d8 <sys_clock_set_timeout+0x24>
 8002422:	f240 60d2 	movw	r0, #1746	; 0x6d2
 8002426:	e7dd      	b.n	80023e4 <sys_clock_set_timeout+0x30>
	ticks = CLAMP(ticks - 1, 0, (int32_t)MAX_TICKS);
 8002428:	f04f 0800 	mov.w	r8, #0
 800242c:	e7dc      	b.n	80023e8 <sys_clock_set_timeout+0x34>
	z_spin_lock_set_owner(l);
 800242e:	4827      	ldr	r0, [pc, #156]	; (80024cc <sys_clock_set_timeout+0x118>)
	cycle_count += pending;
 8002430:	4f2b      	ldr	r7, [pc, #172]	; (80024e0 <sys_clock_set_timeout+0x12c>)
 8002432:	f000 fb0d 	bl	8002a50 <z_spin_lock_set_owner>
	uint32_t pending = elapsed();
 8002436:	f7ff ff63 	bl	8002300 <elapsed>
	val1 = SysTick->VAL;
 800243a:	f04f 23e0 	mov.w	r3, #3758153728	; 0xe000e000
	overflow_cyc = 0U;
 800243e:	2100      	movs	r1, #0
	val1 = SysTick->VAL;
 8002440:	f8d3 c018 	ldr.w	ip, [r3, #24]
	cycle_count += pending;
 8002444:	683b      	ldr	r3, [r7, #0]
 8002446:	18c2      	adds	r2, r0, r3
	overflow_cyc = 0U;
 8002448:	4b26      	ldr	r3, [pc, #152]	; (80024e4 <sys_clock_set_timeout+0x130>)
 800244a:	6019      	str	r1, [r3, #0]
	uint32_t unannounced = cycle_count - announced_cycles;
 800244c:	4b26      	ldr	r3, [pc, #152]	; (80024e8 <sys_clock_set_timeout+0x134>)
 800244e:	681b      	ldr	r3, [r3, #0]
	if ((int32_t)unannounced < 0) {
 8002450:	1ad1      	subs	r1, r2, r3
 8002452:	d431      	bmi.n	80024b8 <sys_clock_set_timeout+0x104>
		delay = ticks * CYC_PER_TICK;
 8002454:	f44f 5016 	mov.w	r0, #9600	; 0x2580
		 ((delay + CYC_PER_TICK - 1) / CYC_PER_TICK) * CYC_PER_TICK;
 8002458:	fb00 1108 	mla	r1, r0, r8, r1
 800245c:	f501 5115 	add.w	r1, r1, #9536	; 0x2540
		delay -= unannounced;
 8002460:	1a9b      	subs	r3, r3, r2
		 ((delay + CYC_PER_TICK - 1) / CYC_PER_TICK) * CYC_PER_TICK;
 8002462:	313f      	adds	r1, #63	; 0x3f
 8002464:	fbb1 f1f0 	udiv	r1, r1, r0
		delay -= unannounced;
 8002468:	fb00 3301 	mla	r3, r0, r1, r3
		delay = MAX(delay, MIN_DELAY);
 800246c:	f5b3 6f80 	cmp.w	r3, #1024	; 0x400
 8002470:	d922      	bls.n	80024b8 <sys_clock_set_timeout+0x104>
		if (delay > MAX_CYCLES) {
 8002472:	491e      	ldr	r1, [pc, #120]	; (80024ec <sys_clock_set_timeout+0x138>)
 8002474:	428b      	cmp	r3, r1
 8002476:	bf28      	it	cs
 8002478:	460b      	movcs	r3, r1
	val2 = SysTick->VAL;
 800247a:	f04f 21e0 	mov.w	r1, #3758153728	; 0xe000e000
		last_load = MIN_DELAY;
 800247e:	6033      	str	r3, [r6, #0]
	val2 = SysTick->VAL;
 8002480:	6988      	ldr	r0, [r1, #24]
	SysTick->LOAD = last_load - 1;
 8002482:	3b01      	subs	r3, #1
 8002484:	614b      	str	r3, [r1, #20]
	SysTick->VAL = 0; /* resets timer to last_load */
 8002486:	2300      	movs	r3, #0
	if (val1 < val2) {
 8002488:	4584      	cmp	ip, r0
	SysTick->VAL = 0; /* resets timer to last_load */
 800248a:	618b      	str	r3, [r1, #24]
	if (val1 < val2) {
 800248c:	ebac 0300 	sub.w	r3, ip, r0
		cycle_count += (val1 + (last_load_ - val2));
 8002490:	bf38      	it	cc
 8002492:	191b      	addcc	r3, r3, r4
		cycle_count += (val1 - val2);
 8002494:	441a      	add	r2, r3
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002496:	480d      	ldr	r0, [pc, #52]	; (80024cc <sys_clock_set_timeout+0x118>)
 8002498:	603a      	str	r2, [r7, #0]
 800249a:	f000 fac9 	bl	8002a30 <z_spin_unlock_valid>
 800249e:	b970      	cbnz	r0, 80024be <sys_clock_set_timeout+0x10a>
 80024a0:	4a0b      	ldr	r2, [pc, #44]	; (80024d0 <sys_clock_set_timeout+0x11c>)
 80024a2:	4913      	ldr	r1, [pc, #76]	; (80024f0 <sys_clock_set_timeout+0x13c>)
 80024a4:	480c      	ldr	r0, [pc, #48]	; (80024d8 <sys_clock_set_timeout+0x124>)
 80024a6:	23c2      	movs	r3, #194	; 0xc2
 80024a8:	f002 fb2d 	bl	8004b06 <assert_print>
 80024ac:	4907      	ldr	r1, [pc, #28]	; (80024cc <sys_clock_set_timeout+0x118>)
 80024ae:	4811      	ldr	r0, [pc, #68]	; (80024f4 <sys_clock_set_timeout+0x140>)
 80024b0:	f002 fb29 	bl	8004b06 <assert_print>
 80024b4:	21c2      	movs	r1, #194	; 0xc2
 80024b6:	e7ae      	b.n	8002416 <sys_clock_set_timeout+0x62>
 80024b8:	f44f 6380 	mov.w	r3, #1024	; 0x400
 80024bc:	e7dd      	b.n	800247a <sys_clock_set_timeout+0xc6>
	__asm__ volatile(
 80024be:	f385 8811 	msr	BASEPRI, r5
 80024c2:	f3bf 8f6f 	isb	sy
 80024c6:	e784      	b.n	80023d2 <sys_clock_set_timeout+0x1e>
 80024c8:	200007b0 	.word	0x200007b0
 80024cc:	200007b4 	.word	0x200007b4
 80024d0:	080061b7 	.word	0x080061b7
 80024d4:	080061e4 	.word	0x080061e4
 80024d8:	08005ca7 	.word	0x08005ca7
 80024dc:	080061f9 	.word	0x080061f9
 80024e0:	200007ac 	.word	0x200007ac
 80024e4:	200007a4 	.word	0x200007a4
 80024e8:	200007a8 	.word	0x200007a8
 80024ec:	00ffc300 	.word	0x00ffc300
 80024f0:	08006211 	.word	0x08006211
 80024f4:	08006228 	.word	0x08006228

080024f8 <sys_clock_elapsed>:
{
 80024f8:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
 80024fa:	f04f 0310 	mov.w	r3, #16
 80024fe:	f3ef 8511 	mrs	r5, BASEPRI
 8002502:	f383 8812 	msr	BASEPRI_MAX, r3
 8002506:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 800250a:	481b      	ldr	r0, [pc, #108]	; (8002578 <sys_clock_elapsed+0x80>)
 800250c:	f000 fa82 	bl	8002a14 <z_spin_lock_valid>
 8002510:	b968      	cbnz	r0, 800252e <sys_clock_elapsed+0x36>
 8002512:	4a1a      	ldr	r2, [pc, #104]	; (800257c <sys_clock_elapsed+0x84>)
 8002514:	491a      	ldr	r1, [pc, #104]	; (8002580 <sys_clock_elapsed+0x88>)
 8002516:	481b      	ldr	r0, [pc, #108]	; (8002584 <sys_clock_elapsed+0x8c>)
 8002518:	2394      	movs	r3, #148	; 0x94
 800251a:	f002 faf4 	bl	8004b06 <assert_print>
 800251e:	4916      	ldr	r1, [pc, #88]	; (8002578 <sys_clock_elapsed+0x80>)
 8002520:	4819      	ldr	r0, [pc, #100]	; (8002588 <sys_clock_elapsed+0x90>)
 8002522:	f002 faf0 	bl	8004b06 <assert_print>
 8002526:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002528:	4814      	ldr	r0, [pc, #80]	; (800257c <sys_clock_elapsed+0x84>)
 800252a:	f002 fae5 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 800252e:	4812      	ldr	r0, [pc, #72]	; (8002578 <sys_clock_elapsed+0x80>)
 8002530:	f000 fa8e 	bl	8002a50 <z_spin_lock_set_owner>
	uint32_t cyc = elapsed() + cycle_count - announced_cycles;
 8002534:	f7ff fee4 	bl	8002300 <elapsed>
 8002538:	4b14      	ldr	r3, [pc, #80]	; (800258c <sys_clock_elapsed+0x94>)
 800253a:	681c      	ldr	r4, [r3, #0]
 800253c:	4b14      	ldr	r3, [pc, #80]	; (8002590 <sys_clock_elapsed+0x98>)
 800253e:	681b      	ldr	r3, [r3, #0]
 8002540:	1ae4      	subs	r4, r4, r3
 8002542:	4404      	add	r4, r0
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002544:	480c      	ldr	r0, [pc, #48]	; (8002578 <sys_clock_elapsed+0x80>)
 8002546:	f000 fa73 	bl	8002a30 <z_spin_unlock_valid>
 800254a:	b958      	cbnz	r0, 8002564 <sys_clock_elapsed+0x6c>
 800254c:	4a0b      	ldr	r2, [pc, #44]	; (800257c <sys_clock_elapsed+0x84>)
 800254e:	4911      	ldr	r1, [pc, #68]	; (8002594 <sys_clock_elapsed+0x9c>)
 8002550:	480c      	ldr	r0, [pc, #48]	; (8002584 <sys_clock_elapsed+0x8c>)
 8002552:	23c2      	movs	r3, #194	; 0xc2
 8002554:	f002 fad7 	bl	8004b06 <assert_print>
 8002558:	4907      	ldr	r1, [pc, #28]	; (8002578 <sys_clock_elapsed+0x80>)
 800255a:	480f      	ldr	r0, [pc, #60]	; (8002598 <sys_clock_elapsed+0xa0>)
 800255c:	f002 fad3 	bl	8004b06 <assert_print>
 8002560:	21c2      	movs	r1, #194	; 0xc2
 8002562:	e7e1      	b.n	8002528 <sys_clock_elapsed+0x30>
	__asm__ volatile(
 8002564:	f385 8811 	msr	BASEPRI, r5
 8002568:	f3bf 8f6f 	isb	sy
}
 800256c:	f44f 5016 	mov.w	r0, #9600	; 0x2580
 8002570:	fbb4 f0f0 	udiv	r0, r4, r0
 8002574:	bd38      	pop	{r3, r4, r5, pc}
 8002576:	bf00      	nop
 8002578:	200007b4 	.word	0x200007b4
 800257c:	080061b7 	.word	0x080061b7
 8002580:	080061e4 	.word	0x080061e4
 8002584:	08005ca7 	.word	0x08005ca7
 8002588:	080061f9 	.word	0x080061f9
 800258c:	200007ac 	.word	0x200007ac
 8002590:	200007a8 	.word	0x200007a8
 8002594:	08006211 	.word	0x08006211
 8002598:	08006228 	.word	0x08006228

0800259c <pinctrl_configure_pins>:
	return gpio_stm32_configure(port_device, STM32_PIN(pin), pin_cgf, pin_func);
}

int pinctrl_configure_pins(const pinctrl_soc_pin_t *pins, uint8_t pin_cnt,
			   uintptr_t reg)
{
 800259c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	port_device = gpio_ports[STM32_PORT(pin)];
 80025a0:	4f25      	ldr	r7, [pc, #148]	; (8002638 <pinctrl_configure_pins+0x9c>)
 80025a2:	4604      	mov	r4, r0
 80025a4:	eb00 06c1 	add.w	r6, r0, r1, lsl #3
	uint32_t pin, mux;
	uint32_t pin_cgf = 0;
 80025a8:	2500      	movs	r5, #0
	if (ret < 0) {
		return ret;
	}
#endif /* DT_HAS_COMPAT_STATUS_OKAY(st_stm32f1_pinctrl) */

	for (uint8_t i = 0U; i < pin_cnt; i++) {
 80025aa:	42b4      	cmp	r4, r6
 80025ac:	d101      	bne.n	80025b2 <pinctrl_configure_pins+0x16>
		if (ret < 0) {
			return ret;
		}
	}

	return 0;
 80025ae:	2000      	movs	r0, #0
 80025b0:	e014      	b.n	80025dc <pinctrl_configure_pins+0x40>
		mux = pins[i].pinmux;
 80025b2:	6820      	ldr	r0, [r4, #0]
		if (STM32_DT_PINMUX_FUNC(mux) < STM32_ANALOG) {
 80025b4:	06c3      	lsls	r3, r0, #27
		} else if (STM32_DT_PINMUX_FUNC(mux) == STM32_ANALOG) {
 80025b6:	f000 081f 	and.w	r8, r0, #31
		if (STM32_DT_PINMUX_FUNC(mux) < STM32_ANALOG) {
 80025ba:	d411      	bmi.n	80025e0 <pinctrl_configure_pins+0x44>
			pin_cgf = pins[i].pincfg | STM32_MODER_ALT_MODE;
 80025bc:	6865      	ldr	r5, [r4, #4]
 80025be:	f045 0520 	orr.w	r5, r5, #32
		pin = STM32PIN(STM32_DT_PINMUX_PORT(mux),
 80025c2:	f3c0 1a47 	ubfx	sl, r0, #5, #8
	if (STM32_PORT(pin) >= gpio_ports_cnt) {
 80025c6:	f3c0 2043 	ubfx	r0, r0, #9, #4
 80025ca:	280a      	cmp	r0, #10
 80025cc:	d830      	bhi.n	8002630 <pinctrl_configure_pins+0x94>
	port_device = gpio_ports[STM32_PORT(pin)];
 80025ce:	f857 9020 	ldr.w	r9, [r7, r0, lsl #2]
	if ((port_device == NULL) || (!device_is_ready(port_device))) {
 80025d2:	f1b9 0f00 	cmp.w	r9, #0
 80025d6:	d11a      	bne.n	800260e <pinctrl_configure_pins+0x72>
		return -ENODEV;
 80025d8:	f06f 0012 	mvn.w	r0, #18
}
 80025dc:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
		} else if (STM32_DT_PINMUX_FUNC(mux) == STM32_ANALOG) {
 80025e0:	f1b8 0f10 	cmp.w	r8, #16
 80025e4:	d011      	beq.n	800260a <pinctrl_configure_pins+0x6e>
		} else if (STM32_DT_PINMUX_FUNC(mux) == STM32_GPIO) {
 80025e6:	f1b8 0f11 	cmp.w	r8, #17
 80025ea:	d101      	bne.n	80025f0 <pinctrl_configure_pins+0x54>
			pin_cgf = pins[i].pincfg;
 80025ec:	6865      	ldr	r5, [r4, #4]
 80025ee:	e7e8      	b.n	80025c2 <pinctrl_configure_pins+0x26>
			__ASSERT_NO_MSG(STM32_DT_PINMUX_FUNC(mux));
 80025f0:	f1b8 0f00 	cmp.w	r8, #0
 80025f4:	d1e5      	bne.n	80025c2 <pinctrl_configure_pins+0x26>
 80025f6:	4911      	ldr	r1, [pc, #68]	; (800263c <pinctrl_configure_pins+0xa0>)
 80025f8:	4811      	ldr	r0, [pc, #68]	; (8002640 <pinctrl_configure_pins+0xa4>)
 80025fa:	4a12      	ldr	r2, [pc, #72]	; (8002644 <pinctrl_configure_pins+0xa8>)
 80025fc:	23f2      	movs	r3, #242	; 0xf2
 80025fe:	f002 fa82 	bl	8004b06 <assert_print>
 8002602:	4810      	ldr	r0, [pc, #64]	; (8002644 <pinctrl_configure_pins+0xa8>)
 8002604:	21f2      	movs	r1, #242	; 0xf2
 8002606:	f002 fa77 	bl	8004af8 <assert_post_action>
			pin_cgf = STM32_MODER_ANALOG_MODE;
 800260a:	2530      	movs	r5, #48	; 0x30
 800260c:	e7d9      	b.n	80025c2 <pinctrl_configure_pins+0x26>
 800260e:	4648      	mov	r0, r9
 8002610:	f002 fe2b 	bl	800526a <z_device_is_ready>
	if ((port_device == NULL) || (!device_is_ready(port_device))) {
 8002614:	2800      	cmp	r0, #0
 8002616:	d0df      	beq.n	80025d8 <pinctrl_configure_pins+0x3c>
	return gpio_stm32_configure(port_device, STM32_PIN(pin), pin_cgf, pin_func);
 8002618:	4643      	mov	r3, r8
 800261a:	462a      	mov	r2, r5
 800261c:	f00a 010f 	and.w	r1, sl, #15
 8002620:	4648      	mov	r0, r9
 8002622:	f002 fc58 	bl	8004ed6 <gpio_stm32_configure>
		if (ret < 0) {
 8002626:	2800      	cmp	r0, #0
 8002628:	f104 0408 	add.w	r4, r4, #8
 800262c:	dabd      	bge.n	80025aa <pinctrl_configure_pins+0xe>
 800262e:	e7d5      	b.n	80025dc <pinctrl_configure_pins+0x40>
		return -EINVAL;
 8002630:	f06f 0015 	mvn.w	r0, #21
 8002634:	e7d2      	b.n	80025dc <pinctrl_configure_pins+0x40>
 8002636:	bf00      	nop
 8002638:	080059f4 	.word	0x080059f4
 800263c:	08006270 	.word	0x08006270
 8002640:	08005ca7 	.word	0x08005ca7
 8002644:	0800623d 	.word	0x0800623d

08002648 <HAL_RCC_GetSysClockFreq>:
  *
  *
  * @retval SYSCLK frequency
  */
__weak uint32_t HAL_RCC_GetSysClockFreq(void)
{
 8002648:	b508      	push	{r3, lr}
  uint32_t pllm = 0U, pllvco = 0U, pllp = 0U;
  uint32_t sysclockfreq = 0U;

  /* Get SYSCLK source -------------------------------------------------------*/
  switch (RCC->CFGR & RCC_CFGR_SWS)
 800264a:	4913      	ldr	r1, [pc, #76]	; (8002698 <HAL_RCC_GetSysClockFreq+0x50>)
 800264c:	688b      	ldr	r3, [r1, #8]
 800264e:	f003 030c 	and.w	r3, r3, #12
 8002652:	2b04      	cmp	r3, #4
 8002654:	d01c      	beq.n	8002690 <HAL_RCC_GetSysClockFreq+0x48>
 8002656:	2b08      	cmp	r3, #8
 8002658:	d11c      	bne.n	8002694 <HAL_RCC_GetSysClockFreq+0x4c>
    }
    case RCC_CFGR_SWS_PLL:  /* PLL used as system clock  source */
    {
      /* PLL_VCO = (HSE_VALUE or HSI_VALUE / PLLM) * PLLN
      SYSCLK = PLL_VCO / PLLP */
      pllm = RCC->PLLCFGR & RCC_PLLCFGR_PLLM;
 800265a:	684a      	ldr	r2, [r1, #4]
      if(__HAL_RCC_GET_PLL_OSCSOURCE() != RCC_PLLSOURCE_HSI)
 800265c:	684b      	ldr	r3, [r1, #4]
      {
        /* HSE used as PLL clock source */
        pllvco = (uint32_t) ((((uint64_t) HSE_VALUE * ((uint64_t) ((RCC->PLLCFGR & RCC_PLLCFGR_PLLN) >> RCC_PLLCFGR_PLLN_Pos)))) / (uint64_t)pllm);
 800265e:	6849      	ldr	r1, [r1, #4]
      if(__HAL_RCC_GET_PLL_OSCSOURCE() != RCC_PLLSOURCE_HSI)
 8002660:	f413 0380 	ands.w	r3, r3, #4194304	; 0x400000
        pllvco = (uint32_t) ((((uint64_t) HSE_VALUE * ((uint64_t) ((RCC->PLLCFGR & RCC_PLLCFGR_PLLN) >> RCC_PLLCFGR_PLLN_Pos)))) / (uint64_t)pllm);
 8002664:	bf14      	ite	ne
 8002666:	480d      	ldrne	r0, [pc, #52]	; (800269c <HAL_RCC_GetSysClockFreq+0x54>)
      }
      else
      {
        /* HSI used as PLL clock source */
        pllvco = (uint32_t) ((((uint64_t) HSI_VALUE * ((uint64_t) ((RCC->PLLCFGR & RCC_PLLCFGR_PLLN) >> RCC_PLLCFGR_PLLN_Pos)))) / (uint64_t)pllm);
 8002668:	480d      	ldreq	r0, [pc, #52]	; (80026a0 <HAL_RCC_GetSysClockFreq+0x58>)
        pllvco = (uint32_t) ((((uint64_t) HSE_VALUE * ((uint64_t) ((RCC->PLLCFGR & RCC_PLLCFGR_PLLN) >> RCC_PLLCFGR_PLLN_Pos)))) / (uint64_t)pllm);
 800266a:	f3c1 1188 	ubfx	r1, r1, #6, #9
 800266e:	bf18      	it	ne
 8002670:	2300      	movne	r3, #0
      pllm = RCC->PLLCFGR & RCC_PLLCFGR_PLLM;
 8002672:	f002 023f 	and.w	r2, r2, #63	; 0x3f
        pllvco = (uint32_t) ((((uint64_t) HSI_VALUE * ((uint64_t) ((RCC->PLLCFGR & RCC_PLLCFGR_PLLN) >> RCC_PLLCFGR_PLLN_Pos)))) / (uint64_t)pllm);
 8002676:	fba1 0100 	umull	r0, r1, r1, r0
 800267a:	f7fd fd8d 	bl	8000198 <__aeabi_uldivmod>
      }
      pllp = ((((RCC->PLLCFGR & RCC_PLLCFGR_PLLP) >> RCC_PLLCFGR_PLLP_Pos) + 1U) *2U);
 800267e:	4b06      	ldr	r3, [pc, #24]	; (8002698 <HAL_RCC_GetSysClockFreq+0x50>)
 8002680:	685b      	ldr	r3, [r3, #4]
 8002682:	f3c3 4301 	ubfx	r3, r3, #16, #2
 8002686:	3301      	adds	r3, #1
 8002688:	005b      	lsls	r3, r3, #1

      sysclockfreq = pllvco/pllp;
 800268a:	fbb0 f0f3 	udiv	r0, r0, r3
      sysclockfreq = HSI_VALUE;
      break;
    }
  }
  return sysclockfreq;
}
 800268e:	bd08      	pop	{r3, pc}
  switch (RCC->CFGR & RCC_CFGR_SWS)
 8002690:	4802      	ldr	r0, [pc, #8]	; (800269c <HAL_RCC_GetSysClockFreq+0x54>)
 8002692:	e7fc      	b.n	800268e <HAL_RCC_GetSysClockFreq+0x46>
      sysclockfreq = HSI_VALUE;
 8002694:	4802      	ldr	r0, [pc, #8]	; (80026a0 <HAL_RCC_GetSysClockFreq+0x58>)
  return sysclockfreq;
 8002696:	e7fa      	b.n	800268e <HAL_RCC_GetSysClockFreq+0x46>
 8002698:	40023800 	.word	0x40023800
 800269c:	007a1200 	.word	0x007a1200
 80026a0:	00f42400 	.word	0x00f42400

080026a4 <LL_SetFlashLatency>:
  uint32_t latency = LL_FLASH_LATENCY_0;  /* default value 0WS */
  ErrorStatus status = SUCCESS;


  /* Frequency cannot be equal to 0 */
  if(HCLK_Frequency == 0U)
 80026a4:	2800      	cmp	r0, #0
 80026a6:	d076      	beq.n	8002796 <LL_SetFlashLatency+0xf2>
  *         @arg @ref LL_PWR_REGU_VOLTAGE_SCALE3
  *         (*) LL_PWR_REGU_VOLTAGE_SCALE1 is not available for STM32F401xx devices
  */
__STATIC_INLINE uint32_t LL_PWR_GetRegulVoltageScaling(void)
{
  return (uint32_t)(READ_BIT(PWR->CR, PWR_CR_VOS));
 80026a8:	4b3c      	ldr	r3, [pc, #240]	; (800279c <LL_SetFlashLatency+0xf8>)
 80026aa:	681a      	ldr	r2, [r3, #0]
 80026ac:	f402 4240 	and.w	r2, r2, #49152	; 0xc000
  {
    status = ERROR;
  }
  else
  {
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE1)
 80026b0:	f5b2 4f40 	cmp.w	r2, #49152	; 0xc000
 80026b4:	d120      	bne.n	80026f8 <LL_SetFlashLatency+0x54>
      {
        latency = LL_FLASH_LATENCY_4;
      }
#endif /* UTILS_SCALE1_LATENCY4_FREQ */
#if defined (UTILS_SCALE1_LATENCY3_FREQ)
      if((HCLK_Frequency > UTILS_SCALE1_LATENCY3_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 80026b6:	4a3a      	ldr	r2, [pc, #232]	; (80027a0 <LL_SetFlashLatency+0xfc>)
 80026b8:	4290      	cmp	r0, r2
 80026ba:	d815      	bhi.n	80026e8 <LL_SetFlashLatency+0x44>
      {
        latency = LL_FLASH_LATENCY_3;
      }
#endif /* UTILS_SCALE1_LATENCY3_FREQ */
#if defined (UTILS_SCALE1_LATENCY2_FREQ)
      if((HCLK_Frequency > UTILS_SCALE1_LATENCY2_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 80026bc:	4a39      	ldr	r2, [pc, #228]	; (80027a4 <LL_SetFlashLatency+0x100>)
 80026be:	4290      	cmp	r0, r2
 80026c0:	d907      	bls.n	80026d2 <LL_SetFlashLatency+0x2e>
 80026c2:	681a      	ldr	r2, [r3, #0]
 80026c4:	f402 4240 	and.w	r2, r2, #49152	; 0xc000
          latency = LL_FLASH_LATENCY_1;
        }
      }
#endif /* UTILS_SCALE1_LATENCY2_FREQ */
    }
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE2)
 80026c8:	f5b2 4f00 	cmp.w	r2, #32768	; 0x8000
 80026cc:	d15c      	bne.n	8002788 <LL_SetFlashLatency+0xe4>
 80026ce:	2002      	movs	r0, #2
 80026d0:	e01f      	b.n	8002712 <LL_SetFlashLatency+0x6e>
        if((HCLK_Frequency > UTILS_SCALE1_LATENCY1_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 80026d2:	4a35      	ldr	r2, [pc, #212]	; (80027a8 <LL_SetFlashLatency+0x104>)
 80026d4:	4290      	cmp	r0, r2
 80026d6:	681a      	ldr	r2, [r3, #0]
 80026d8:	f402 4240 	and.w	r2, r2, #49152	; 0xc000
 80026dc:	d947      	bls.n	800276e <LL_SetFlashLatency+0xca>
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE2)
 80026de:	f5b2 4f00 	cmp.w	r2, #32768	; 0x8000
 80026e2:	d14c      	bne.n	800277e <LL_SetFlashLatency+0xda>
          latency = LL_FLASH_LATENCY_1;
 80026e4:	2001      	movs	r0, #1
 80026e6:	e014      	b.n	8002712 <LL_SetFlashLatency+0x6e>
 80026e8:	681a      	ldr	r2, [r3, #0]
 80026ea:	f402 4240 	and.w	r2, r2, #49152	; 0xc000
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE2)
 80026ee:	f5b2 4f00 	cmp.w	r2, #32768	; 0x8000
 80026f2:	d13f      	bne.n	8002774 <LL_SetFlashLatency+0xd0>
 80026f4:	2003      	movs	r0, #3
 80026f6:	e00c      	b.n	8002712 <LL_SetFlashLatency+0x6e>
 80026f8:	681a      	ldr	r2, [r3, #0]
 80026fa:	f402 4240 	and.w	r2, r2, #49152	; 0xc000
 80026fe:	f5b2 4f00 	cmp.w	r2, #32768	; 0x8000
 8002702:	d122      	bne.n	800274a <LL_SetFlashLatency+0xa6>
      if((HCLK_Frequency > UTILS_SCALE2_LATENCY3_FREQ)&&(latency == LL_FLASH_LATENCY_0))
      {
        latency = LL_FLASH_LATENCY_3;
      }
#endif /*UTILS_SCALE1_LATENCY3_FREQ */
      if((HCLK_Frequency > UTILS_SCALE2_LATENCY2_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 8002704:	4a27      	ldr	r2, [pc, #156]	; (80027a4 <LL_SetFlashLatency+0x100>)
 8002706:	4290      	cmp	r0, r2
 8002708:	d83e      	bhi.n	8002788 <LL_SetFlashLatency+0xe4>
      {
        latency = LL_FLASH_LATENCY_2;
      }
      else
      {
        if((HCLK_Frequency > UTILS_SCALE2_LATENCY1_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 800270a:	4a27      	ldr	r2, [pc, #156]	; (80027a8 <LL_SetFlashLatency+0x104>)
 800270c:	4290      	cmp	r0, r2
 800270e:	d92e      	bls.n	800276e <LL_SetFlashLatency+0xca>
 8002710:	2000      	movs	r0, #0
 8002712:	4b22      	ldr	r3, [pc, #136]	; (800279c <LL_SetFlashLatency+0xf8>)
 8002714:	681b      	ldr	r3, [r3, #0]
 8002716:	2801      	cmp	r0, #1
 8002718:	bf38      	it	cc
 800271a:	2001      	movcc	r0, #1
 800271c:	f403 4340 	and.w	r3, r3, #49152	; 0xc000
          latency = LL_FLASH_LATENCY_1;
        }
      }
    }
#if defined (LL_PWR_REGU_VOLTAGE_SCALE3)
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE3)
 8002720:	f5b3 4f80 	cmp.w	r3, #16384	; 0x4000
 8002724:	d01f      	beq.n	8002766 <LL_SetFlashLatency+0xc2>
  MODIFY_REG(FLASH->ACR, FLASH_ACR_LATENCY, Latency);
 8002726:	4a21      	ldr	r2, [pc, #132]	; (80027ac <LL_SetFlashLatency+0x108>)
 8002728:	6813      	ldr	r3, [r2, #0]
 800272a:	f023 0307 	bic.w	r3, r3, #7
 800272e:	4303      	orrs	r3, r0
 8002730:	6013      	str	r3, [r2, #0]
  return (uint32_t)(READ_BIT(FLASH->ACR, FLASH_ACR_LATENCY));
 8002732:	6813      	ldr	r3, [r2, #0]
 8002734:	f003 0307 	and.w	r3, r3, #7
    do
    {
    /* Wait for Flash latency to be updated */
    getlatency = LL_FLASH_GetLatency();
    timeout--;
    } while ((getlatency != latency) && (timeout > 0));
 8002738:	4298      	cmp	r0, r3
 800273a:	bf1c      	itt	ne
 800273c:	6813      	ldrne	r3, [r2, #0]
 800273e:	f003 0307 	andne.w	r3, r3, #7

    if(getlatency != latency)
 8002742:	1ac0      	subs	r0, r0, r3
 8002744:	bf18      	it	ne
 8002746:	2001      	movne	r0, #1
 8002748:	4770      	bx	lr
 800274a:	681b      	ldr	r3, [r3, #0]
 800274c:	f403 4340 	and.w	r3, r3, #49152	; 0xc000
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE3)
 8002750:	f5b3 4f80 	cmp.w	r3, #16384	; 0x4000
 8002754:	d10c      	bne.n	8002770 <LL_SetFlashLatency+0xcc>
      if((HCLK_Frequency > UTILS_SCALE3_LATENCY2_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 8002756:	4b13      	ldr	r3, [pc, #76]	; (80027a4 <LL_SetFlashLatency+0x100>)
 8002758:	4298      	cmp	r0, r3
 800275a:	d81a      	bhi.n	8002792 <LL_SetFlashLatency+0xee>
        if((HCLK_Frequency > UTILS_SCALE3_LATENCY1_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 800275c:	4b12      	ldr	r3, [pc, #72]	; (80027a8 <LL_SetFlashLatency+0x104>)
 800275e:	4298      	cmp	r0, r3
  uint32_t latency = LL_FLASH_LATENCY_0;  /* default value 0WS */
 8002760:	f04f 0000 	mov.w	r0, #0
        if((HCLK_Frequency > UTILS_SCALE3_LATENCY1_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 8002764:	d9df      	bls.n	8002726 <LL_SetFlashLatency+0x82>
 8002766:	2801      	cmp	r0, #1
 8002768:	bf38      	it	cc
 800276a:	2001      	movcc	r0, #1
 800276c:	e7db      	b.n	8002726 <LL_SetFlashLatency+0x82>
 800276e:	681b      	ldr	r3, [r3, #0]
  uint32_t latency = LL_FLASH_LATENCY_0;  /* default value 0WS */
 8002770:	2000      	movs	r0, #0
 8002772:	e7d8      	b.n	8002726 <LL_SetFlashLatency+0x82>
 8002774:	681b      	ldr	r3, [r3, #0]
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE3)
 8002776:	2003      	movs	r0, #3
 8002778:	f403 4340 	and.w	r3, r3, #49152	; 0xc000
 800277c:	e7d0      	b.n	8002720 <LL_SetFlashLatency+0x7c>
 800277e:	681b      	ldr	r3, [r3, #0]
          latency = LL_FLASH_LATENCY_1;
 8002780:	2001      	movs	r0, #1
 8002782:	f403 4340 	and.w	r3, r3, #49152	; 0xc000
 8002786:	e7cb      	b.n	8002720 <LL_SetFlashLatency+0x7c>
 8002788:	681b      	ldr	r3, [r3, #0]
    if(LL_PWR_GetRegulVoltageScaling() == LL_PWR_REGU_VOLTAGE_SCALE3)
 800278a:	2002      	movs	r0, #2
 800278c:	f403 4340 	and.w	r3, r3, #49152	; 0xc000
 8002790:	e7c6      	b.n	8002720 <LL_SetFlashLatency+0x7c>
      if((HCLK_Frequency > UTILS_SCALE3_LATENCY2_FREQ)&&(latency == LL_FLASH_LATENCY_0))
 8002792:	2002      	movs	r0, #2
 8002794:	e7c7      	b.n	8002726 <LL_SetFlashLatency+0x82>
    status = ERROR;
 8002796:	2001      	movs	r0, #1
    {
      status = SUCCESS;
    }
  }
  return status;
}
 8002798:	4770      	bx	lr
 800279a:	bf00      	nop
 800279c:	40007000 	.word	0x40007000
 80027a0:	055d4a80 	.word	0x055d4a80
 80027a4:	03d09000 	.word	0x03d09000
 80027a8:	01c9c380 	.word	0x01c9c380
 80027ac:	40023c00 	.word	0x40023c00

080027b0 <z_fatal_error>:
	return 0;
#endif
}

void z_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
 80027b0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
 80027b2:	4604      	mov	r4, r0
 80027b4:	460e      	mov	r6, r1
	__asm__ volatile(
 80027b6:	f04f 0310 	mov.w	r3, #16
 80027ba:	f3ef 8711 	mrs	r7, BASEPRI
 80027be:	f383 8812 	msr	BASEPRI_MAX, r3
 80027c2:	f3bf 8f6f 	isb	sy
	return z_impl_z_current_get();
 80027c6:	f001 fbff 	bl	8003fc8 <z_impl_z_current_get>

#ifndef CONFIG_XTENSA
	coredump(reason, esf, thread);
#endif

	k_sys_fatal_error_handler(reason, esf);
 80027ca:	4631      	mov	r1, r6
 80027cc:	4605      	mov	r5, r0
 80027ce:	4620      	mov	r0, r4
 80027d0:	f002 fd5f 	bl	8005292 <k_sys_fatal_error_handler>
	 *
	 * Note that k_thread_abort() returns on some architectures but
	 * not others; e.g. on ARC, x86_64, Xtensa with ASM2, ARM
	 */
	if (!IS_ENABLED(CONFIG_TEST)) {
		__ASSERT(reason != K_ERR_KERNEL_PANIC,
 80027d4:	2c04      	cmp	r4, #4
 80027d6:	d10c      	bne.n	80027f2 <z_fatal_error+0x42>
 80027d8:	490a      	ldr	r1, [pc, #40]	; (8002804 <z_fatal_error+0x54>)
 80027da:	4a0b      	ldr	r2, [pc, #44]	; (8002808 <z_fatal_error+0x58>)
 80027dc:	480b      	ldr	r0, [pc, #44]	; (800280c <z_fatal_error+0x5c>)
 80027de:	2393      	movs	r3, #147	; 0x93
 80027e0:	f002 f991 	bl	8004b06 <assert_print>
 80027e4:	480a      	ldr	r0, [pc, #40]	; (8002810 <z_fatal_error+0x60>)
 80027e6:	f002 f98e 	bl	8004b06 <assert_print>
 80027ea:	4807      	ldr	r0, [pc, #28]	; (8002808 <z_fatal_error+0x58>)
 80027ec:	2193      	movs	r1, #147	; 0x93
 80027ee:	f002 f983 	bl	8004af8 <assert_post_action>
	__asm__ volatile(
 80027f2:	f387 8811 	msr	BASEPRI, r7
 80027f6:	f3bf 8f6f 	isb	sy
	z_impl_k_thread_abort(thread);
 80027fa:	4628      	mov	r0, r5
	arch_irq_unlock(key);

	if (IS_ENABLED(CONFIG_MULTITHREADING)) {
		k_thread_abort(thread);
	}
}
 80027fc:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
 8002800:	f7fe bfbe 	b.w	8001780 <z_impl_k_thread_abort>
 8002804:	080062cb 	.word	0x080062cb
 8002808:	080062a9 	.word	0x080062a9
 800280c:	08005ca7 	.word	0x08005ca7
 8002810:	080062e8 	.word	0x080062e8

08002814 <z_sys_init_run_level>:
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
 8002814:	4b0f      	ldr	r3, [pc, #60]	; (8002854 <z_sys_init_run_level+0x40>)
{
 8002816:	b570      	push	{r4, r5, r6, lr}
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
 8002818:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
 800281c:	3001      	adds	r0, #1
 800281e:	f853 6020 	ldr.w	r6, [r3, r0, lsl #2]
 8002822:	42a6      	cmp	r6, r4
 8002824:	d800      	bhi.n	8002828 <z_sys_init_run_level+0x14>
				dev->state->init_res = rc;
			}
			dev->state->initialized = true;
		}
	}
}
 8002826:	bd70      	pop	{r4, r5, r6, pc}
		int rc = entry->init(dev);
 8002828:	e9d4 3500 	ldrd	r3, r5, [r4]
 800282c:	4628      	mov	r0, r5
 800282e:	4798      	blx	r3
		if (dev != NULL) {
 8002830:	b16d      	cbz	r5, 800284e <z_sys_init_run_level+0x3a>
			if (rc != 0) {
 8002832:	b138      	cbz	r0, 8002844 <z_sys_init_run_level+0x30>
				if (rc < 0) {
 8002834:	2800      	cmp	r0, #0
 8002836:	bfb8      	it	lt
 8002838:	4240      	neglt	r0, r0
				dev->state->init_res = rc;
 800283a:	68eb      	ldr	r3, [r5, #12]
				if (rc > UINT8_MAX) {
 800283c:	28ff      	cmp	r0, #255	; 0xff
 800283e:	bfa8      	it	ge
 8002840:	20ff      	movge	r0, #255	; 0xff
				dev->state->init_res = rc;
 8002842:	7018      	strb	r0, [r3, #0]
			dev->state->initialized = true;
 8002844:	68ea      	ldr	r2, [r5, #12]
 8002846:	7853      	ldrb	r3, [r2, #1]
 8002848:	f043 0301 	orr.w	r3, r3, #1
 800284c:	7053      	strb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
 800284e:	3408      	adds	r4, #8
 8002850:	e7e7      	b.n	8002822 <z_sys_init_run_level+0xe>
 8002852:	bf00      	nop
 8002854:	08005a38 	.word	0x08005a38

08002858 <bg_thread_main>:
 * This routine completes kernel initialization by invoking the remaining
 * init functions, then invokes application's main() routine.
 */
__boot_func
static void bg_thread_main(void *unused1, void *unused2, void *unused3)
{
 8002858:	b508      	push	{r3, lr}
	 * may perform memory management tasks (except for z_phys_map() which
	 * is allowed at any time)
	 */
	z_mem_manage_init();
#endif /* CONFIG_MMU */
	z_sys_post_kernel = true;
 800285a:	4b0a      	ldr	r3, [pc, #40]	; (8002884 <bg_thread_main+0x2c>)
 800285c:	2201      	movs	r2, #1

	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
 800285e:	2003      	movs	r0, #3
	z_sys_post_kernel = true;
 8002860:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
 8002862:	f7ff ffd7 	bl	8002814 <z_sys_init_run_level>
#if CONFIG_STACK_POINTER_RANDOM
	z_stack_adjust_initialized = 1;
#endif
	boot_banner();
 8002866:	f001 ff39 	bl	80046dc <boot_banner>
	void z_cpp_init_static(void);
	z_cpp_init_static();
#endif

	/* Final init level before app starts */
	z_sys_init_run_level(INIT_LEVEL_APPLICATION);
 800286a:	2004      	movs	r0, #4
 800286c:	f7ff ffd2 	bl	8002814 <z_sys_init_run_level>

	z_init_static_threads();
 8002870:	f000 fa44 	bl	8002cfc <z_init_static_threads>
	extern int main(void);
#else
	extern void main(void);
#endif

	(void)main();
 8002874:	f7fd feb0 	bl	80005d8 <main>

	/* Mark nonessential since main() has no more work to do */
	z_main_thread.base.user_options &= ~K_ESSENTIAL;
 8002878:	4a03      	ldr	r2, [pc, #12]	; (8002888 <bg_thread_main+0x30>)
 800287a:	7b13      	ldrb	r3, [r2, #12]
 800287c:	f023 0301 	bic.w	r3, r3, #1
 8002880:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
 8002882:	bd08      	pop	{r3, pc}
 8002884:	20000809 	.word	0x20000809
 8002888:	20000530 	.word	0x20000530

0800288c <z_bss_zero>:
{
 800288c:	b508      	push	{r3, lr}
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
 800288e:	4803      	ldr	r0, [pc, #12]	; (800289c <z_bss_zero+0x10>)
 8002890:	4a03      	ldr	r2, [pc, #12]	; (80028a0 <z_bss_zero+0x14>)
 8002892:	2100      	movs	r1, #0
 8002894:	1a12      	subs	r2, r2, r0
 8002896:	f002 fcff 	bl	8005298 <z_early_memset>
}
 800289a:	bd08      	pop	{r3, pc}
 800289c:	20000060 	.word	0x20000060
 80028a0:	2000080c 	.word	0x2000080c

080028a4 <z_init_cpu>:
	thread->base.is_idle = 1U;
#endif
}

void z_init_cpu(int id)
{
 80028a4:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = &z_idle_threads[i];
 80028a6:	4e17      	ldr	r6, [pc, #92]	; (8002904 <z_init_cpu+0x60>)
			  CONFIG_IDLE_STACK_SIZE, idle, &_kernel.cpus[i],
 80028a8:	4d17      	ldr	r5, [pc, #92]	; (8002908 <z_init_cpu+0x64>)
	z_setup_new_thread(thread, stack,
 80028aa:	4918      	ldr	r1, [pc, #96]	; (800290c <z_init_cpu+0x68>)
{
 80028ac:	b086      	sub	sp, #24
	struct k_thread *thread = &z_idle_threads[i];
 80028ae:	23b0      	movs	r3, #176	; 0xb0
 80028b0:	fb03 6600 	mla	r6, r3, r0, r6
	z_setup_new_thread(thread, stack,
 80028b4:	4b16      	ldr	r3, [pc, #88]	; (8002910 <z_init_cpu+0x6c>)
 80028b6:	9305      	str	r3, [sp, #20]
 80028b8:	2201      	movs	r2, #1
 80028ba:	2328      	movs	r3, #40	; 0x28
 80028bc:	e9cd 3203 	strd	r3, r2, [sp, #12]
 80028c0:	2300      	movs	r3, #0
 80028c2:	e9cd 3301 	strd	r3, r3, [sp, #4]
			  CONFIG_IDLE_STACK_SIZE, idle, &_kernel.cpus[i],
 80028c6:	2318      	movs	r3, #24
 80028c8:	fb03 5500 	mla	r5, r3, r0, r5
{
 80028cc:	4604      	mov	r4, r0
	z_setup_new_thread(thread, stack,
 80028ce:	f44f 70c0 	mov.w	r0, #384	; 0x180
 80028d2:	fb00 1104 	mla	r1, r0, r4, r1
 80028d6:	4b0f      	ldr	r3, [pc, #60]	; (8002914 <z_init_cpu+0x70>)
 80028d8:	9500      	str	r5, [sp, #0]
 80028da:	f44f 72a0 	mov.w	r2, #320	; 0x140
 80028de:	4630      	mov	r0, r6
 80028e0:	f000 f912 	bl	8002b08 <z_setup_new_thread>
	SYS_PORT_TRACING_FUNC(k_thread, sched_resume, thread);
}

static inline void z_mark_thread_as_started(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PRESTART;
 80028e4:	7b73      	ldrb	r3, [r6, #13]
	init_idle_thread(id);
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
	_kernel.cpus[id].id = id;
	_kernel.cpus[id].irq_stack =
		(Z_KERNEL_STACK_BUFFER(z_interrupt_stacks[id]) +
 80028e6:	4a0c      	ldr	r2, [pc, #48]	; (8002918 <z_init_cpu+0x74>)
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
 80028e8:	60ee      	str	r6, [r5, #12]
 80028ea:	f023 0304 	bic.w	r3, r3, #4
 80028ee:	7373      	strb	r3, [r6, #13]
		(Z_KERNEL_STACK_BUFFER(z_interrupt_stacks[id]) +
 80028f0:	f44f 6304 	mov.w	r3, #2112	; 0x840
 80028f4:	fb04 3303 	mla	r3, r4, r3, r3
 80028f8:	4413      	add	r3, r2
	_kernel.cpus[id].id = id;
 80028fa:	752c      	strb	r4, [r5, #20]
	_kernel.cpus[id].irq_stack =
 80028fc:	606b      	str	r3, [r5, #4]
		 K_KERNEL_STACK_SIZEOF(z_interrupt_stacks[id]));
#ifdef CONFIG_SCHED_THREAD_USAGE_ALL
	_kernel.cpus[id].usage.track_usage =
		CONFIG_SCHED_THREAD_USAGE_AUTO_ENABLE;
#endif
}
 80028fe:	b006      	add	sp, #24
 8002900:	bd70      	pop	{r4, r5, r6, pc}
 8002902:	bf00      	nop
 8002904:	20000480 	.word	0x20000480
 8002908:	200007b8 	.word	0x200007b8
 800290c:	20004200 	.word	0x20004200
 8002910:	0800631d 	.word	0x0800631d
 8002914:	08002de1 	.word	0x08002de1
 8002918:	200039c0 	.word	0x200039c0

0800291c <z_cstart>:
 *
 * @return Does not return
 */
__boot_func
FUNC_NORETURN void z_cstart(void)
{
 800291c:	b580      	push	{r7, lr}
	/* gcov hook needed to get the coverage report.*/
	gcov_static_init();

	/* initialize early init calls */
	z_sys_init_run_level(INIT_LEVEL_EARLY);
 800291e:	2000      	movs	r0, #0
{
 8002920:	b0b2      	sub	sp, #200	; 0xc8
	z_sys_init_run_level(INIT_LEVEL_EARLY);
 8002922:	f7ff ff77 	bl	8002814 <z_sys_init_run_level>
 * pointer) register, and switched to automatically when taking an exception.
 *
 */
static ALWAYS_INLINE void z_arm_interrupt_stack_setup(void)
{
	uint32_t msp =
 8002926:	4b2c      	ldr	r3, [pc, #176]	; (80029d8 <z_cstart+0xbc>)
  \details Assigns the given value to the Main Stack Pointer (MSP).
  \param [in]    topOfMainStack  Main Stack Pointer value to set
 */
__STATIC_FORCEINLINE void __set_MSP(uint32_t topOfMainStack)
{
  __ASM volatile ("MSR msp, %0" : : "r" (topOfMainStack) : );
 8002928:	f383 8808 	msr	MSP, r3
	 * for Cortex-M3 and Cortex-M4 (ARMv7-M) MCUs. For the rest
	 * of ARM Cortex-M processors this setting is enforced by
	 * default and it is not configurable.
	 */
#if defined(CONFIG_CPU_CORTEX_M3) || defined(CONFIG_CPU_CORTEX_M4)
	SCB->CCR |= SCB_CCR_STKALIGN_Msk;
 800292c:	4d2b      	ldr	r5, [pc, #172]	; (80029dc <z_cstart+0xc0>)

#ifdef CONFIG_TIMESLICE_PER_THREAD
	dummy_thread->base.slice_ticks = 0;
#endif

	_current_cpu->current = dummy_thread;
 800292e:	4e2c      	ldr	r6, [pc, #176]	; (80029e0 <z_cstart+0xc4>)
 8002930:	696b      	ldr	r3, [r5, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
 8002932:	4f2c      	ldr	r7, [pc, #176]	; (80029e4 <z_cstart+0xc8>)
 8002934:	f443 7300 	orr.w	r3, r3, #512	; 0x200
 8002938:	616b      	str	r3, [r5, #20]
 800293a:	2400      	movs	r4, #0
 800293c:	23f0      	movs	r3, #240	; 0xf0
 800293e:	f885 3022 	strb.w	r3, [r5, #34]	; 0x22
 8002942:	77ec      	strb	r4, [r5, #31]
 8002944:	762c      	strb	r4, [r5, #24]
 8002946:	766c      	strb	r4, [r5, #25]
 8002948:	76ac      	strb	r4, [r5, #26]
 800294a:	f885 4020 	strb.w	r4, [r5, #32]
#if defined(CONFIG_ARM_SECURE_FIRMWARE)
	NVIC_SetPriority(SecureFault_IRQn, _EXC_FAULT_PRIO);
#endif /* CONFIG_ARM_SECURE_FIRMWARE */

	/* Enable Usage, Mem, & Bus Faults */
	SCB->SHCSR |= SCB_SHCSR_USGFAULTENA_Msk | SCB_SHCSR_MEMFAULTENA_Msk |
 800294e:	6a6b      	ldr	r3, [r5, #36]	; 0x24
 8002950:	f443 23e0 	orr.w	r3, r3, #458752	; 0x70000
 8002954:	626b      	str	r3, [r5, #36]	; 0x24

static ALWAYS_INLINE void arch_kernel_init(void)
{
	z_arm_interrupt_stack_setup();
	z_arm_exc_setup();
	z_arm_fault_init();
 8002956:	f7fe fedb 	bl	8001710 <z_arm_fault_init>
	z_arm_cpu_idle_init();
 800295a:	f7fe fc55 	bl	8001208 <z_arm_cpu_idle_init>
static ALWAYS_INLINE void z_arm_clear_faults(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* Reset all faults */
	SCB->CFSR = SCB_CFSR_USGFAULTSR_Msk |
 800295e:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
 8002962:	62ab      	str	r3, [r5, #40]	; 0x28
		    SCB_CFSR_MEMFAULTSR_Msk |
		    SCB_CFSR_BUSFAULTSR_Msk;

	/* Clear all Hard Faults - HFSR is write-one-to-clear */
	SCB->HFSR = 0xffffffff;
 8002964:	62eb      	str	r3, [r5, #44]	; 0x2c
	z_arm_clear_faults();
#if defined(CONFIG_ARM_MPU)
	z_arm_mpu_init();
 8002966:	f7fe ffef 	bl	8001948 <z_arm_mpu_init>
	 * to set up access permissions for fixed memory sections, such
	 * as Application Memory or No-Cacheable SRAM area.
	 *
	 * This function is invoked once, upon system initialization.
	 */
	z_arm_configure_static_mpu_regions();
 800296a:	f7fe ff1f 	bl	80017ac <z_arm_configure_static_mpu_regions>
	dummy_thread->base.user_options = K_ESSENTIAL;
 800296e:	f240 1301 	movw	r3, #257	; 0x101
 8002972:	f8ad 3024 	strh.w	r3, [sp, #36]	; 0x24
	_current_cpu->current = dummy_thread;
 8002976:	ab06      	add	r3, sp, #24
 8002978:	60b3      	str	r3, [r6, #8]
	dummy_thread->stack_info.size = 0U;
 800297a:	e9cd 442c 	strd	r4, r4, [sp, #176]	; 0xb0
	dummy_thread->resource_pool = NULL;
 800297e:	942f      	str	r4, [sp, #188]	; 0xbc
	struct k_thread dummy_thread;

	z_dummy_thread_init(&dummy_thread);
#endif
	/* do any necessary initialization of static devices */
	z_device_state_init();
 8002980:	f002 fc72 	bl	8005268 <z_device_state_init>

	/* perform basic hardware initialization */
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
 8002984:	2001      	movs	r0, #1
 8002986:	f7ff ff45 	bl	8002814 <z_sys_init_run_level>
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
 800298a:	2002      	movs	r0, #2
	_kernel.ready_q.cache = &z_main_thread;
 800298c:	4d16      	ldr	r5, [pc, #88]	; (80029e8 <z_cstart+0xcc>)
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
 800298e:	f7ff ff41 	bl	8002814 <z_sys_init_run_level>
	z_sched_init();
 8002992:	f001 f9c9 	bl	8003d28 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
 8002996:	4b15      	ldr	r3, [pc, #84]	; (80029ec <z_cstart+0xd0>)
	_kernel.ready_q.cache = &z_main_thread;
 8002998:	61b5      	str	r5, [r6, #24]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
 800299a:	9305      	str	r3, [sp, #20]
 800299c:	2301      	movs	r3, #1
 800299e:	4914      	ldr	r1, [pc, #80]	; (80029f0 <z_cstart+0xd4>)
 80029a0:	9400      	str	r4, [sp, #0]
 80029a2:	e9cd 4303 	strd	r4, r3, [sp, #12]
 80029a6:	f44f 6280 	mov.w	r2, #1024	; 0x400
 80029aa:	463b      	mov	r3, r7
 80029ac:	e9cd 4401 	strd	r4, r4, [sp, #4]
 80029b0:	4628      	mov	r0, r5
 80029b2:	f000 f8a9 	bl	8002b08 <z_setup_new_thread>
 80029b6:	7b6a      	ldrb	r2, [r5, #13]
 80029b8:	4606      	mov	r6, r0
 80029ba:	f022 0204 	bic.w	r2, r2, #4
	z_ready_thread(&z_main_thread);
 80029be:	4628      	mov	r0, r5
 80029c0:	736a      	strb	r2, [r5, #13]
 80029c2:	f000 fe47 	bl	8003654 <z_ready_thread>
	z_init_cpu(0);
 80029c6:	4620      	mov	r0, r4
 80029c8:	f7ff ff6c 	bl	80028a4 <z_init_cpu>
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
 80029cc:	463a      	mov	r2, r7
 80029ce:	4631      	mov	r1, r6
 80029d0:	4628      	mov	r0, r5
 80029d2:	f7fe fd23 	bl	800141c <arch_switch_to_main_thread>
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
 80029d6:	bf00      	nop
 80029d8:	20004200 	.word	0x20004200
 80029dc:	e000ed00 	.word	0xe000ed00
 80029e0:	200007b8 	.word	0x200007b8
 80029e4:	08002859 	.word	0x08002859
 80029e8:	20000530 	.word	0x20000530
 80029ec:	08006322 	.word	0x08006322
 80029f0:	20004380 	.word	0x20004380

080029f4 <z_impl_k_thread_name_set>:
	k_spin_unlock(&z_thread_monitor_lock, key);
}
#endif

int z_impl_k_thread_name_set(struct k_thread *thread, const char *value)
{
 80029f4:	b510      	push	{r4, lr}
#ifdef CONFIG_THREAD_NAME
	if (thread == NULL) {
 80029f6:	4604      	mov	r4, r0
 80029f8:	b908      	cbnz	r0, 80029fe <z_impl_k_thread_name_set+0xa>
		thread = _current;
 80029fa:	4b05      	ldr	r3, [pc, #20]	; (8002a10 <z_impl_k_thread_name_set+0x1c>)
 80029fc:	689c      	ldr	r4, [r3, #8]
	}

	strncpy(thread->name, value, CONFIG_THREAD_MAX_NAME_LEN - 1);
 80029fe:	221f      	movs	r2, #31
 8002a00:	f104 0074 	add.w	r0, r4, #116	; 0x74
 8002a04:	f002 f8a0 	bl	8004b48 <strncpy>
	thread->name[CONFIG_THREAD_MAX_NAME_LEN - 1] = '\0';
 8002a08:	2000      	movs	r0, #0
 8002a0a:	f884 0093 	strb.w	r0, [r4, #147]	; 0x93

	SYS_PORT_TRACING_OBJ_FUNC(k_thread, name_set, thread, -ENOSYS);

	return -ENOSYS;
#endif /* CONFIG_THREAD_NAME */
}
 8002a0e:	bd10      	pop	{r4, pc}
 8002a10:	200007b8 	.word	0x200007b8

08002a14 <z_spin_lock_valid>:
 * them in spinlock.h is a giant header ordering headache.
 */
#ifdef CONFIG_SPIN_VALIDATE
bool z_spin_lock_valid(struct k_spinlock *l)
{
	uintptr_t thread_cpu = l->thread_cpu;
 8002a14:	6800      	ldr	r0, [r0, #0]

	if (thread_cpu != 0U) {
 8002a16:	b138      	cbz	r0, 8002a28 <z_spin_lock_valid+0x14>
		if ((thread_cpu & 3U) == _current_cpu->id) {
 8002a18:	4b04      	ldr	r3, [pc, #16]	; (8002a2c <z_spin_lock_valid+0x18>)
 8002a1a:	7d1b      	ldrb	r3, [r3, #20]
 8002a1c:	f000 0003 	and.w	r0, r0, #3
 8002a20:	1ac0      	subs	r0, r0, r3
 8002a22:	bf18      	it	ne
 8002a24:	2001      	movne	r0, #1
 8002a26:	4770      	bx	lr
			return false;
		}
	}
	return true;
 8002a28:	2001      	movs	r0, #1
}
 8002a2a:	4770      	bx	lr
 8002a2c:	200007b8 	.word	0x200007b8

08002a30 <z_spin_unlock_valid>:

bool z_spin_unlock_valid(struct k_spinlock *l)
{
	if (l->thread_cpu != (_current_cpu->id | (uintptr_t)_current)) {
 8002a30:	4a06      	ldr	r2, [pc, #24]	; (8002a4c <z_spin_unlock_valid+0x1c>)
 8002a32:	7d11      	ldrb	r1, [r2, #20]
 8002a34:	6892      	ldr	r2, [r2, #8]
 8002a36:	430a      	orrs	r2, r1
 8002a38:	6801      	ldr	r1, [r0, #0]
{
 8002a3a:	4603      	mov	r3, r0
	if (l->thread_cpu != (_current_cpu->id | (uintptr_t)_current)) {
 8002a3c:	4291      	cmp	r1, r2
 8002a3e:	f04f 0000 	mov.w	r0, #0
		return false;
	}
	l->thread_cpu = 0;
 8002a42:	bf04      	itt	eq
 8002a44:	6018      	streq	r0, [r3, #0]
	return true;
 8002a46:	2001      	moveq	r0, #1
}
 8002a48:	4770      	bx	lr
 8002a4a:	bf00      	nop
 8002a4c:	200007b8 	.word	0x200007b8

08002a50 <z_spin_lock_set_owner>:

void z_spin_lock_set_owner(struct k_spinlock *l)
{
	l->thread_cpu = _current_cpu->id | (uintptr_t)_current;
 8002a50:	4b02      	ldr	r3, [pc, #8]	; (8002a5c <z_spin_lock_set_owner+0xc>)
 8002a52:	7d1a      	ldrb	r2, [r3, #20]
 8002a54:	689b      	ldr	r3, [r3, #8]
 8002a56:	4313      	orrs	r3, r2
 8002a58:	6003      	str	r3, [r0, #0]
}
 8002a5a:	4770      	bx	lr
 8002a5c:	200007b8 	.word	0x200007b8

08002a60 <z_thread_monitor_exit>:
{
 8002a60:	b510      	push	{r4, lr}
 8002a62:	4601      	mov	r1, r0
	__asm__ volatile(
 8002a64:	f04f 0310 	mov.w	r3, #16
 8002a68:	f3ef 8411 	mrs	r4, BASEPRI
 8002a6c:	f383 8812 	msr	BASEPRI_MAX, r3
 8002a70:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8002a74:	481c      	ldr	r0, [pc, #112]	; (8002ae8 <z_thread_monitor_exit+0x88>)
 8002a76:	f7ff ffcd 	bl	8002a14 <z_spin_lock_valid>
 8002a7a:	b968      	cbnz	r0, 8002a98 <z_thread_monitor_exit+0x38>
 8002a7c:	4a1b      	ldr	r2, [pc, #108]	; (8002aec <z_thread_monitor_exit+0x8c>)
 8002a7e:	491c      	ldr	r1, [pc, #112]	; (8002af0 <z_thread_monitor_exit+0x90>)
 8002a80:	481c      	ldr	r0, [pc, #112]	; (8002af4 <z_thread_monitor_exit+0x94>)
 8002a82:	2394      	movs	r3, #148	; 0x94
 8002a84:	f002 f83f 	bl	8004b06 <assert_print>
 8002a88:	4917      	ldr	r1, [pc, #92]	; (8002ae8 <z_thread_monitor_exit+0x88>)
 8002a8a:	481b      	ldr	r0, [pc, #108]	; (8002af8 <z_thread_monitor_exit+0x98>)
 8002a8c:	f002 f83b 	bl	8004b06 <assert_print>
 8002a90:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002a92:	4816      	ldr	r0, [pc, #88]	; (8002aec <z_thread_monitor_exit+0x8c>)
 8002a94:	f002 f830 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 8002a98:	4813      	ldr	r0, [pc, #76]	; (8002ae8 <z_thread_monitor_exit+0x88>)
 8002a9a:	f7ff ffd9 	bl	8002a50 <z_spin_lock_set_owner>
	if (thread == _kernel.threads) {
 8002a9e:	4a17      	ldr	r2, [pc, #92]	; (8002afc <z_thread_monitor_exit+0x9c>)
 8002aa0:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
 8002aa2:	428b      	cmp	r3, r1
 8002aa4:	d112      	bne.n	8002acc <z_thread_monitor_exit+0x6c>
		_kernel.threads = _kernel.threads->next_thread;
 8002aa6:	6f1b      	ldr	r3, [r3, #112]	; 0x70
 8002aa8:	62d3      	str	r3, [r2, #44]	; 0x2c
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002aaa:	480f      	ldr	r0, [pc, #60]	; (8002ae8 <z_thread_monitor_exit+0x88>)
 8002aac:	f7ff ffc0 	bl	8002a30 <z_spin_unlock_valid>
 8002ab0:	b9a0      	cbnz	r0, 8002adc <z_thread_monitor_exit+0x7c>
 8002ab2:	4a0e      	ldr	r2, [pc, #56]	; (8002aec <z_thread_monitor_exit+0x8c>)
 8002ab4:	4912      	ldr	r1, [pc, #72]	; (8002b00 <z_thread_monitor_exit+0xa0>)
 8002ab6:	480f      	ldr	r0, [pc, #60]	; (8002af4 <z_thread_monitor_exit+0x94>)
 8002ab8:	23c2      	movs	r3, #194	; 0xc2
 8002aba:	f002 f824 	bl	8004b06 <assert_print>
 8002abe:	490a      	ldr	r1, [pc, #40]	; (8002ae8 <z_thread_monitor_exit+0x88>)
 8002ac0:	4810      	ldr	r0, [pc, #64]	; (8002b04 <z_thread_monitor_exit+0xa4>)
 8002ac2:	f002 f820 	bl	8004b06 <assert_print>
 8002ac6:	21c2      	movs	r1, #194	; 0xc2
 8002ac8:	e7e3      	b.n	8002a92 <z_thread_monitor_exit+0x32>
 8002aca:	4613      	mov	r3, r2
		while ((prev_thread != NULL) &&
 8002acc:	2b00      	cmp	r3, #0
 8002ace:	d0ec      	beq.n	8002aaa <z_thread_monitor_exit+0x4a>
			(thread != prev_thread->next_thread)) {
 8002ad0:	6f1a      	ldr	r2, [r3, #112]	; 0x70
		while ((prev_thread != NULL) &&
 8002ad2:	428a      	cmp	r2, r1
 8002ad4:	d1f9      	bne.n	8002aca <z_thread_monitor_exit+0x6a>
			prev_thread->next_thread = thread->next_thread;
 8002ad6:	6f0a      	ldr	r2, [r1, #112]	; 0x70
 8002ad8:	671a      	str	r2, [r3, #112]	; 0x70
 8002ada:	e7e6      	b.n	8002aaa <z_thread_monitor_exit+0x4a>
	__asm__ volatile(
 8002adc:	f384 8811 	msr	BASEPRI, r4
 8002ae0:	f3bf 8f6f 	isb	sy
}
 8002ae4:	bd10      	pop	{r4, pc}
 8002ae6:	bf00      	nop
 8002ae8:	200007e8 	.word	0x200007e8
 8002aec:	080061b7 	.word	0x080061b7
 8002af0:	080061e4 	.word	0x080061e4
 8002af4:	08005ca7 	.word	0x08005ca7
 8002af8:	080061f9 	.word	0x080061f9
 8002afc:	200007b8 	.word	0x200007b8
 8002b00:	08006211 	.word	0x08006211
 8002b04:	08006228 	.word	0x08006228

08002b08 <z_setup_new_thread>:
{
 8002b08:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
 8002b0c:	b085      	sub	sp, #20
 8002b0e:	e9dd 8610 	ldrd	r8, r6, [sp, #64]	; 0x40
	Z_ASSERT_VALID_PRIO(prio, entry);
 8002b12:	2e28      	cmp	r6, #40	; 0x28
{
 8002b14:	e9dd a90e 	ldrd	sl, r9, [sp, #56]	; 0x38
 8002b18:	9f13      	ldr	r7, [sp, #76]	; 0x4c
 8002b1a:	4604      	mov	r4, r0
 8002b1c:	469b      	mov	fp, r3
	Z_ASSERT_VALID_PRIO(prio, entry);
 8002b1e:	d143      	bne.n	8002ba8 <z_setup_new_thread+0xa0>
 8002b20:	4b47      	ldr	r3, [pc, #284]	; (8002c40 <z_setup_new_thread+0x138>)
 8002b22:	459b      	cmp	fp, r3
 8002b24:	d144      	bne.n	8002bb0 <z_setup_new_thread+0xa8>
	SYS_DLIST_FOR_EACH_CONTAINER(&((wq)->waitq), thread_ptr, \
				     base.qnode_dlist)

static inline void z_waitq_init(_wait_q_t *w)
{
	sys_dlist_init(&w->waitq);
 8002b26:	f104 0358 	add.w	r3, r4, #88	; 0x58
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
 8002b2a:	3207      	adds	r2, #7
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
	list->tail = (sys_dnode_t *)list;
 8002b2c:	e9c4 3316 	strd	r3, r3, [r4, #88]	; 0x58
 8002b30:	f022 0207 	bic.w	r2, r2, #7
	thread_base->user_options = (uint8_t)options;
 8002b34:	9b12      	ldr	r3, [sp, #72]	; 0x48
 8002b36:	7323      	strb	r3, [r4, #12]
	thread_base->prio = priority;
 8002b38:	73a6      	strb	r6, [r4, #14]
	thread_base->thread_state = (uint8_t)initial_state;
 8002b3a:	2304      	movs	r3, #4
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
 8002b3c:	f102 0640 	add.w	r6, r2, #64	; 0x40
	thread_base->pended_on = NULL;
 8002b40:	2500      	movs	r5, #0
	thread_base->thread_state = (uint8_t)initial_state;
 8002b42:	7363      	strb	r3, [r4, #13]
	stack_ptr = (char *)stack + stack_obj_size;
 8002b44:	440e      	add	r6, r1

/** @} */

static inline char *Z_KERNEL_STACK_BUFFER(k_thread_stack_t *sym)
{
	return (char *)sym + K_KERNEL_STACK_RESERVED;
 8002b46:	f101 0340 	add.w	r3, r1, #64	; 0x40
	new_thread->stack_info.size = stack_buf_size;
 8002b4a:	e9c4 3226 	strd	r3, r2, [r4, #152]	; 0x98
 */

static inline void sys_dnode_init(sys_dnode_t *node)
{
	node->next = NULL;
	node->prev = NULL;
 8002b4e:	e9c4 5506 	strd	r5, r5, [r4, #24]
	thread_base->pended_on = NULL;
 8002b52:	60a5      	str	r5, [r4, #8]
	thread_base->sched_locked = 0U;
 8002b54:	73e5      	strb	r5, [r4, #15]
	new_thread->stack_info.delta = delta;
 8002b56:	f8c4 50a0 	str.w	r5, [r4, #160]	; 0xa0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
 8002b5a:	465b      	mov	r3, fp
 8002b5c:	e9cd 9801 	strd	r9, r8, [sp, #4]
 8002b60:	f8cd a000 	str.w	sl, [sp]
 8002b64:	4632      	mov	r2, r6
 8002b66:	4620      	mov	r0, r4
 8002b68:	f7fe fc24 	bl	80013b4 <arch_new_thread>
	new_thread->entry.parameter1 = p1;
 8002b6c:	e9c4 ba18 	strd	fp, sl, [r4, #96]	; 0x60
	new_thread->entry.parameter3 = p3;
 8002b70:	e9c4 981a 	strd	r9, r8, [r4, #104]	; 0x68
	new_thread->init_data = NULL;
 8002b74:	6565      	str	r5, [r4, #84]	; 0x54
	__asm__ volatile(
 8002b76:	f04f 0310 	mov.w	r3, #16
 8002b7a:	f3ef 8911 	mrs	r9, BASEPRI
 8002b7e:	f383 8812 	msr	BASEPRI_MAX, r3
 8002b82:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8002b86:	482f      	ldr	r0, [pc, #188]	; (8002c44 <z_setup_new_thread+0x13c>)
 8002b88:	f7ff ff44 	bl	8002a14 <z_spin_lock_valid>
 8002b8c:	bb18      	cbnz	r0, 8002bd6 <z_setup_new_thread+0xce>
 8002b8e:	4a2e      	ldr	r2, [pc, #184]	; (8002c48 <z_setup_new_thread+0x140>)
 8002b90:	492e      	ldr	r1, [pc, #184]	; (8002c4c <z_setup_new_thread+0x144>)
 8002b92:	482f      	ldr	r0, [pc, #188]	; (8002c50 <z_setup_new_thread+0x148>)
 8002b94:	2394      	movs	r3, #148	; 0x94
 8002b96:	f001 ffb6 	bl	8004b06 <assert_print>
 8002b9a:	492a      	ldr	r1, [pc, #168]	; (8002c44 <z_setup_new_thread+0x13c>)
 8002b9c:	482d      	ldr	r0, [pc, #180]	; (8002c54 <z_setup_new_thread+0x14c>)
 8002b9e:	f001 ffb2 	bl	8004b06 <assert_print>
 8002ba2:	2194      	movs	r1, #148	; 0x94
 8002ba4:	4828      	ldr	r0, [pc, #160]	; (8002c48 <z_setup_new_thread+0x140>)
 8002ba6:	e014      	b.n	8002bd2 <z_setup_new_thread+0xca>
	Z_ASSERT_VALID_PRIO(prio, entry);
 8002ba8:	f106 031d 	add.w	r3, r6, #29
 8002bac:	2b44      	cmp	r3, #68	; 0x44
 8002bae:	d9ba      	bls.n	8002b26 <z_setup_new_thread+0x1e>
 8002bb0:	4a29      	ldr	r2, [pc, #164]	; (8002c58 <z_setup_new_thread+0x150>)
 8002bb2:	492a      	ldr	r1, [pc, #168]	; (8002c5c <z_setup_new_thread+0x154>)
 8002bb4:	4826      	ldr	r0, [pc, #152]	; (8002c50 <z_setup_new_thread+0x148>)
 8002bb6:	f44f 7306 	mov.w	r3, #536	; 0x218
 8002bba:	f001 ffa4 	bl	8004b06 <assert_print>
 8002bbe:	4828      	ldr	r0, [pc, #160]	; (8002c60 <z_setup_new_thread+0x158>)
 8002bc0:	4631      	mov	r1, r6
 8002bc2:	f06f 031c 	mvn.w	r3, #28
 8002bc6:	2227      	movs	r2, #39	; 0x27
 8002bc8:	f001 ff9d 	bl	8004b06 <assert_print>
 8002bcc:	4822      	ldr	r0, [pc, #136]	; (8002c58 <z_setup_new_thread+0x150>)
 8002bce:	f44f 7106 	mov.w	r1, #536	; 0x218
 8002bd2:	f001 ff91 	bl	8004af8 <assert_post_action>
	new_thread->next_thread = _kernel.threads;
 8002bd6:	f8df 808c 	ldr.w	r8, [pc, #140]	; 8002c64 <z_setup_new_thread+0x15c>
	z_spin_lock_set_owner(l);
 8002bda:	481a      	ldr	r0, [pc, #104]	; (8002c44 <z_setup_new_thread+0x13c>)
 8002bdc:	f7ff ff38 	bl	8002a50 <z_spin_lock_set_owner>
 8002be0:	f8d8 302c 	ldr.w	r3, [r8, #44]	; 0x2c
 8002be4:	6723      	str	r3, [r4, #112]	; 0x70
	_kernel.threads = new_thread;
 8002be6:	f8c8 402c 	str.w	r4, [r8, #44]	; 0x2c
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002bea:	f7ff ff21 	bl	8002a30 <z_spin_unlock_valid>
 8002bee:	b958      	cbnz	r0, 8002c08 <z_setup_new_thread+0x100>
 8002bf0:	4a15      	ldr	r2, [pc, #84]	; (8002c48 <z_setup_new_thread+0x140>)
 8002bf2:	491d      	ldr	r1, [pc, #116]	; (8002c68 <z_setup_new_thread+0x160>)
 8002bf4:	4816      	ldr	r0, [pc, #88]	; (8002c50 <z_setup_new_thread+0x148>)
 8002bf6:	23c2      	movs	r3, #194	; 0xc2
 8002bf8:	f001 ff85 	bl	8004b06 <assert_print>
 8002bfc:	4911      	ldr	r1, [pc, #68]	; (8002c44 <z_setup_new_thread+0x13c>)
 8002bfe:	481b      	ldr	r0, [pc, #108]	; (8002c6c <z_setup_new_thread+0x164>)
 8002c00:	f001 ff81 	bl	8004b06 <assert_print>
 8002c04:	21c2      	movs	r1, #194	; 0xc2
 8002c06:	e7cd      	b.n	8002ba4 <z_setup_new_thread+0x9c>
	__asm__ volatile(
 8002c08:	f389 8811 	msr	BASEPRI, r9
 8002c0c:	f3bf 8f6f 	isb	sy
	if (name != NULL) {
 8002c10:	b197      	cbz	r7, 8002c38 <z_setup_new_thread+0x130>
		strncpy(new_thread->name, name,
 8002c12:	221f      	movs	r2, #31
 8002c14:	4639      	mov	r1, r7
 8002c16:	f104 0074 	add.w	r0, r4, #116	; 0x74
 8002c1a:	f001 ff95 	bl	8004b48 <strncpy>
		new_thread->name[CONFIG_THREAD_MAX_NAME_LEN - 1] = '\0';
 8002c1e:	f884 5093 	strb.w	r5, [r4, #147]	; 0x93
	if (!_current) {
 8002c22:	f8d8 3008 	ldr.w	r3, [r8, #8]
 8002c26:	b10b      	cbz	r3, 8002c2c <z_setup_new_thread+0x124>
	new_thread->resource_pool = _current->resource_pool;
 8002c28:	f8d3 30a4 	ldr.w	r3, [r3, #164]	; 0xa4
	return stack_ptr;
 8002c2c:	f8c4 30a4 	str.w	r3, [r4, #164]	; 0xa4
}
 8002c30:	4630      	mov	r0, r6
 8002c32:	b005      	add	sp, #20
 8002c34:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		new_thread->name[0] = '\0';
 8002c38:	f884 7074 	strb.w	r7, [r4, #116]	; 0x74
 8002c3c:	e7f1      	b.n	8002c22 <z_setup_new_thread+0x11a>
 8002c3e:	bf00      	nop
 8002c40:	08002de1 	.word	0x08002de1
 8002c44:	200007e8 	.word	0x200007e8
 8002c48:	080061b7 	.word	0x080061b7
 8002c4c:	080061e4 	.word	0x080061e4
 8002c50:	08005ca7 	.word	0x08005ca7
 8002c54:	080061f9 	.word	0x080061f9
 8002c58:	0800632a 	.word	0x0800632a
 8002c5c:	0800637e 	.word	0x0800637e
 8002c60:	080063fe 	.word	0x080063fe
 8002c64:	200007b8 	.word	0x200007b8
 8002c68:	08006211 	.word	0x08006211
 8002c6c:	08006228 	.word	0x08006228

08002c70 <z_impl_k_thread_create>:
{
 8002c70:	b5f0      	push	{r4, r5, r6, r7, lr}
 8002c72:	b087      	sub	sp, #28
 8002c74:	e9dd 7612 	ldrd	r7, r6, [sp, #72]	; 0x48
 8002c78:	4604      	mov	r4, r0
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
 8002c7a:	f3ef 8505 	mrs	r5, IPSR
	__ASSERT(!arch_is_in_isr(), "Threads may not be created in ISRs");
 8002c7e:	b175      	cbz	r5, 8002c9e <z_impl_k_thread_create+0x2e>
 8002c80:	4919      	ldr	r1, [pc, #100]	; (8002ce8 <z_impl_k_thread_create+0x78>)
 8002c82:	4a1a      	ldr	r2, [pc, #104]	; (8002cec <z_impl_k_thread_create+0x7c>)
 8002c84:	481a      	ldr	r0, [pc, #104]	; (8002cf0 <z_impl_k_thread_create+0x80>)
 8002c86:	f240 2387 	movw	r3, #647	; 0x287
 8002c8a:	f001 ff3c 	bl	8004b06 <assert_print>
 8002c8e:	4819      	ldr	r0, [pc, #100]	; (8002cf4 <z_impl_k_thread_create+0x84>)
 8002c90:	f001 ff39 	bl	8004b06 <assert_print>
 8002c94:	4815      	ldr	r0, [pc, #84]	; (8002cec <z_impl_k_thread_create+0x7c>)
 8002c96:	f240 2187 	movw	r1, #647	; 0x287
 8002c9a:	f001 ff2d 	bl	8004af8 <assert_post_action>
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
 8002c9e:	9505      	str	r5, [sp, #20]
 8002ca0:	9d10      	ldr	r5, [sp, #64]	; 0x40
 8002ca2:	9504      	str	r5, [sp, #16]
 8002ca4:	9d0f      	ldr	r5, [sp, #60]	; 0x3c
 8002ca6:	9503      	str	r5, [sp, #12]
 8002ca8:	9d0e      	ldr	r5, [sp, #56]	; 0x38
 8002caa:	9502      	str	r5, [sp, #8]
 8002cac:	9d0d      	ldr	r5, [sp, #52]	; 0x34
 8002cae:	9501      	str	r5, [sp, #4]
 8002cb0:	9d0c      	ldr	r5, [sp, #48]	; 0x30
 8002cb2:	9500      	str	r5, [sp, #0]
 8002cb4:	f7ff ff28 	bl	8002b08 <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
 8002cb8:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
 8002cbc:	bf08      	it	eq
 8002cbe:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
 8002cc2:	d005      	beq.n	8002cd0 <z_impl_k_thread_create+0x60>
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
 8002cc4:	ea56 0307 	orrs.w	r3, r6, r7
 8002cc8:	d105      	bne.n	8002cd6 <z_impl_k_thread_create+0x66>
	z_sched_start(thread);
 8002cca:	4620      	mov	r0, r4
 8002ccc:	f000 fd08 	bl	80036e0 <z_sched_start>
}
 8002cd0:	4620      	mov	r0, r4
 8002cd2:	b007      	add	sp, #28
 8002cd4:	bdf0      	pop	{r4, r5, r6, r7, pc}

extern void z_thread_timeout(struct _timeout *timeout);

static inline void z_add_thread_timeout(struct k_thread *thread, k_timeout_t ticks)
{
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
 8002cd6:	4908      	ldr	r1, [pc, #32]	; (8002cf8 <z_impl_k_thread_create+0x88>)
 8002cd8:	463a      	mov	r2, r7
 8002cda:	4633      	mov	r3, r6
 8002cdc:	f104 0018 	add.w	r0, r4, #24
 8002ce0:	f001 faac 	bl	800423c <z_add_timeout>
 8002ce4:	e7f4      	b.n	8002cd0 <z_impl_k_thread_create+0x60>
 8002ce6:	bf00      	nop
 8002ce8:	0800642f 	.word	0x0800642f
 8002cec:	0800632a 	.word	0x0800632a
 8002cf0:	08005ca7 	.word	0x08005ca7
 8002cf4:	08006441 	.word	0x08006441
 8002cf8:	08003785 	.word	0x08003785

08002cfc <z_init_static_threads>:
{
 8002cfc:	b5f0      	push	{r4, r5, r6, r7, lr}
 8002cfe:	4c31      	ldr	r4, [pc, #196]	; (8002dc4 <z_init_static_threads+0xc8>)
	_FOREACH_STATIC_THREAD(thread_data) {
 8002d00:	4d31      	ldr	r5, [pc, #196]	; (8002dc8 <z_init_static_threads+0xcc>)
{
 8002d02:	b087      	sub	sp, #28
	_FOREACH_STATIC_THREAD(thread_data) {
 8002d04:	42ac      	cmp	r4, r5
 8002d06:	4626      	mov	r6, r4
 8002d08:	d92a      	bls.n	8002d60 <z_init_static_threads+0x64>
 8002d0a:	4930      	ldr	r1, [pc, #192]	; (8002dcc <z_init_static_threads+0xd0>)
 8002d0c:	4a30      	ldr	r2, [pc, #192]	; (8002dd0 <z_init_static_threads+0xd4>)
 8002d0e:	4831      	ldr	r0, [pc, #196]	; (8002dd4 <z_init_static_threads+0xd8>)
 8002d10:	f240 23ee 	movw	r3, #750	; 0x2ee
 8002d14:	f001 fef7 	bl	8004b06 <assert_print>
 8002d18:	482f      	ldr	r0, [pc, #188]	; (8002dd8 <z_init_static_threads+0xdc>)
 8002d1a:	f001 fef4 	bl	8004b06 <assert_print>
 8002d1e:	f240 21ee 	movw	r1, #750	; 0x2ee
	_FOREACH_STATIC_THREAD(thread_data) {
 8002d22:	482b      	ldr	r0, [pc, #172]	; (8002dd0 <z_init_static_threads+0xd4>)
 8002d24:	f001 fee8 	bl	8004af8 <assert_post_action>
		z_setup_new_thread(
 8002d28:	f854 3c04 	ldr.w	r3, [r4, #-4]
 8002d2c:	9305      	str	r3, [sp, #20]
 8002d2e:	f854 3c10 	ldr.w	r3, [r4, #-16]
 8002d32:	9304      	str	r3, [sp, #16]
 8002d34:	f854 3c14 	ldr.w	r3, [r4, #-20]
 8002d38:	9303      	str	r3, [sp, #12]
 8002d3a:	f854 3c18 	ldr.w	r3, [r4, #-24]
 8002d3e:	9302      	str	r3, [sp, #8]
 8002d40:	f854 3c1c 	ldr.w	r3, [r4, #-28]
 8002d44:	9301      	str	r3, [sp, #4]
 8002d46:	f854 3c20 	ldr.w	r3, [r4, #-32]
 8002d4a:	9300      	str	r3, [sp, #0]
 8002d4c:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
 8002d50:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
 8002d54:	f7ff fed8 	bl	8002b08 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
 8002d58:	f854 3c30 	ldr.w	r3, [r4, #-48]
 8002d5c:	655e      	str	r6, [r3, #84]	; 0x54
	_FOREACH_STATIC_THREAD(thread_data) {
 8002d5e:	e7d1      	b.n	8002d04 <z_init_static_threads+0x8>
 8002d60:	42ae      	cmp	r6, r5
 8002d62:	f104 0430 	add.w	r4, r4, #48	; 0x30
 8002d66:	d3df      	bcc.n	8002d28 <z_init_static_threads+0x2c>
	k_sched_lock();
 8002d68:	f000 faa4 	bl	80032b4 <k_sched_lock>
	_FOREACH_STATIC_THREAD(thread_data) {
 8002d6c:	4c15      	ldr	r4, [pc, #84]	; (8002dc4 <z_init_static_threads+0xc8>)
 8002d6e:	4f1b      	ldr	r7, [pc, #108]	; (8002ddc <z_init_static_threads+0xe0>)
		}
	} else if (mul_ratio) {
		if (result32) {
			return ((uint32_t)t) * (to_hz / from_hz);
		} else {
			return t * ((uint64_t)to_hz / from_hz);
 8002d70:	260a      	movs	r6, #10
 8002d72:	42ac      	cmp	r4, r5
 8002d74:	d920      	bls.n	8002db8 <z_init_static_threads+0xbc>
 8002d76:	4915      	ldr	r1, [pc, #84]	; (8002dcc <z_init_static_threads+0xd0>)
 8002d78:	4a15      	ldr	r2, [pc, #84]	; (8002dd0 <z_init_static_threads+0xd4>)
 8002d7a:	4816      	ldr	r0, [pc, #88]	; (8002dd4 <z_init_static_threads+0xd8>)
 8002d7c:	f240 330d 	movw	r3, #781	; 0x30d
 8002d80:	f001 fec1 	bl	8004b06 <assert_print>
 8002d84:	4814      	ldr	r0, [pc, #80]	; (8002dd8 <z_init_static_threads+0xdc>)
 8002d86:	f001 febe 	bl	8004b06 <assert_print>
 8002d8a:	f240 310d 	movw	r1, #781	; 0x30d
 8002d8e:	e7c8      	b.n	8002d22 <z_init_static_threads+0x26>
		if (thread_data->init_delay != K_TICKS_FOREVER) {
 8002d90:	6a62      	ldr	r2, [r4, #36]	; 0x24
 8002d92:	1c53      	adds	r3, r2, #1
 8002d94:	d009      	beq.n	8002daa <z_init_static_threads+0xae>
					    K_MSEC(thread_data->init_delay));
 8002d96:	ea22 72e2 	bic.w	r2, r2, r2, asr #31
 8002d9a:	fb82 2306 	smull	r2, r3, r2, r6
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
 8002d9e:	ea52 0103 	orrs.w	r1, r2, r3
			schedule_new_thread(thread_data->init_thread,
 8002da2:	6820      	ldr	r0, [r4, #0]
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
 8002da4:	d103      	bne.n	8002dae <z_init_static_threads+0xb2>
	z_sched_start(thread);
 8002da6:	f000 fc9b 	bl	80036e0 <z_sched_start>
	_FOREACH_STATIC_THREAD(thread_data) {
 8002daa:	3430      	adds	r4, #48	; 0x30
 8002dac:	e7e1      	b.n	8002d72 <z_init_static_threads+0x76>
 8002dae:	4639      	mov	r1, r7
 8002db0:	3018      	adds	r0, #24
 8002db2:	f001 fa43 	bl	800423c <z_add_timeout>
 8002db6:	e7f8      	b.n	8002daa <z_init_static_threads+0xae>
 8002db8:	d3ea      	bcc.n	8002d90 <z_init_static_threads+0x94>
}
 8002dba:	b007      	add	sp, #28
 8002dbc:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
	k_sched_unlock();
 8002dc0:	f000 bae4 	b.w	800338c <k_sched_unlock>
 8002dc4:	0800577c 	.word	0x0800577c
 8002dc8:	0800577c 	.word	0x0800577c
 8002dcc:	08006466 	.word	0x08006466
 8002dd0:	0800632a 	.word	0x0800632a
 8002dd4:	08005ca7 	.word	0x08005ca7
 8002dd8:	08006493 	.word	0x08006493
 8002ddc:	08003785 	.word	0x08003785

08002de0 <idle>:
#endif	/* CONFIG_PM */
	sys_clock_idle_exit();
}

void idle(void *unused1, void *unused2, void *unused3)
{
 8002de0:	b508      	push	{r3, lr}
	ARG_UNUSED(unused1);
	ARG_UNUSED(unused2);
	ARG_UNUSED(unused3);

	__ASSERT_NO_MSG(_current->base.prio >= 0);
 8002de2:	4b0d      	ldr	r3, [pc, #52]	; (8002e18 <idle+0x38>)
 8002de4:	689b      	ldr	r3, [r3, #8]
 8002de6:	f993 300e 	ldrsb.w	r3, [r3, #14]
 8002dea:	2b00      	cmp	r3, #0
 8002dec:	da09      	bge.n	8002e02 <idle+0x22>
 8002dee:	490b      	ldr	r1, [pc, #44]	; (8002e1c <idle+0x3c>)
 8002df0:	480b      	ldr	r0, [pc, #44]	; (8002e20 <idle+0x40>)
 8002df2:	4a0c      	ldr	r2, [pc, #48]	; (8002e24 <idle+0x44>)
 8002df4:	2327      	movs	r3, #39	; 0x27
 8002df6:	f001 fe86 	bl	8004b06 <assert_print>
 8002dfa:	480a      	ldr	r0, [pc, #40]	; (8002e24 <idle+0x44>)
 8002dfc:	2127      	movs	r1, #39	; 0x27
 8002dfe:	f001 fe7b 	bl	8004af8 <assert_post_action>
	__asm__ volatile(
 8002e02:	f04f 0210 	mov.w	r2, #16
 8002e06:	f3ef 8311 	mrs	r3, BASEPRI
 8002e0a:	f382 8812 	msr	BASEPRI_MAX, r2
 8002e0e:	f3bf 8f6f 	isb	sy
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
 8002e12:	f7fe f9ff 	bl	8001214 <arch_cpu_idle>
 8002e16:	e7f4      	b.n	8002e02 <idle+0x22>
 8002e18:	200007b8 	.word	0x200007b8
 8002e1c:	080064d3 	.word	0x080064d3
 8002e20:	08005ca7 	.word	0x08005ca7
 8002e24:	080064b2 	.word	0x080064b2

08002e28 <z_impl_k_mutex_lock>:
	}
	return false;
}

int z_impl_k_mutex_lock(struct k_mutex *mutex, k_timeout_t timeout)
{
 8002e28:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
 8002e2c:	4604      	mov	r4, r0
 8002e2e:	4617      	mov	r7, r2
 8002e30:	461e      	mov	r6, r3
 8002e32:	f3ef 8505 	mrs	r5, IPSR
	int new_prio;
	k_spinlock_key_t key;
	bool resched = false;

	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");
 8002e36:	b165      	cbz	r5, 8002e52 <z_impl_k_mutex_lock+0x2a>
 8002e38:	4958      	ldr	r1, [pc, #352]	; (8002f9c <z_impl_k_mutex_lock+0x174>)
 8002e3a:	4a59      	ldr	r2, [pc, #356]	; (8002fa0 <z_impl_k_mutex_lock+0x178>)
 8002e3c:	4859      	ldr	r0, [pc, #356]	; (8002fa4 <z_impl_k_mutex_lock+0x17c>)
 8002e3e:	2365      	movs	r3, #101	; 0x65
 8002e40:	f001 fe61 	bl	8004b06 <assert_print>
 8002e44:	4858      	ldr	r0, [pc, #352]	; (8002fa8 <z_impl_k_mutex_lock+0x180>)
 8002e46:	f001 fe5e 	bl	8004b06 <assert_print>
 8002e4a:	4855      	ldr	r0, [pc, #340]	; (8002fa0 <z_impl_k_mutex_lock+0x178>)
 8002e4c:	2165      	movs	r1, #101	; 0x65
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8002e4e:	f001 fe53 	bl	8004af8 <assert_post_action>
 8002e52:	f04f 0310 	mov.w	r3, #16
 8002e56:	f3ef 8811 	mrs	r8, BASEPRI
 8002e5a:	f383 8812 	msr	BASEPRI_MAX, r3
 8002e5e:	f3bf 8f6f 	isb	sy
 8002e62:	4852      	ldr	r0, [pc, #328]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002e64:	f7ff fdd6 	bl	8002a14 <z_spin_lock_valid>
 8002e68:	b960      	cbnz	r0, 8002e84 <z_impl_k_mutex_lock+0x5c>
 8002e6a:	4a51      	ldr	r2, [pc, #324]	; (8002fb0 <z_impl_k_mutex_lock+0x188>)
 8002e6c:	4951      	ldr	r1, [pc, #324]	; (8002fb4 <z_impl_k_mutex_lock+0x18c>)
 8002e6e:	484d      	ldr	r0, [pc, #308]	; (8002fa4 <z_impl_k_mutex_lock+0x17c>)
 8002e70:	2394      	movs	r3, #148	; 0x94
 8002e72:	f001 fe48 	bl	8004b06 <assert_print>
 8002e76:	494d      	ldr	r1, [pc, #308]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002e78:	484f      	ldr	r0, [pc, #316]	; (8002fb8 <z_impl_k_mutex_lock+0x190>)
 8002e7a:	f001 fe44 	bl	8004b06 <assert_print>
 8002e7e:	2194      	movs	r1, #148	; 0x94
 8002e80:	484b      	ldr	r0, [pc, #300]	; (8002fb0 <z_impl_k_mutex_lock+0x188>)
 8002e82:	e7e4      	b.n	8002e4e <z_impl_k_mutex_lock+0x26>
	z_spin_lock_set_owner(l);
 8002e84:	4849      	ldr	r0, [pc, #292]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002e86:	f7ff fde3 	bl	8002a50 <z_spin_lock_set_owner>

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_mutex, lock, mutex, timeout);

	key = k_spin_lock(&lock);

	if (likely((mutex->lock_count == 0U) || (mutex->owner == _current))) {
 8002e8a:	68e3      	ldr	r3, [r4, #12]
 8002e8c:	4a4b      	ldr	r2, [pc, #300]	; (8002fbc <z_impl_k_mutex_lock+0x194>)
 8002e8e:	b19b      	cbz	r3, 8002eb8 <z_impl_k_mutex_lock+0x90>
 8002e90:	68a0      	ldr	r0, [r4, #8]
 8002e92:	6891      	ldr	r1, [r2, #8]
 8002e94:	4288      	cmp	r0, r1
 8002e96:	d027      	beq.n	8002ee8 <z_impl_k_mutex_lock+0xc0>
		SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, lock, mutex, timeout, 0);

		return 0;
	}

	if (unlikely(K_TIMEOUT_EQ(timeout, K_NO_WAIT))) {
 8002e98:	ea57 0306 	orrs.w	r3, r7, r6
 8002e9c:	d12c      	bne.n	8002ef8 <z_impl_k_mutex_lock+0xd0>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002e9e:	4843      	ldr	r0, [pc, #268]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002ea0:	f7ff fdc6 	bl	8002a30 <z_spin_unlock_valid>
 8002ea4:	b1a0      	cbz	r0, 8002ed0 <z_impl_k_mutex_lock+0xa8>
	__asm__ volatile(
 8002ea6:	f388 8811 	msr	BASEPRI, r8
 8002eaa:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);

		SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, lock, mutex, timeout, -EBUSY);

		return -EBUSY;
 8002eae:	f06f 000f 	mvn.w	r0, #15
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, lock, mutex, timeout, -EAGAIN);

	return -EAGAIN;
}
 8002eb2:	b002      	add	sp, #8
 8002eb4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
					_current->base.prio :
 8002eb8:	6891      	ldr	r1, [r2, #8]
 8002eba:	f991 100e 	ldrsb.w	r1, [r1, #14]
 8002ebe:	483b      	ldr	r0, [pc, #236]	; (8002fac <z_impl_k_mutex_lock+0x184>)
		mutex->owner_orig_prio = (mutex->lock_count == 0U) ?
 8002ec0:	6121      	str	r1, [r4, #16]
		mutex->lock_count++;
 8002ec2:	3301      	adds	r3, #1
 8002ec4:	60e3      	str	r3, [r4, #12]
		mutex->owner = _current;
 8002ec6:	6893      	ldr	r3, [r2, #8]
 8002ec8:	60a3      	str	r3, [r4, #8]
 8002eca:	f7ff fdb1 	bl	8002a30 <z_spin_unlock_valid>
 8002ece:	b968      	cbnz	r0, 8002eec <z_impl_k_mutex_lock+0xc4>
 8002ed0:	4a37      	ldr	r2, [pc, #220]	; (8002fb0 <z_impl_k_mutex_lock+0x188>)
 8002ed2:	493b      	ldr	r1, [pc, #236]	; (8002fc0 <z_impl_k_mutex_lock+0x198>)
 8002ed4:	4833      	ldr	r0, [pc, #204]	; (8002fa4 <z_impl_k_mutex_lock+0x17c>)
 8002ed6:	23c2      	movs	r3, #194	; 0xc2
 8002ed8:	f001 fe15 	bl	8004b06 <assert_print>
 8002edc:	4933      	ldr	r1, [pc, #204]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002ede:	4839      	ldr	r0, [pc, #228]	; (8002fc4 <z_impl_k_mutex_lock+0x19c>)
 8002ee0:	f001 fe11 	bl	8004b06 <assert_print>
 8002ee4:	21c2      	movs	r1, #194	; 0xc2
 8002ee6:	e7cb      	b.n	8002e80 <z_impl_k_mutex_lock+0x58>
					_current->base.prio :
 8002ee8:	6921      	ldr	r1, [r4, #16]
 8002eea:	e7e8      	b.n	8002ebe <z_impl_k_mutex_lock+0x96>
 8002eec:	f388 8811 	msr	BASEPRI, r8
 8002ef0:	f3bf 8f6f 	isb	sy
		return 0;
 8002ef4:	2000      	movs	r0, #0
 8002ef6:	e7dc      	b.n	8002eb2 <z_impl_k_mutex_lock+0x8a>
	new_prio = new_prio_for_inheritance(_current->base.prio,
 8002ef8:	f991 100e 	ldrsb.w	r1, [r1, #14]
 8002efc:	f990 300e 	ldrsb.w	r3, [r0, #14]
	return prio >= CONFIG_PRIORITY_CEILING;
}

static inline int z_get_new_prio_with_ceiling(int prio)
{
	return z_is_under_prio_ceiling(prio) ? prio : CONFIG_PRIORITY_CEILING;
 8002f00:	4299      	cmp	r1, r3
 8002f02:	bfa8      	it	ge
 8002f04:	4619      	movge	r1, r3
 8002f06:	f06f 027e 	mvn.w	r2, #126	; 0x7e
 8002f0a:	4291      	cmp	r1, r2
 8002f0c:	bfb8      	it	lt
 8002f0e:	4611      	movlt	r1, r2
	if (z_is_prio_higher(new_prio, mutex->owner->base.prio)) {
 8002f10:	428b      	cmp	r3, r1
 8002f12:	dd02      	ble.n	8002f1a <z_impl_k_mutex_lock+0xf2>
		resched = adjust_owner_prio(mutex, new_prio);
 8002f14:	f002 f9c6 	bl	80052a4 <adjust_owner_prio.isra.0>
 8002f18:	4605      	mov	r5, r0
	int got_mutex = z_pend_curr(&lock, key, &mutex->wait_q, timeout);
 8002f1a:	e9cd 7600 	strd	r7, r6, [sp]
 8002f1e:	4823      	ldr	r0, [pc, #140]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002f20:	4622      	mov	r2, r4
 8002f22:	4641      	mov	r1, r8
 8002f24:	f000 fdb2 	bl	8003a8c <z_pend_curr>
	if (got_mutex == 0) {
 8002f28:	2800      	cmp	r0, #0
 8002f2a:	d0e3      	beq.n	8002ef4 <z_impl_k_mutex_lock+0xcc>
	__asm__ volatile(
 8002f2c:	f04f 0310 	mov.w	r3, #16
 8002f30:	f3ef 8611 	mrs	r6, BASEPRI
 8002f34:	f383 8812 	msr	BASEPRI_MAX, r3
 8002f38:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8002f3c:	481b      	ldr	r0, [pc, #108]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002f3e:	f7ff fd69 	bl	8002a14 <z_spin_lock_valid>
 8002f42:	2800      	cmp	r0, #0
 8002f44:	d091      	beq.n	8002e6a <z_impl_k_mutex_lock+0x42>
	z_spin_lock_set_owner(l);
 8002f46:	4819      	ldr	r0, [pc, #100]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002f48:	f7ff fd82 	bl	8002a50 <z_spin_lock_set_owner>
	if (likely(mutex->owner != NULL)) {
 8002f4c:	68a0      	ldr	r0, [r4, #8]
 8002f4e:	b1c0      	cbz	r0, 8002f82 <z_impl_k_mutex_lock+0x15a>
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
 8002f50:	6823      	ldr	r3, [r4, #0]
			new_prio_for_inheritance(waiter->base.prio, mutex->owner_orig_prio) :
 8002f52:	6921      	ldr	r1, [r4, #16]
 * @return a pointer to the head element, NULL if list is empty
 */

static inline sys_dnode_t *sys_dlist_peek_head(sys_dlist_t *list)
{
	return sys_dlist_is_empty(list) ? NULL : list->head;
 8002f54:	429c      	cmp	r4, r3
 8002f56:	d00a      	beq.n	8002f6e <z_impl_k_mutex_lock+0x146>
 8002f58:	b14b      	cbz	r3, 8002f6e <z_impl_k_mutex_lock+0x146>
 8002f5a:	f993 300e 	ldrsb.w	r3, [r3, #14]
 8002f5e:	4299      	cmp	r1, r3
 8002f60:	bfa8      	it	ge
 8002f62:	4619      	movge	r1, r3
 8002f64:	f06f 037e 	mvn.w	r3, #126	; 0x7e
 8002f68:	4299      	cmp	r1, r3
 8002f6a:	bfb8      	it	lt
 8002f6c:	4619      	movlt	r1, r3
		resched = adjust_owner_prio(mutex, new_prio) || resched;
 8002f6e:	f002 f999 	bl	80052a4 <adjust_owner_prio.isra.0>
 8002f72:	b130      	cbz	r0, 8002f82 <z_impl_k_mutex_lock+0x15a>
		z_reschedule(&lock, key);
 8002f74:	480d      	ldr	r0, [pc, #52]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002f76:	4631      	mov	r1, r6
 8002f78:	f000 f95a 	bl	8003230 <z_reschedule>
	return -EAGAIN;
 8002f7c:	f06f 000a 	mvn.w	r0, #10
 8002f80:	e797      	b.n	8002eb2 <z_impl_k_mutex_lock+0x8a>
	if (resched) {
 8002f82:	2d00      	cmp	r5, #0
 8002f84:	d1f6      	bne.n	8002f74 <z_impl_k_mutex_lock+0x14c>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8002f86:	4809      	ldr	r0, [pc, #36]	; (8002fac <z_impl_k_mutex_lock+0x184>)
 8002f88:	f7ff fd52 	bl	8002a30 <z_spin_unlock_valid>
 8002f8c:	2800      	cmp	r0, #0
 8002f8e:	d09f      	beq.n	8002ed0 <z_impl_k_mutex_lock+0xa8>
	__asm__ volatile(
 8002f90:	f386 8811 	msr	BASEPRI, r6
 8002f94:	f3bf 8f6f 	isb	sy
 8002f98:	e7f0      	b.n	8002f7c <z_impl_k_mutex_lock+0x154>
 8002f9a:	bf00      	nop
 8002f9c:	0800642f 	.word	0x0800642f
 8002fa0:	080064fb 	.word	0x080064fb
 8002fa4:	08005ca7 	.word	0x08005ca7
 8002fa8:	0800651d 	.word	0x0800651d
 8002fac:	200007ec 	.word	0x200007ec
 8002fb0:	080061b7 	.word	0x080061b7
 8002fb4:	080061e4 	.word	0x080061e4
 8002fb8:	080061f9 	.word	0x080061f9
 8002fbc:	200007b8 	.word	0x200007b8
 8002fc0:	08006211 	.word	0x08006211
 8002fc4:	08006228 	.word	0x08006228

08002fc8 <z_impl_k_mutex_unlock>:
}
#include <syscalls/k_mutex_lock_mrsh.c>
#endif

int z_impl_k_mutex_unlock(struct k_mutex *mutex)
{
 8002fc8:	b570      	push	{r4, r5, r6, lr}
 8002fca:	4604      	mov	r4, r0
 8002fcc:	f3ef 8605 	mrs	r6, IPSR
	struct k_thread *new_owner;

	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");
 8002fd0:	b166      	cbz	r6, 8002fec <z_impl_k_mutex_unlock+0x24>
 8002fd2:	4938      	ldr	r1, [pc, #224]	; (80030b4 <z_impl_k_mutex_unlock+0xec>)
 8002fd4:	4a38      	ldr	r2, [pc, #224]	; (80030b8 <z_impl_k_mutex_unlock+0xf0>)
 8002fd6:	4839      	ldr	r0, [pc, #228]	; (80030bc <z_impl_k_mutex_unlock+0xf4>)
 8002fd8:	23cd      	movs	r3, #205	; 0xcd
 8002fda:	f001 fd94 	bl	8004b06 <assert_print>
 8002fde:	4838      	ldr	r0, [pc, #224]	; (80030c0 <z_impl_k_mutex_unlock+0xf8>)
 8002fe0:	f001 fd91 	bl	8004b06 <assert_print>
 8002fe4:	21cd      	movs	r1, #205	; 0xcd
	 * Attempt to unlock a mutex which is unlocked. mutex->lock_count
	 * cannot be zero if the current thread is equal to mutex->owner,
	 * therefore no underflow check is required. Use assert to catch
	 * undefined behavior.
	 */
	__ASSERT_NO_MSG(mutex->lock_count > 0U);
 8002fe6:	4834      	ldr	r0, [pc, #208]	; (80030b8 <z_impl_k_mutex_unlock+0xf0>)
 8002fe8:	f001 fd86 	bl	8004af8 <assert_post_action>
	CHECKIF(mutex->owner == NULL) {
 8002fec:	6883      	ldr	r3, [r0, #8]
 8002fee:	2b00      	cmp	r3, #0
 8002ff0:	d05a      	beq.n	80030a8 <z_impl_k_mutex_unlock+0xe0>
	CHECKIF(mutex->owner != _current) {
 8002ff2:	4a34      	ldr	r2, [pc, #208]	; (80030c4 <z_impl_k_mutex_unlock+0xfc>)
 8002ff4:	6892      	ldr	r2, [r2, #8]
 8002ff6:	4293      	cmp	r3, r2
 8002ff8:	d159      	bne.n	80030ae <z_impl_k_mutex_unlock+0xe6>
	__ASSERT_NO_MSG(mutex->lock_count > 0U);
 8002ffa:	68c3      	ldr	r3, [r0, #12]
 8002ffc:	b93b      	cbnz	r3, 800300e <z_impl_k_mutex_unlock+0x46>
 8002ffe:	4932      	ldr	r1, [pc, #200]	; (80030c8 <z_impl_k_mutex_unlock+0x100>)
 8003000:	4a2d      	ldr	r2, [pc, #180]	; (80030b8 <z_impl_k_mutex_unlock+0xf0>)
 8003002:	482e      	ldr	r0, [pc, #184]	; (80030bc <z_impl_k_mutex_unlock+0xf4>)
 8003004:	23e5      	movs	r3, #229	; 0xe5
 8003006:	f001 fd7e 	bl	8004b06 <assert_print>
 800300a:	21e5      	movs	r1, #229	; 0xe5
 800300c:	e7eb      	b.n	8002fe6 <z_impl_k_mutex_unlock+0x1e>

	/*
	 * If we are the owner and count is greater than 1, then decrement
	 * the count and return and keep current thread as the owner.
	 */
	if (mutex->lock_count > 1U) {
 800300e:	2b01      	cmp	r3, #1
 8003010:	d003      	beq.n	800301a <z_impl_k_mutex_unlock+0x52>
		mutex->lock_count--;
 8003012:	3b01      	subs	r3, #1
 8003014:	60c3      	str	r3, [r0, #12]


k_mutex_unlock_return:
	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, unlock, mutex, 0);

	return 0;
 8003016:	2000      	movs	r0, #0
}
 8003018:	bd70      	pop	{r4, r5, r6, pc}
	__asm__ volatile(
 800301a:	f04f 0310 	mov.w	r3, #16
 800301e:	f3ef 8511 	mrs	r5, BASEPRI
 8003022:	f383 8812 	msr	BASEPRI_MAX, r3
 8003026:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 800302a:	4828      	ldr	r0, [pc, #160]	; (80030cc <z_impl_k_mutex_unlock+0x104>)
 800302c:	f7ff fcf2 	bl	8002a14 <z_spin_lock_valid>
 8003030:	b960      	cbnz	r0, 800304c <z_impl_k_mutex_unlock+0x84>
 8003032:	4a27      	ldr	r2, [pc, #156]	; (80030d0 <z_impl_k_mutex_unlock+0x108>)
 8003034:	4927      	ldr	r1, [pc, #156]	; (80030d4 <z_impl_k_mutex_unlock+0x10c>)
 8003036:	4821      	ldr	r0, [pc, #132]	; (80030bc <z_impl_k_mutex_unlock+0xf4>)
 8003038:	2394      	movs	r3, #148	; 0x94
 800303a:	f001 fd64 	bl	8004b06 <assert_print>
 800303e:	4923      	ldr	r1, [pc, #140]	; (80030cc <z_impl_k_mutex_unlock+0x104>)
 8003040:	4825      	ldr	r0, [pc, #148]	; (80030d8 <z_impl_k_mutex_unlock+0x110>)
 8003042:	f001 fd60 	bl	8004b06 <assert_print>
 8003046:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003048:	4821      	ldr	r0, [pc, #132]	; (80030d0 <z_impl_k_mutex_unlock+0x108>)
 800304a:	e7cd      	b.n	8002fe8 <z_impl_k_mutex_unlock+0x20>
	z_spin_lock_set_owner(l);
 800304c:	481f      	ldr	r0, [pc, #124]	; (80030cc <z_impl_k_mutex_unlock+0x104>)
 800304e:	f7ff fcff 	bl	8002a50 <z_spin_lock_set_owner>
	adjust_owner_prio(mutex, mutex->owner_orig_prio);
 8003052:	6921      	ldr	r1, [r4, #16]
 8003054:	68a0      	ldr	r0, [r4, #8]
 8003056:	f002 f925 	bl	80052a4 <adjust_owner_prio.isra.0>
	new_owner = z_unpend_first_thread(&mutex->wait_q);
 800305a:	4620      	mov	r0, r4
 800305c:	f000 fa4a 	bl	80034f4 <z_unpend_first_thread>
	mutex->owner = new_owner;
 8003060:	60a0      	str	r0, [r4, #8]
	if (new_owner != NULL) {
 8003062:	b158      	cbz	r0, 800307c <z_impl_k_mutex_unlock+0xb4>
		mutex->owner_orig_prio = new_owner->base.prio;
 8003064:	f990 200e 	ldrsb.w	r2, [r0, #14]
 8003068:	6122      	str	r2, [r4, #16]
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
 800306a:	f8c0 60ac 	str.w	r6, [r0, #172]	; 0xac
		z_ready_thread(new_owner);
 800306e:	f000 faf1 	bl	8003654 <z_ready_thread>
		z_reschedule(&lock, key);
 8003072:	4816      	ldr	r0, [pc, #88]	; (80030cc <z_impl_k_mutex_unlock+0x104>)
 8003074:	4629      	mov	r1, r5
 8003076:	f000 f8db 	bl	8003230 <z_reschedule>
 800307a:	e7cc      	b.n	8003016 <z_impl_k_mutex_unlock+0x4e>
		mutex->lock_count = 0U;
 800307c:	60e0      	str	r0, [r4, #12]
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 800307e:	4813      	ldr	r0, [pc, #76]	; (80030cc <z_impl_k_mutex_unlock+0x104>)
 8003080:	f7ff fcd6 	bl	8002a30 <z_spin_unlock_valid>
 8003084:	b958      	cbnz	r0, 800309e <z_impl_k_mutex_unlock+0xd6>
 8003086:	4a12      	ldr	r2, [pc, #72]	; (80030d0 <z_impl_k_mutex_unlock+0x108>)
 8003088:	4914      	ldr	r1, [pc, #80]	; (80030dc <z_impl_k_mutex_unlock+0x114>)
 800308a:	480c      	ldr	r0, [pc, #48]	; (80030bc <z_impl_k_mutex_unlock+0xf4>)
 800308c:	23c2      	movs	r3, #194	; 0xc2
 800308e:	f001 fd3a 	bl	8004b06 <assert_print>
 8003092:	490e      	ldr	r1, [pc, #56]	; (80030cc <z_impl_k_mutex_unlock+0x104>)
 8003094:	4812      	ldr	r0, [pc, #72]	; (80030e0 <z_impl_k_mutex_unlock+0x118>)
 8003096:	f001 fd36 	bl	8004b06 <assert_print>
 800309a:	21c2      	movs	r1, #194	; 0xc2
 800309c:	e7d4      	b.n	8003048 <z_impl_k_mutex_unlock+0x80>
	__asm__ volatile(
 800309e:	f385 8811 	msr	BASEPRI, r5
 80030a2:	f3bf 8f6f 	isb	sy
 80030a6:	e7b6      	b.n	8003016 <z_impl_k_mutex_unlock+0x4e>
		return -EINVAL;
 80030a8:	f06f 0015 	mvn.w	r0, #21
 80030ac:	e7b4      	b.n	8003018 <z_impl_k_mutex_unlock+0x50>
		return -EPERM;
 80030ae:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
 80030b2:	e7b1      	b.n	8003018 <z_impl_k_mutex_unlock+0x50>
 80030b4:	0800642f 	.word	0x0800642f
 80030b8:	080064fb 	.word	0x080064fb
 80030bc:	08005ca7 	.word	0x08005ca7
 80030c0:	0800651d 	.word	0x0800651d
 80030c4:	200007b8 	.word	0x200007b8
 80030c8:	08006542 	.word	0x08006542
 80030cc:	200007ec 	.word	0x200007ec
 80030d0:	080061b7 	.word	0x080061b7
 80030d4:	080061e4 	.word	0x080061e4
 80030d8:	080061f9 	.word	0x080061f9
 80030dc:	08006211 	.word	0x08006211
 80030e0:	08006228 	.word	0x08006228

080030e4 <z_reset_time_slice>:
 */
static struct k_thread *pending_current;
#endif

void z_reset_time_slice(struct k_thread *curr)
{
 80030e4:	b538      	push	{r3, r4, r5, lr}
	int ret = slice_ticks;
 80030e6:	4d07      	ldr	r5, [pc, #28]	; (8003104 <z_reset_time_slice+0x20>)
 80030e8:	682c      	ldr	r4, [r5, #0]
	/* Add the elapsed time since the last announced tick to the
	 * slice count, as we'll see those "expired" ticks arrive in a
	 * FUTURE z_time_slice() call.
	 */
	if (slice_time(curr) != 0) {
 80030ea:	b154      	cbz	r4, 8003102 <z_reset_time_slice+0x1e>
		_current_cpu->slice_ticks = slice_time(curr) + sys_clock_elapsed();
 80030ec:	f7ff fa04 	bl	80024f8 <sys_clock_elapsed>
 80030f0:	4b05      	ldr	r3, [pc, #20]	; (8003108 <z_reset_time_slice+0x24>)
 80030f2:	4404      	add	r4, r0
 80030f4:	611c      	str	r4, [r3, #16]
		z_set_timeout_expiry(slice_time(curr), false);
 80030f6:	6828      	ldr	r0, [r5, #0]
 80030f8:	2100      	movs	r1, #0
	}
}
 80030fa:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_set_timeout_expiry(slice_time(curr), false);
 80030fe:	f001 b9af 	b.w	8004460 <z_set_timeout_expiry>
}
 8003102:	bd38      	pop	{r3, r4, r5, pc}
 8003104:	200007f8 	.word	0x200007f8
 8003108:	200007b8 	.word	0x200007b8

0800310c <update_cache>:
	}
#endif
}

static void update_cache(int preempt_ok)
{
 800310c:	b570      	push	{r4, r5, r6, lr}
/**
 * @brief Returns the lowest-sorted member of the tree
 */
static inline struct rbnode *rb_get_min(struct rbtree *tree)
{
	return z_rb_get_minmax(tree, 0U);
 800310e:	2100      	movs	r1, #0
 8003110:	4606      	mov	r6, r0
 8003112:	4813      	ldr	r0, [pc, #76]	; (8003160 <update_cache+0x54>)
 8003114:	4d13      	ldr	r5, [pc, #76]	; (8003164 <update_cache+0x58>)
 8003116:	f001 fbb6 	bl	8004886 <z_rb_get_minmax>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
 800311a:	4604      	mov	r4, r0
 800311c:	b900      	cbnz	r0, 8003120 <update_cache+0x14>
 800311e:	68ec      	ldr	r4, [r5, #12]
	__ASSERT(_current != NULL, "");
 8003120:	68ab      	ldr	r3, [r5, #8]
	if (preempt_ok != 0) {
 8003122:	b9ae      	cbnz	r6, 8003150 <update_cache+0x44>
	__ASSERT(_current != NULL, "");
 8003124:	b963      	cbnz	r3, 8003140 <update_cache+0x34>
 8003126:	4910      	ldr	r1, [pc, #64]	; (8003168 <update_cache+0x5c>)
 8003128:	4a10      	ldr	r2, [pc, #64]	; (800316c <update_cache+0x60>)
 800312a:	4811      	ldr	r0, [pc, #68]	; (8003170 <update_cache+0x64>)
 800312c:	2389      	movs	r3, #137	; 0x89
 800312e:	f001 fcea 	bl	8004b06 <assert_print>
 8003132:	4810      	ldr	r0, [pc, #64]	; (8003174 <update_cache+0x68>)
 8003134:	f001 fce7 	bl	8004b06 <assert_print>
 8003138:	480c      	ldr	r0, [pc, #48]	; (800316c <update_cache+0x60>)
 800313a:	2189      	movs	r1, #137	; 0x89
 800313c:	f001 fcdc 	bl	8004af8 <assert_post_action>
	if (z_is_thread_prevented_from_running(_current)) {
 8003140:	7b5a      	ldrb	r2, [r3, #13]
 8003142:	06d2      	lsls	r2, r2, #27
 8003144:	d104      	bne.n	8003150 <update_cache+0x44>
	if (IS_ENABLED(CONFIG_SWAP_NONATOMIC)
 8003146:	69a2      	ldr	r2, [r4, #24]
 8003148:	b912      	cbnz	r2, 8003150 <update_cache+0x44>
	if (is_preempt(_current) || is_metairq(thread)) {
 800314a:	89da      	ldrh	r2, [r3, #14]
 800314c:	2a7f      	cmp	r2, #127	; 0x7f
 800314e:	d805      	bhi.n	800315c <update_cache+0x50>
#ifndef CONFIG_SMP
	struct k_thread *thread = next_up();

	if (should_preempt(thread, preempt_ok)) {
#ifdef CONFIG_TIMESLICING
		if (thread != _current) {
 8003150:	429c      	cmp	r4, r3
 8003152:	d002      	beq.n	800315a <update_cache+0x4e>
			z_reset_time_slice(thread);
 8003154:	4620      	mov	r0, r4
 8003156:	f7ff ffc5 	bl	80030e4 <z_reset_time_slice>
		}
#endif
		update_metairq_preempt(thread);
		_kernel.ready_q.cache = thread;
 800315a:	4623      	mov	r3, r4
 800315c:	61ab      	str	r3, [r5, #24]
	 * thread because if the thread gets preempted for whatever
	 * reason the scheduler will make the same decision anyway.
	 */
	_current_cpu->swap_ok = preempt_ok;
#endif
}
 800315e:	bd70      	pop	{r4, r5, r6, pc}
 8003160:	200007d4 	.word	0x200007d4
 8003164:	200007b8 	.word	0x200007b8
 8003168:	0800657b 	.word	0x0800657b
 800316c:	08006559 	.word	0x08006559
 8003170:	08005ca7 	.word	0x08005ca7
 8003174:	080065a2 	.word	0x080065a2

08003178 <k_sched_time_slice_set>:
{
 8003178:	b570      	push	{r4, r5, r6, lr}
 800317a:	4604      	mov	r4, r0
 800317c:	460d      	mov	r5, r1
	__asm__ volatile(
 800317e:	f04f 0310 	mov.w	r3, #16
 8003182:	f3ef 8611 	mrs	r6, BASEPRI
 8003186:	f383 8812 	msr	BASEPRI_MAX, r3
 800318a:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 800318e:	481e      	ldr	r0, [pc, #120]	; (8003208 <k_sched_time_slice_set+0x90>)
 8003190:	f7ff fc40 	bl	8002a14 <z_spin_lock_valid>
 8003194:	b968      	cbnz	r0, 80031b2 <k_sched_time_slice_set+0x3a>
 8003196:	4a1d      	ldr	r2, [pc, #116]	; (800320c <k_sched_time_slice_set+0x94>)
 8003198:	491d      	ldr	r1, [pc, #116]	; (8003210 <k_sched_time_slice_set+0x98>)
 800319a:	481e      	ldr	r0, [pc, #120]	; (8003214 <k_sched_time_slice_set+0x9c>)
 800319c:	2394      	movs	r3, #148	; 0x94
 800319e:	f001 fcb2 	bl	8004b06 <assert_print>
 80031a2:	4919      	ldr	r1, [pc, #100]	; (8003208 <k_sched_time_slice_set+0x90>)
 80031a4:	481c      	ldr	r0, [pc, #112]	; (8003218 <k_sched_time_slice_set+0xa0>)
 80031a6:	f001 fcae 	bl	8004b06 <assert_print>
 80031aa:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80031ac:	4817      	ldr	r0, [pc, #92]	; (800320c <k_sched_time_slice_set+0x94>)
 80031ae:	f001 fca3 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 80031b2:	4815      	ldr	r0, [pc, #84]	; (8003208 <k_sched_time_slice_set+0x90>)
 80031b4:	f7ff fc4c 	bl	8002a50 <z_spin_lock_set_owner>
			return ((uint32_t)t) * (to_hz / from_hz);
 80031b8:	230a      	movs	r3, #10
		if (IS_ENABLED(CONFIG_TICKLESS_KERNEL) && slice > 0) {
 80031ba:	2c00      	cmp	r4, #0
 80031bc:	fb04 f303 	mul.w	r3, r4, r3
 80031c0:	dd02      	ble.n	80031c8 <k_sched_time_slice_set+0x50>
			slice_ticks = MAX(2, slice_ticks);
 80031c2:	2b02      	cmp	r3, #2
 80031c4:	bfb8      	it	lt
 80031c6:	2302      	movlt	r3, #2
		_current_cpu->slice_ticks = 0;
 80031c8:	4a14      	ldr	r2, [pc, #80]	; (800321c <k_sched_time_slice_set+0xa4>)
 80031ca:	2100      	movs	r1, #0
 80031cc:	6111      	str	r1, [r2, #16]
		slice_ticks = k_ms_to_ticks_ceil32(slice);
 80031ce:	4914      	ldr	r1, [pc, #80]	; (8003220 <k_sched_time_slice_set+0xa8>)
		z_reset_time_slice(_current);
 80031d0:	6890      	ldr	r0, [r2, #8]
		slice_ticks = k_ms_to_ticks_ceil32(slice);
 80031d2:	600b      	str	r3, [r1, #0]
		slice_max_prio = prio;
 80031d4:	4b13      	ldr	r3, [pc, #76]	; (8003224 <k_sched_time_slice_set+0xac>)
 80031d6:	601d      	str	r5, [r3, #0]
		z_reset_time_slice(_current);
 80031d8:	f7ff ff84 	bl	80030e4 <z_reset_time_slice>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80031dc:	480a      	ldr	r0, [pc, #40]	; (8003208 <k_sched_time_slice_set+0x90>)
 80031de:	f7ff fc27 	bl	8002a30 <z_spin_unlock_valid>
 80031e2:	b958      	cbnz	r0, 80031fc <k_sched_time_slice_set+0x84>
 80031e4:	4a09      	ldr	r2, [pc, #36]	; (800320c <k_sched_time_slice_set+0x94>)
 80031e6:	4910      	ldr	r1, [pc, #64]	; (8003228 <k_sched_time_slice_set+0xb0>)
 80031e8:	480a      	ldr	r0, [pc, #40]	; (8003214 <k_sched_time_slice_set+0x9c>)
 80031ea:	23c2      	movs	r3, #194	; 0xc2
 80031ec:	f001 fc8b 	bl	8004b06 <assert_print>
 80031f0:	4905      	ldr	r1, [pc, #20]	; (8003208 <k_sched_time_slice_set+0x90>)
 80031f2:	480e      	ldr	r0, [pc, #56]	; (800322c <k_sched_time_slice_set+0xb4>)
 80031f4:	f001 fc87 	bl	8004b06 <assert_print>
 80031f8:	21c2      	movs	r1, #194	; 0xc2
 80031fa:	e7d7      	b.n	80031ac <k_sched_time_slice_set+0x34>
	__asm__ volatile(
 80031fc:	f386 8811 	msr	BASEPRI, r6
 8003200:	f3bf 8f6f 	isb	sy
}
 8003204:	bd70      	pop	{r4, r5, r6, pc}
 8003206:	bf00      	nop
 8003208:	200007fc 	.word	0x200007fc
 800320c:	080061b7 	.word	0x080061b7
 8003210:	080061e4 	.word	0x080061e4
 8003214:	08005ca7 	.word	0x08005ca7
 8003218:	080061f9 	.word	0x080061f9
 800321c:	200007b8 	.word	0x200007b8
 8003220:	200007f8 	.word	0x200007f8
 8003224:	200007f4 	.word	0x200007f4
 8003228:	08006211 	.word	0x08006211
 800322c:	08006228 	.word	0x08006228

08003230 <z_reschedule>:
	return new_thread != _current;
#endif
}

void z_reschedule(struct k_spinlock *lock, k_spinlock_key_t key)
{
 8003230:	b570      	push	{r4, r5, r6, lr}
 8003232:	4604      	mov	r4, r0
	return arch_irq_unlocked(key) && !arch_is_in_isr();
 8003234:	460d      	mov	r5, r1
 8003236:	b9e9      	cbnz	r1, 8003274 <z_reschedule+0x44>
 8003238:	f3ef 8605 	mrs	r6, IPSR
 800323c:	b9d6      	cbnz	r6, 8003274 <z_reschedule+0x44>
	new_thread = _kernel.ready_q.cache;
 800323e:	4b18      	ldr	r3, [pc, #96]	; (80032a0 <z_reschedule+0x70>)
	if (resched(key.key) && need_swap()) {
 8003240:	699a      	ldr	r2, [r3, #24]
 8003242:	689b      	ldr	r3, [r3, #8]
 8003244:	429a      	cmp	r2, r3
 8003246:	d015      	beq.n	8003274 <z_reschedule+0x44>
 */
static ALWAYS_INLINE void k_spin_release(struct k_spinlock *l)
{
	ARG_UNUSED(l);
#ifdef CONFIG_SPIN_VALIDATE
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003248:	f7ff fbf2 	bl	8002a30 <z_spin_unlock_valid>
 800324c:	b968      	cbnz	r0, 800326a <z_reschedule+0x3a>
 800324e:	4a15      	ldr	r2, [pc, #84]	; (80032a4 <z_reschedule+0x74>)
 8003250:	4915      	ldr	r1, [pc, #84]	; (80032a8 <z_reschedule+0x78>)
 8003252:	4816      	ldr	r0, [pc, #88]	; (80032ac <z_reschedule+0x7c>)
 8003254:	23e1      	movs	r3, #225	; 0xe1
 8003256:	f001 fc56 	bl	8004b06 <assert_print>
 800325a:	4621      	mov	r1, r4
 800325c:	4814      	ldr	r0, [pc, #80]	; (80032b0 <z_reschedule+0x80>)
 800325e:	f001 fc52 	bl	8004b06 <assert_print>
 8003262:	21e1      	movs	r1, #225	; 0xe1
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003264:	480f      	ldr	r0, [pc, #60]	; (80032a4 <z_reschedule+0x74>)
 8003266:	f001 fc47 	bl	8004af8 <assert_post_action>
	ret = arch_swap(key);
 800326a:	4630      	mov	r0, r6
		z_swap(lock, key);
	} else {
		k_spin_unlock(lock, key);
		signal_pending_ipi();
	}
}
 800326c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
 8003270:	f7fe b848 	b.w	8001304 <arch_swap>
 8003274:	4620      	mov	r0, r4
 8003276:	f7ff fbdb 	bl	8002a30 <z_spin_unlock_valid>
 800327a:	b958      	cbnz	r0, 8003294 <z_reschedule+0x64>
 800327c:	4a09      	ldr	r2, [pc, #36]	; (80032a4 <z_reschedule+0x74>)
 800327e:	490a      	ldr	r1, [pc, #40]	; (80032a8 <z_reschedule+0x78>)
 8003280:	480a      	ldr	r0, [pc, #40]	; (80032ac <z_reschedule+0x7c>)
 8003282:	23c2      	movs	r3, #194	; 0xc2
 8003284:	f001 fc3f 	bl	8004b06 <assert_print>
 8003288:	4621      	mov	r1, r4
 800328a:	4809      	ldr	r0, [pc, #36]	; (80032b0 <z_reschedule+0x80>)
 800328c:	f001 fc3b 	bl	8004b06 <assert_print>
 8003290:	21c2      	movs	r1, #194	; 0xc2
 8003292:	e7e7      	b.n	8003264 <z_reschedule+0x34>
 8003294:	f385 8811 	msr	BASEPRI, r5
 8003298:	f3bf 8f6f 	isb	sy
 800329c:	bd70      	pop	{r4, r5, r6, pc}
 800329e:	bf00      	nop
 80032a0:	200007b8 	.word	0x200007b8
 80032a4:	080061b7 	.word	0x080061b7
 80032a8:	08006211 	.word	0x08006211
 80032ac:	08005ca7 	.word	0x08005ca7
 80032b0:	08006228 	.word	0x08006228

080032b4 <k_sched_lock>:
		signal_pending_ipi();
	}
}

void k_sched_lock(void)
{
 80032b4:	b510      	push	{r4, lr}
	__asm__ volatile(
 80032b6:	f04f 0310 	mov.w	r3, #16
 80032ba:	f3ef 8411 	mrs	r4, BASEPRI
 80032be:	f383 8812 	msr	BASEPRI_MAX, r3
 80032c2:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 80032c6:	4825      	ldr	r0, [pc, #148]	; (800335c <k_sched_lock+0xa8>)
 80032c8:	f7ff fba4 	bl	8002a14 <z_spin_lock_valid>
 80032cc:	b960      	cbnz	r0, 80032e8 <k_sched_lock+0x34>
 80032ce:	4a24      	ldr	r2, [pc, #144]	; (8003360 <k_sched_lock+0xac>)
 80032d0:	4924      	ldr	r1, [pc, #144]	; (8003364 <k_sched_lock+0xb0>)
 80032d2:	4825      	ldr	r0, [pc, #148]	; (8003368 <k_sched_lock+0xb4>)
 80032d4:	2394      	movs	r3, #148	; 0x94
 80032d6:	f001 fc16 	bl	8004b06 <assert_print>
 80032da:	4920      	ldr	r1, [pc, #128]	; (800335c <k_sched_lock+0xa8>)
 80032dc:	4823      	ldr	r0, [pc, #140]	; (800336c <k_sched_lock+0xb8>)
 80032de:	f001 fc12 	bl	8004b06 <assert_print>
 80032e2:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80032e4:	481e      	ldr	r0, [pc, #120]	; (8003360 <k_sched_lock+0xac>)
 80032e6:	e010      	b.n	800330a <k_sched_lock+0x56>
	z_spin_lock_set_owner(l);
 80032e8:	481c      	ldr	r0, [pc, #112]	; (800335c <k_sched_lock+0xa8>)
 80032ea:	f7ff fbb1 	bl	8002a50 <z_spin_lock_set_owner>
 80032ee:	f3ef 8305 	mrs	r3, IPSR
	}
}

static inline void z_sched_lock(void)
{
	__ASSERT(!arch_is_in_isr(), "");
 80032f2:	b163      	cbz	r3, 800330e <k_sched_lock+0x5a>
 80032f4:	491e      	ldr	r1, [pc, #120]	; (8003370 <k_sched_lock+0xbc>)
 80032f6:	4a1f      	ldr	r2, [pc, #124]	; (8003374 <k_sched_lock+0xc0>)
 80032f8:	481b      	ldr	r0, [pc, #108]	; (8003368 <k_sched_lock+0xb4>)
 80032fa:	23fd      	movs	r3, #253	; 0xfd
 80032fc:	f001 fc03 	bl	8004b06 <assert_print>
 8003300:	481d      	ldr	r0, [pc, #116]	; (8003378 <k_sched_lock+0xc4>)
 8003302:	f001 fc00 	bl	8004b06 <assert_print>
 8003306:	21fd      	movs	r1, #253	; 0xfd
 8003308:	481a      	ldr	r0, [pc, #104]	; (8003374 <k_sched_lock+0xc0>)
 800330a:	f001 fbf5 	bl	8004af8 <assert_post_action>
	__ASSERT(_current->base.sched_locked != 1U, "");
 800330e:	4b1b      	ldr	r3, [pc, #108]	; (800337c <k_sched_lock+0xc8>)
 8003310:	689a      	ldr	r2, [r3, #8]
 8003312:	7bd3      	ldrb	r3, [r2, #15]
 8003314:	2b01      	cmp	r3, #1
 8003316:	d10a      	bne.n	800332e <k_sched_lock+0x7a>
 8003318:	4919      	ldr	r1, [pc, #100]	; (8003380 <k_sched_lock+0xcc>)
 800331a:	4a16      	ldr	r2, [pc, #88]	; (8003374 <k_sched_lock+0xc0>)
 800331c:	4812      	ldr	r0, [pc, #72]	; (8003368 <k_sched_lock+0xb4>)
 800331e:	23fe      	movs	r3, #254	; 0xfe
 8003320:	f001 fbf1 	bl	8004b06 <assert_print>
 8003324:	4814      	ldr	r0, [pc, #80]	; (8003378 <k_sched_lock+0xc4>)
 8003326:	f001 fbee 	bl	8004b06 <assert_print>
 800332a:	21fe      	movs	r1, #254	; 0xfe
 800332c:	e7ec      	b.n	8003308 <k_sched_lock+0x54>

	--_current->base.sched_locked;
 800332e:	3b01      	subs	r3, #1
 8003330:	73d3      	strb	r3, [r2, #15]
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003332:	480a      	ldr	r0, [pc, #40]	; (800335c <k_sched_lock+0xa8>)
 8003334:	f7ff fb7c 	bl	8002a30 <z_spin_unlock_valid>
 8003338:	b958      	cbnz	r0, 8003352 <k_sched_lock+0x9e>
 800333a:	4a09      	ldr	r2, [pc, #36]	; (8003360 <k_sched_lock+0xac>)
 800333c:	4911      	ldr	r1, [pc, #68]	; (8003384 <k_sched_lock+0xd0>)
 800333e:	480a      	ldr	r0, [pc, #40]	; (8003368 <k_sched_lock+0xb4>)
 8003340:	23c2      	movs	r3, #194	; 0xc2
 8003342:	f001 fbe0 	bl	8004b06 <assert_print>
 8003346:	4905      	ldr	r1, [pc, #20]	; (800335c <k_sched_lock+0xa8>)
 8003348:	480f      	ldr	r0, [pc, #60]	; (8003388 <k_sched_lock+0xd4>)
 800334a:	f001 fbdc 	bl	8004b06 <assert_print>
 800334e:	21c2      	movs	r1, #194	; 0xc2
 8003350:	e7c8      	b.n	80032e4 <k_sched_lock+0x30>
	__asm__ volatile(
 8003352:	f384 8811 	msr	BASEPRI, r4
 8003356:	f3bf 8f6f 	isb	sy
	LOCKED(&sched_spinlock) {
		SYS_PORT_TRACING_FUNC(k_thread, sched_lock);

		z_sched_lock();
	}
}
 800335a:	bd10      	pop	{r4, pc}
 800335c:	200007fc 	.word	0x200007fc
 8003360:	080061b7 	.word	0x080061b7
 8003364:	080061e4 	.word	0x080061e4
 8003368:	08005ca7 	.word	0x08005ca7
 800336c:	080061f9 	.word	0x080061f9
 8003370:	0800642f 	.word	0x0800642f
 8003374:	080065a5 	.word	0x080065a5
 8003378:	080065a2 	.word	0x080065a2
 800337c:	200007b8 	.word	0x200007b8
 8003380:	080065d0 	.word	0x080065d0
 8003384:	08006211 	.word	0x08006211
 8003388:	08006228 	.word	0x08006228

0800338c <k_sched_unlock>:

void k_sched_unlock(void)
{
 800338c:	b510      	push	{r4, lr}
	__asm__ volatile(
 800338e:	f04f 0310 	mov.w	r3, #16
 8003392:	f3ef 8411 	mrs	r4, BASEPRI
 8003396:	f383 8812 	msr	BASEPRI_MAX, r3
 800339a:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 800339e:	4829      	ldr	r0, [pc, #164]	; (8003444 <k_sched_unlock+0xb8>)
 80033a0:	f7ff fb38 	bl	8002a14 <z_spin_lock_valid>
 80033a4:	b960      	cbnz	r0, 80033c0 <k_sched_unlock+0x34>
 80033a6:	4a28      	ldr	r2, [pc, #160]	; (8003448 <k_sched_unlock+0xbc>)
 80033a8:	4928      	ldr	r1, [pc, #160]	; (800344c <k_sched_unlock+0xc0>)
 80033aa:	4829      	ldr	r0, [pc, #164]	; (8003450 <k_sched_unlock+0xc4>)
 80033ac:	2394      	movs	r3, #148	; 0x94
 80033ae:	f001 fbaa 	bl	8004b06 <assert_print>
 80033b2:	4924      	ldr	r1, [pc, #144]	; (8003444 <k_sched_unlock+0xb8>)
 80033b4:	4827      	ldr	r0, [pc, #156]	; (8003454 <k_sched_unlock+0xc8>)
 80033b6:	f001 fba6 	bl	8004b06 <assert_print>
 80033ba:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80033bc:	4822      	ldr	r0, [pc, #136]	; (8003448 <k_sched_unlock+0xbc>)
 80033be:	e013      	b.n	80033e8 <k_sched_unlock+0x5c>
	z_spin_lock_set_owner(l);
 80033c0:	4820      	ldr	r0, [pc, #128]	; (8003444 <k_sched_unlock+0xb8>)
 80033c2:	f7ff fb45 	bl	8002a50 <z_spin_lock_set_owner>
	LOCKED(&sched_spinlock) {
		__ASSERT(_current->base.sched_locked != 0U, "");
 80033c6:	4b24      	ldr	r3, [pc, #144]	; (8003458 <k_sched_unlock+0xcc>)
 80033c8:	689a      	ldr	r2, [r3, #8]
 80033ca:	7bd3      	ldrb	r3, [r2, #15]
 80033cc:	b973      	cbnz	r3, 80033ec <k_sched_unlock+0x60>
 80033ce:	4923      	ldr	r1, [pc, #140]	; (800345c <k_sched_unlock+0xd0>)
 80033d0:	4a23      	ldr	r2, [pc, #140]	; (8003460 <k_sched_unlock+0xd4>)
 80033d2:	481f      	ldr	r0, [pc, #124]	; (8003450 <k_sched_unlock+0xc4>)
 80033d4:	f240 33e7 	movw	r3, #999	; 0x3e7
 80033d8:	f001 fb95 	bl	8004b06 <assert_print>
 80033dc:	4821      	ldr	r0, [pc, #132]	; (8003464 <k_sched_unlock+0xd8>)
 80033de:	f001 fb92 	bl	8004b06 <assert_print>
 80033e2:	f240 31e7 	movw	r1, #999	; 0x3e7
 80033e6:	481e      	ldr	r0, [pc, #120]	; (8003460 <k_sched_unlock+0xd4>)
 80033e8:	f001 fb86 	bl	8004af8 <assert_post_action>
 80033ec:	f3ef 8005 	mrs	r0, IPSR
		__ASSERT(!arch_is_in_isr(), "");
 80033f0:	b160      	cbz	r0, 800340c <k_sched_unlock+0x80>
 80033f2:	491d      	ldr	r1, [pc, #116]	; (8003468 <k_sched_unlock+0xdc>)
 80033f4:	4a1a      	ldr	r2, [pc, #104]	; (8003460 <k_sched_unlock+0xd4>)
 80033f6:	4816      	ldr	r0, [pc, #88]	; (8003450 <k_sched_unlock+0xc4>)
 80033f8:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
 80033fc:	f001 fb83 	bl	8004b06 <assert_print>
 8003400:	4818      	ldr	r0, [pc, #96]	; (8003464 <k_sched_unlock+0xd8>)
 8003402:	f001 fb80 	bl	8004b06 <assert_print>
 8003406:	f44f 717a 	mov.w	r1, #1000	; 0x3e8
 800340a:	e7ec      	b.n	80033e6 <k_sched_unlock+0x5a>

		++_current->base.sched_locked;
 800340c:	3301      	adds	r3, #1
 800340e:	73d3      	strb	r3, [r2, #15]
		update_cache(0);
 8003410:	f7ff fe7c 	bl	800310c <update_cache>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003414:	480b      	ldr	r0, [pc, #44]	; (8003444 <k_sched_unlock+0xb8>)
 8003416:	f7ff fb0b 	bl	8002a30 <z_spin_unlock_valid>
 800341a:	b958      	cbnz	r0, 8003434 <k_sched_unlock+0xa8>
 800341c:	4a0a      	ldr	r2, [pc, #40]	; (8003448 <k_sched_unlock+0xbc>)
 800341e:	4913      	ldr	r1, [pc, #76]	; (800346c <k_sched_unlock+0xe0>)
 8003420:	480b      	ldr	r0, [pc, #44]	; (8003450 <k_sched_unlock+0xc4>)
 8003422:	23c2      	movs	r3, #194	; 0xc2
 8003424:	f001 fb6f 	bl	8004b06 <assert_print>
 8003428:	4906      	ldr	r1, [pc, #24]	; (8003444 <k_sched_unlock+0xb8>)
 800342a:	4811      	ldr	r0, [pc, #68]	; (8003470 <k_sched_unlock+0xe4>)
 800342c:	f001 fb6b 	bl	8004b06 <assert_print>
 8003430:	21c2      	movs	r1, #194	; 0xc2
 8003432:	e7c3      	b.n	80033bc <k_sched_unlock+0x30>
	__asm__ volatile(
 8003434:	f384 8811 	msr	BASEPRI, r4
 8003438:	f3bf 8f6f 	isb	sy
		_current, _current->base.sched_locked);

	SYS_PORT_TRACING_FUNC(k_thread, sched_unlock);

	z_reschedule_unlocked();
}
 800343c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule_unlocked();
 8003440:	f001 bf5d 	b.w	80052fe <z_reschedule_unlocked>
 8003444:	200007fc 	.word	0x200007fc
 8003448:	080061b7 	.word	0x080061b7
 800344c:	080061e4 	.word	0x080061e4
 8003450:	08005ca7 	.word	0x08005ca7
 8003454:	080061f9 	.word	0x080061f9
 8003458:	200007b8 	.word	0x200007b8
 800345c:	08006601 	.word	0x08006601
 8003460:	08006559 	.word	0x08006559
 8003464:	080065a2 	.word	0x080065a2
 8003468:	0800642f 	.word	0x0800642f
 800346c:	08006211 	.word	0x08006211
 8003470:	08006228 	.word	0x08006228

08003474 <z_priq_dumb_remove>:
#endif
}
#endif

void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
 8003474:	b508      	push	{r3, lr}
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 8003476:	4b0b      	ldr	r3, [pc, #44]	; (80034a4 <z_priq_dumb_remove+0x30>)
 8003478:	4299      	cmp	r1, r3
 800347a:	d10b      	bne.n	8003494 <z_priq_dumb_remove+0x20>
 800347c:	490a      	ldr	r1, [pc, #40]	; (80034a8 <z_priq_dumb_remove+0x34>)
 800347e:	480b      	ldr	r0, [pc, #44]	; (80034ac <z_priq_dumb_remove+0x38>)
 8003480:	4a0b      	ldr	r2, [pc, #44]	; (80034b0 <z_priq_dumb_remove+0x3c>)
 8003482:	f240 4373 	movw	r3, #1139	; 0x473
 8003486:	f001 fb3e 	bl	8004b06 <assert_print>
 800348a:	4809      	ldr	r0, [pc, #36]	; (80034b0 <z_priq_dumb_remove+0x3c>)
 800348c:	f240 4173 	movw	r1, #1139	; 0x473
 8003490:	f001 fb32 	bl	8004af8 <assert_post_action>
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	sys_dnode_t *const prev = node->prev;
	sys_dnode_t *const next = node->next;
 8003494:	e9d1 3200 	ldrd	r3, r2, [r1]

	prev->next = next;
 8003498:	6013      	str	r3, [r2, #0]
	next->prev = prev;
 800349a:	605a      	str	r2, [r3, #4]
	node->next = NULL;
 800349c:	2300      	movs	r3, #0
	node->prev = NULL;
 800349e:	e9c1 3300 	strd	r3, r3, [r1]

	sys_dlist_remove(&thread->base.qnode_dlist);
}
 80034a2:	bd08      	pop	{r3, pc}
 80034a4:	20000480 	.word	0x20000480
 80034a8:	08006632 	.word	0x08006632
 80034ac:	08005ca7 	.word	0x08005ca7
 80034b0:	08006559 	.word	0x08006559

080034b4 <unpend_thread_no_timeout>:
{
 80034b4:	b510      	push	{r4, lr}
 80034b6:	4604      	mov	r4, r0
 80034b8:	6880      	ldr	r0, [r0, #8]
	__ASSERT_NO_MSG(thread->base.pended_on);
 80034ba:	b958      	cbnz	r0, 80034d4 <unpend_thread_no_timeout+0x20>
 80034bc:	490a      	ldr	r1, [pc, #40]	; (80034e8 <unpend_thread_no_timeout+0x34>)
 80034be:	480b      	ldr	r0, [pc, #44]	; (80034ec <unpend_thread_no_timeout+0x38>)
 80034c0:	4a0b      	ldr	r2, [pc, #44]	; (80034f0 <unpend_thread_no_timeout+0x3c>)
 80034c2:	f240 23d6 	movw	r3, #726	; 0x2d6
 80034c6:	f001 fb1e 	bl	8004b06 <assert_print>
 80034ca:	4809      	ldr	r0, [pc, #36]	; (80034f0 <unpend_thread_no_timeout+0x3c>)
 80034cc:	f240 21d6 	movw	r1, #726	; 0x2d6
 80034d0:	f001 fb12 	bl	8004af8 <assert_post_action>
	_priq_wait_remove(&pended_on_thread(thread)->waitq, thread);
 80034d4:	4621      	mov	r1, r4
 80034d6:	f7ff ffcd 	bl	8003474 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
 80034da:	7b63      	ldrb	r3, [r4, #13]
 80034dc:	f023 0302 	bic.w	r3, r3, #2
 80034e0:	7363      	strb	r3, [r4, #13]
	thread->base.pended_on = NULL;
 80034e2:	2300      	movs	r3, #0
 80034e4:	60a3      	str	r3, [r4, #8]
}
 80034e6:	bd10      	pop	{r4, pc}
 80034e8:	08006653 	.word	0x08006653
 80034ec:	08005ca7 	.word	0x08005ca7
 80034f0:	08006559 	.word	0x08006559

080034f4 <z_unpend_first_thread>:
{
 80034f4:	b570      	push	{r4, r5, r6, lr}
 80034f6:	4605      	mov	r5, r0
	__asm__ volatile(
 80034f8:	f04f 0310 	mov.w	r3, #16
 80034fc:	f3ef 8611 	mrs	r6, BASEPRI
 8003500:	f383 8812 	msr	BASEPRI_MAX, r3
 8003504:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003508:	481b      	ldr	r0, [pc, #108]	; (8003578 <z_unpend_first_thread+0x84>)
 800350a:	f7ff fa83 	bl	8002a14 <z_spin_lock_valid>
 800350e:	b968      	cbnz	r0, 800352c <z_unpend_first_thread+0x38>
 8003510:	4a1a      	ldr	r2, [pc, #104]	; (800357c <z_unpend_first_thread+0x88>)
 8003512:	491b      	ldr	r1, [pc, #108]	; (8003580 <z_unpend_first_thread+0x8c>)
 8003514:	481b      	ldr	r0, [pc, #108]	; (8003584 <z_unpend_first_thread+0x90>)
 8003516:	2394      	movs	r3, #148	; 0x94
 8003518:	f001 faf5 	bl	8004b06 <assert_print>
 800351c:	4916      	ldr	r1, [pc, #88]	; (8003578 <z_unpend_first_thread+0x84>)
 800351e:	481a      	ldr	r0, [pc, #104]	; (8003588 <z_unpend_first_thread+0x94>)
 8003520:	f001 faf1 	bl	8004b06 <assert_print>
 8003524:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003526:	4815      	ldr	r0, [pc, #84]	; (800357c <z_unpend_first_thread+0x88>)
 8003528:	f001 fae6 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 800352c:	4812      	ldr	r0, [pc, #72]	; (8003578 <z_unpend_first_thread+0x84>)
 800352e:	f7ff fa8f 	bl	8002a50 <z_spin_lock_set_owner>
	return list->head == list;
 8003532:	682c      	ldr	r4, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
 8003534:	42a5      	cmp	r5, r4
 8003536:	d017      	beq.n	8003568 <z_unpend_first_thread+0x74>
		if (thread != NULL) {
 8003538:	b134      	cbz	r4, 8003548 <z_unpend_first_thread+0x54>
			unpend_thread_no_timeout(thread);
 800353a:	4620      	mov	r0, r4
 800353c:	f7ff ffba 	bl	80034b4 <unpend_thread_no_timeout>
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
 8003540:	f104 0018 	add.w	r0, r4, #24
 8003544:	f000 ff40 	bl	80043c8 <z_abort_timeout>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003548:	480b      	ldr	r0, [pc, #44]	; (8003578 <z_unpend_first_thread+0x84>)
 800354a:	f7ff fa71 	bl	8002a30 <z_spin_unlock_valid>
 800354e:	b968      	cbnz	r0, 800356c <z_unpend_first_thread+0x78>
 8003550:	4a0a      	ldr	r2, [pc, #40]	; (800357c <z_unpend_first_thread+0x88>)
 8003552:	490e      	ldr	r1, [pc, #56]	; (800358c <z_unpend_first_thread+0x98>)
 8003554:	480b      	ldr	r0, [pc, #44]	; (8003584 <z_unpend_first_thread+0x90>)
 8003556:	23c2      	movs	r3, #194	; 0xc2
 8003558:	f001 fad5 	bl	8004b06 <assert_print>
 800355c:	4906      	ldr	r1, [pc, #24]	; (8003578 <z_unpend_first_thread+0x84>)
 800355e:	480c      	ldr	r0, [pc, #48]	; (8003590 <z_unpend_first_thread+0x9c>)
 8003560:	f001 fad1 	bl	8004b06 <assert_print>
 8003564:	21c2      	movs	r1, #194	; 0xc2
 8003566:	e7de      	b.n	8003526 <z_unpend_first_thread+0x32>
 8003568:	2400      	movs	r4, #0
 800356a:	e7ed      	b.n	8003548 <z_unpend_first_thread+0x54>
	__asm__ volatile(
 800356c:	f386 8811 	msr	BASEPRI, r6
 8003570:	f3bf 8f6f 	isb	sy
}
 8003574:	4620      	mov	r0, r4
 8003576:	bd70      	pop	{r4, r5, r6, pc}
 8003578:	200007fc 	.word	0x200007fc
 800357c:	080061b7 	.word	0x080061b7
 8003580:	080061e4 	.word	0x080061e4
 8003584:	08005ca7 	.word	0x08005ca7
 8003588:	080061f9 	.word	0x080061f9
 800358c:	08006211 	.word	0x08006211
 8003590:	08006228 	.word	0x08006228

08003594 <z_priq_rb_add>:
			? 1 : 0;
	}
}

void z_priq_rb_add(struct _priq_rb *pq, struct k_thread *thread)
{
 8003594:	b5b0      	push	{r4, r5, r7, lr}
	struct k_thread *t;

	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 8003596:	4b1e      	ldr	r3, [pc, #120]	; (8003610 <z_priq_rb_add+0x7c>)
{
 8003598:	b084      	sub	sp, #16
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 800359a:	4299      	cmp	r1, r3
{
 800359c:	4604      	mov	r4, r0
 800359e:	af00      	add	r7, sp, #0
 80035a0:	460d      	mov	r5, r1
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 80035a2:	d10b      	bne.n	80035bc <z_priq_rb_add+0x28>
 80035a4:	491b      	ldr	r1, [pc, #108]	; (8003614 <z_priq_rb_add+0x80>)
 80035a6:	481c      	ldr	r0, [pc, #112]	; (8003618 <z_priq_rb_add+0x84>)
 80035a8:	4a1c      	ldr	r2, [pc, #112]	; (800361c <z_priq_rb_add+0x88>)
 80035aa:	f240 439b 	movw	r3, #1179	; 0x49b
 80035ae:	f001 faaa 	bl	8004b06 <assert_print>
 80035b2:	481a      	ldr	r0, [pc, #104]	; (800361c <z_priq_rb_add+0x88>)
 80035b4:	f240 419b 	movw	r1, #1179	; 0x49b
 80035b8:	f001 fa9e 	bl	8004af8 <assert_post_action>

	thread->base.order_key = pq->next_order_key++;
 80035bc:	68c3      	ldr	r3, [r0, #12]
 80035be:	1c5a      	adds	r2, r3, #1
 80035c0:	60c2      	str	r2, [r0, #12]
 80035c2:	610b      	str	r3, [r1, #16]
	 * will almost never be hit on real systems.  BUT on very
	 * long-running systems where a priq never completely empties
	 * AND that contains very large numbers of threads, it can be
	 * a latency glitch to loop over all the threads like this.
	 */
	if (!pq->next_order_key) {
 80035c4:	68c3      	ldr	r3, [r0, #12]
 80035c6:	b9bb      	cbnz	r3, 80035f8 <z_priq_rb_add+0x64>
		RB_FOR_EACH_CONTAINER(&pq->tree, t, base.qnode_rb) {
 80035c8:	6883      	ldr	r3, [r0, #8]
 80035ca:	009a      	lsls	r2, r3, #2
 80035cc:	3207      	adds	r2, #7
 80035ce:	f022 0207 	bic.w	r2, r2, #7
 80035d2:	3307      	adds	r3, #7
 80035d4:	ebad 0d02 	sub.w	sp, sp, r2
 80035d8:	f023 0307 	bic.w	r3, r3, #7
 80035dc:	f8c7 d004 	str.w	sp, [r7, #4]
 80035e0:	ebad 0d03 	sub.w	sp, sp, r3
 80035e4:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
 80035e8:	f8c7 d008 	str.w	sp, [r7, #8]
 80035ec:	60fb      	str	r3, [r7, #12]
 80035ee:	1d39      	adds	r1, r7, #4
 80035f0:	4620      	mov	r0, r4
 80035f2:	f001 f9ef 	bl	80049d4 <z_rb_foreach_next>
 80035f6:	b930      	cbnz	r0, 8003606 <z_priq_rb_add+0x72>
			t->base.order_key = pq->next_order_key++;
		}
	}

	rb_insert(&pq->tree, &thread->base.qnode_rb);
 80035f8:	4629      	mov	r1, r5
 80035fa:	4620      	mov	r0, r4
 80035fc:	f001 f950 	bl	80048a0 <rb_insert>
}
 8003600:	3710      	adds	r7, #16
 8003602:	46bd      	mov	sp, r7
 8003604:	bdb0      	pop	{r4, r5, r7, pc}
			t->base.order_key = pq->next_order_key++;
 8003606:	68e3      	ldr	r3, [r4, #12]
 8003608:	1c5a      	adds	r2, r3, #1
 800360a:	60e2      	str	r2, [r4, #12]
 800360c:	6103      	str	r3, [r0, #16]
 800360e:	e7ee      	b.n	80035ee <z_priq_rb_add+0x5a>
 8003610:	20000480 	.word	0x20000480
 8003614:	08006632 	.word	0x08006632
 8003618:	08005ca7 	.word	0x08005ca7
 800361c:	08006559 	.word	0x08006559

08003620 <ready_thread>:
{
 8003620:	b510      	push	{r4, lr}
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
 8003622:	f990 200d 	ldrsb.w	r2, [r0, #13]
	return (thread->base.thread_state & state) != 0U;
 8003626:	7b43      	ldrb	r3, [r0, #13]
 8003628:	2a00      	cmp	r2, #0
{
 800362a:	4601      	mov	r1, r0
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
 800362c:	db0e      	blt.n	800364c <ready_thread+0x2c>
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
 800362e:	06da      	lsls	r2, r3, #27
 8003630:	d10c      	bne.n	800364c <ready_thread+0x2c>
 8003632:	6984      	ldr	r4, [r0, #24]
 8003634:	b954      	cbnz	r4, 800364c <ready_thread+0x2c>
	thread->base.thread_state |= _THREAD_QUEUED;
 8003636:	f063 037f 	orn	r3, r3, #127	; 0x7f
 800363a:	7343      	strb	r3, [r0, #13]
	_priq_run_add(thread_runq(thread), thread);
 800363c:	4804      	ldr	r0, [pc, #16]	; (8003650 <ready_thread+0x30>)
 800363e:	f7ff ffa9 	bl	8003594 <z_priq_rb_add>
		update_cache(0);
 8003642:	4620      	mov	r0, r4
}
 8003644:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		update_cache(0);
 8003648:	f7ff bd60 	b.w	800310c <update_cache>
}
 800364c:	bd10      	pop	{r4, pc}
 800364e:	bf00      	nop
 8003650:	200007d4 	.word	0x200007d4

08003654 <z_ready_thread>:
{
 8003654:	b538      	push	{r3, r4, r5, lr}
 8003656:	4604      	mov	r4, r0
	__asm__ volatile(
 8003658:	f04f 0310 	mov.w	r3, #16
 800365c:	f3ef 8511 	mrs	r5, BASEPRI
 8003660:	f383 8812 	msr	BASEPRI_MAX, r3
 8003664:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003668:	4816      	ldr	r0, [pc, #88]	; (80036c4 <z_ready_thread+0x70>)
 800366a:	f7ff f9d3 	bl	8002a14 <z_spin_lock_valid>
 800366e:	b968      	cbnz	r0, 800368c <z_ready_thread+0x38>
 8003670:	4a15      	ldr	r2, [pc, #84]	; (80036c8 <z_ready_thread+0x74>)
 8003672:	4916      	ldr	r1, [pc, #88]	; (80036cc <z_ready_thread+0x78>)
 8003674:	4816      	ldr	r0, [pc, #88]	; (80036d0 <z_ready_thread+0x7c>)
 8003676:	2394      	movs	r3, #148	; 0x94
 8003678:	f001 fa45 	bl	8004b06 <assert_print>
 800367c:	4911      	ldr	r1, [pc, #68]	; (80036c4 <z_ready_thread+0x70>)
 800367e:	4815      	ldr	r0, [pc, #84]	; (80036d4 <z_ready_thread+0x80>)
 8003680:	f001 fa41 	bl	8004b06 <assert_print>
 8003684:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003686:	4810      	ldr	r0, [pc, #64]	; (80036c8 <z_ready_thread+0x74>)
 8003688:	f001 fa36 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 800368c:	480d      	ldr	r0, [pc, #52]	; (80036c4 <z_ready_thread+0x70>)
 800368e:	f7ff f9df 	bl	8002a50 <z_spin_lock_set_owner>
			ready_thread(thread);
 8003692:	4620      	mov	r0, r4
 8003694:	f7ff ffc4 	bl	8003620 <ready_thread>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003698:	480a      	ldr	r0, [pc, #40]	; (80036c4 <z_ready_thread+0x70>)
 800369a:	f7ff f9c9 	bl	8002a30 <z_spin_unlock_valid>
 800369e:	b958      	cbnz	r0, 80036b8 <z_ready_thread+0x64>
 80036a0:	4a09      	ldr	r2, [pc, #36]	; (80036c8 <z_ready_thread+0x74>)
 80036a2:	490d      	ldr	r1, [pc, #52]	; (80036d8 <z_ready_thread+0x84>)
 80036a4:	480a      	ldr	r0, [pc, #40]	; (80036d0 <z_ready_thread+0x7c>)
 80036a6:	23c2      	movs	r3, #194	; 0xc2
 80036a8:	f001 fa2d 	bl	8004b06 <assert_print>
 80036ac:	4905      	ldr	r1, [pc, #20]	; (80036c4 <z_ready_thread+0x70>)
 80036ae:	480b      	ldr	r0, [pc, #44]	; (80036dc <z_ready_thread+0x88>)
 80036b0:	f001 fa29 	bl	8004b06 <assert_print>
 80036b4:	21c2      	movs	r1, #194	; 0xc2
 80036b6:	e7e6      	b.n	8003686 <z_ready_thread+0x32>
	__asm__ volatile(
 80036b8:	f385 8811 	msr	BASEPRI, r5
 80036bc:	f3bf 8f6f 	isb	sy
}
 80036c0:	bd38      	pop	{r3, r4, r5, pc}
 80036c2:	bf00      	nop
 80036c4:	200007fc 	.word	0x200007fc
 80036c8:	080061b7 	.word	0x080061b7
 80036cc:	080061e4 	.word	0x080061e4
 80036d0:	08005ca7 	.word	0x08005ca7
 80036d4:	080061f9 	.word	0x080061f9
 80036d8:	08006211 	.word	0x08006211
 80036dc:	08006228 	.word	0x08006228

080036e0 <z_sched_start>:
{
 80036e0:	b538      	push	{r3, r4, r5, lr}
 80036e2:	4604      	mov	r4, r0
	__asm__ volatile(
 80036e4:	f04f 0310 	mov.w	r3, #16
 80036e8:	f3ef 8511 	mrs	r5, BASEPRI
 80036ec:	f383 8812 	msr	BASEPRI_MAX, r3
 80036f0:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 80036f4:	481c      	ldr	r0, [pc, #112]	; (8003768 <z_sched_start+0x88>)
 80036f6:	f7ff f98d 	bl	8002a14 <z_spin_lock_valid>
 80036fa:	b968      	cbnz	r0, 8003718 <z_sched_start+0x38>
 80036fc:	4a1b      	ldr	r2, [pc, #108]	; (800376c <z_sched_start+0x8c>)
 80036fe:	491c      	ldr	r1, [pc, #112]	; (8003770 <z_sched_start+0x90>)
 8003700:	481c      	ldr	r0, [pc, #112]	; (8003774 <z_sched_start+0x94>)
 8003702:	2394      	movs	r3, #148	; 0x94
 8003704:	f001 f9ff 	bl	8004b06 <assert_print>
 8003708:	4917      	ldr	r1, [pc, #92]	; (8003768 <z_sched_start+0x88>)
 800370a:	481b      	ldr	r0, [pc, #108]	; (8003778 <z_sched_start+0x98>)
 800370c:	f001 f9fb 	bl	8004b06 <assert_print>
 8003710:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003712:	4816      	ldr	r0, [pc, #88]	; (800376c <z_sched_start+0x8c>)
 8003714:	f001 f9f0 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 8003718:	4813      	ldr	r0, [pc, #76]	; (8003768 <z_sched_start+0x88>)
 800371a:	f7ff f999 	bl	8002a50 <z_spin_lock_set_owner>
	return (thread->base.thread_state & _THREAD_PRESTART) == 0U;
 800371e:	7b63      	ldrb	r3, [r4, #13]
	if (z_has_thread_started(thread)) {
 8003720:	075a      	lsls	r2, r3, #29
 8003722:	d414      	bmi.n	800374e <z_sched_start+0x6e>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003724:	4810      	ldr	r0, [pc, #64]	; (8003768 <z_sched_start+0x88>)
 8003726:	f7ff f983 	bl	8002a30 <z_spin_unlock_valid>
 800372a:	b958      	cbnz	r0, 8003744 <z_sched_start+0x64>
 800372c:	4a0f      	ldr	r2, [pc, #60]	; (800376c <z_sched_start+0x8c>)
 800372e:	4913      	ldr	r1, [pc, #76]	; (800377c <z_sched_start+0x9c>)
 8003730:	4810      	ldr	r0, [pc, #64]	; (8003774 <z_sched_start+0x94>)
 8003732:	23c2      	movs	r3, #194	; 0xc2
 8003734:	f001 f9e7 	bl	8004b06 <assert_print>
 8003738:	490b      	ldr	r1, [pc, #44]	; (8003768 <z_sched_start+0x88>)
 800373a:	4811      	ldr	r0, [pc, #68]	; (8003780 <z_sched_start+0xa0>)
 800373c:	f001 f9e3 	bl	8004b06 <assert_print>
 8003740:	21c2      	movs	r1, #194	; 0xc2
 8003742:	e7e6      	b.n	8003712 <z_sched_start+0x32>
	__asm__ volatile(
 8003744:	f385 8811 	msr	BASEPRI, r5
 8003748:	f3bf 8f6f 	isb	sy
}
 800374c:	bd38      	pop	{r3, r4, r5, pc}
	thread->base.thread_state &= ~_THREAD_PRESTART;
 800374e:	f023 0304 	bic.w	r3, r3, #4
	ready_thread(thread);
 8003752:	4620      	mov	r0, r4
 8003754:	7363      	strb	r3, [r4, #13]
 8003756:	f7ff ff63 	bl	8003620 <ready_thread>
	z_reschedule(&sched_spinlock, key);
 800375a:	4629      	mov	r1, r5
 800375c:	4802      	ldr	r0, [pc, #8]	; (8003768 <z_sched_start+0x88>)
}
 800375e:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&sched_spinlock, key);
 8003762:	f7ff bd65 	b.w	8003230 <z_reschedule>
 8003766:	bf00      	nop
 8003768:	200007fc 	.word	0x200007fc
 800376c:	080061b7 	.word	0x080061b7
 8003770:	080061e4 	.word	0x080061e4
 8003774:	08005ca7 	.word	0x08005ca7
 8003778:	080061f9 	.word	0x080061f9
 800377c:	08006211 	.word	0x08006211
 8003780:	08006228 	.word	0x08006228

08003784 <z_thread_timeout>:
{
 8003784:	b570      	push	{r4, r5, r6, lr}
 8003786:	4604      	mov	r4, r0
	__asm__ volatile(
 8003788:	f04f 0310 	mov.w	r3, #16
 800378c:	f3ef 8611 	mrs	r6, BASEPRI
 8003790:	f383 8812 	msr	BASEPRI_MAX, r3
 8003794:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003798:	481f      	ldr	r0, [pc, #124]	; (8003818 <z_thread_timeout+0x94>)
 800379a:	f7ff f93b 	bl	8002a14 <z_spin_lock_valid>
 800379e:	b968      	cbnz	r0, 80037bc <z_thread_timeout+0x38>
 80037a0:	4a1e      	ldr	r2, [pc, #120]	; (800381c <z_thread_timeout+0x98>)
 80037a2:	491f      	ldr	r1, [pc, #124]	; (8003820 <z_thread_timeout+0x9c>)
 80037a4:	481f      	ldr	r0, [pc, #124]	; (8003824 <z_thread_timeout+0xa0>)
 80037a6:	2394      	movs	r3, #148	; 0x94
 80037a8:	f001 f9ad 	bl	8004b06 <assert_print>
 80037ac:	491a      	ldr	r1, [pc, #104]	; (8003818 <z_thread_timeout+0x94>)
 80037ae:	481e      	ldr	r0, [pc, #120]	; (8003828 <z_thread_timeout+0xa4>)
 80037b0:	f001 f9a9 	bl	8004b06 <assert_print>
 80037b4:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80037b6:	4819      	ldr	r0, [pc, #100]	; (800381c <z_thread_timeout+0x98>)
 80037b8:	f001 f99e 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 80037bc:	4816      	ldr	r0, [pc, #88]	; (8003818 <z_thread_timeout+0x94>)
 80037be:	f7ff f947 	bl	8002a50 <z_spin_lock_set_owner>
		if (!killed) {
 80037c2:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
 80037c6:	f013 0f28 	tst.w	r3, #40	; 0x28
 80037ca:	d110      	bne.n	80037ee <z_thread_timeout+0x6a>
			if (thread->base.pended_on != NULL) {
 80037cc:	f854 3c10 	ldr.w	r3, [r4, #-16]
	struct k_thread *thread = CONTAINER_OF(timeout,
 80037d0:	f1a4 0518 	sub.w	r5, r4, #24
			if (thread->base.pended_on != NULL) {
 80037d4:	b113      	cbz	r3, 80037dc <z_thread_timeout+0x58>
				unpend_thread_no_timeout(thread);
 80037d6:	4628      	mov	r0, r5
 80037d8:	f7ff fe6c 	bl	80034b4 <unpend_thread_no_timeout>
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
 80037dc:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
 80037e0:	f023 0314 	bic.w	r3, r3, #20
 80037e4:	f804 3c0b 	strb.w	r3, [r4, #-11]
			ready_thread(thread);
 80037e8:	4628      	mov	r0, r5
 80037ea:	f7ff ff19 	bl	8003620 <ready_thread>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80037ee:	480a      	ldr	r0, [pc, #40]	; (8003818 <z_thread_timeout+0x94>)
 80037f0:	f7ff f91e 	bl	8002a30 <z_spin_unlock_valid>
 80037f4:	b958      	cbnz	r0, 800380e <z_thread_timeout+0x8a>
 80037f6:	4a09      	ldr	r2, [pc, #36]	; (800381c <z_thread_timeout+0x98>)
 80037f8:	490c      	ldr	r1, [pc, #48]	; (800382c <z_thread_timeout+0xa8>)
 80037fa:	480a      	ldr	r0, [pc, #40]	; (8003824 <z_thread_timeout+0xa0>)
 80037fc:	23c2      	movs	r3, #194	; 0xc2
 80037fe:	f001 f982 	bl	8004b06 <assert_print>
 8003802:	4905      	ldr	r1, [pc, #20]	; (8003818 <z_thread_timeout+0x94>)
 8003804:	480a      	ldr	r0, [pc, #40]	; (8003830 <z_thread_timeout+0xac>)
 8003806:	f001 f97e 	bl	8004b06 <assert_print>
 800380a:	21c2      	movs	r1, #194	; 0xc2
 800380c:	e7d3      	b.n	80037b6 <z_thread_timeout+0x32>
	__asm__ volatile(
 800380e:	f386 8811 	msr	BASEPRI, r6
 8003812:	f3bf 8f6f 	isb	sy
}
 8003816:	bd70      	pop	{r4, r5, r6, pc}
 8003818:	200007fc 	.word	0x200007fc
 800381c:	080061b7 	.word	0x080061b7
 8003820:	080061e4 	.word	0x080061e4
 8003824:	08005ca7 	.word	0x08005ca7
 8003828:	080061f9 	.word	0x080061f9
 800382c:	08006211 	.word	0x08006211
 8003830:	08006228 	.word	0x08006228

08003834 <z_priq_rb_remove>:

void z_priq_rb_remove(struct _priq_rb *pq, struct k_thread *thread)
{
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 8003834:	4b0b      	ldr	r3, [pc, #44]	; (8003864 <z_priq_rb_remove+0x30>)
 8003836:	428b      	cmp	r3, r1
{
 8003838:	b510      	push	{r4, lr}
 800383a:	4604      	mov	r4, r0
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 800383c:	d10b      	bne.n	8003856 <z_priq_rb_remove+0x22>
 800383e:	490a      	ldr	r1, [pc, #40]	; (8003868 <z_priq_rb_remove+0x34>)
 8003840:	480a      	ldr	r0, [pc, #40]	; (800386c <z_priq_rb_remove+0x38>)
 8003842:	4a0b      	ldr	r2, [pc, #44]	; (8003870 <z_priq_rb_remove+0x3c>)
 8003844:	f44f 6396 	mov.w	r3, #1200	; 0x4b0
 8003848:	f001 f95d 	bl	8004b06 <assert_print>
 800384c:	4808      	ldr	r0, [pc, #32]	; (8003870 <z_priq_rb_remove+0x3c>)
 800384e:	f44f 6196 	mov.w	r1, #1200	; 0x4b0
 8003852:	f001 f951 	bl	8004af8 <assert_post_action>

	rb_remove(&pq->tree, &thread->base.qnode_rb);
 8003856:	f7fc ff49 	bl	80006ec <rb_remove>

	if (!pq->tree.root) {
 800385a:	6823      	ldr	r3, [r4, #0]
 800385c:	b903      	cbnz	r3, 8003860 <z_priq_rb_remove+0x2c>
		pq->next_order_key = 0;
 800385e:	60e3      	str	r3, [r4, #12]
	}
}
 8003860:	bd10      	pop	{r4, pc}
 8003862:	bf00      	nop
 8003864:	20000480 	.word	0x20000480
 8003868:	08006632 	.word	0x08006632
 800386c:	08005ca7 	.word	0x08005ca7
 8003870:	08006559 	.word	0x08006559

08003874 <move_thread_to_end_of_prio_q>:
{
 8003874:	b510      	push	{r4, lr}
	if (z_is_thread_queued(thread)) {
 8003876:	f990 200d 	ldrsb.w	r2, [r0, #13]
	return (thread->base.thread_state & state) != 0U;
 800387a:	7b43      	ldrb	r3, [r0, #13]
 800387c:	2a00      	cmp	r2, #0
{
 800387e:	4604      	mov	r4, r0
	if (z_is_thread_queued(thread)) {
 8003880:	da06      	bge.n	8003890 <move_thread_to_end_of_prio_q+0x1c>
	thread->base.thread_state &= ~_THREAD_QUEUED;
 8003882:	f003 037f 	and.w	r3, r3, #127	; 0x7f
 8003886:	7343      	strb	r3, [r0, #13]
	_priq_run_remove(thread_runq(thread), thread);
 8003888:	4601      	mov	r1, r0
 800388a:	480a      	ldr	r0, [pc, #40]	; (80038b4 <move_thread_to_end_of_prio_q+0x40>)
 800388c:	f7ff ffd2 	bl	8003834 <z_priq_rb_remove>
	thread->base.thread_state |= _THREAD_QUEUED;
 8003890:	7b63      	ldrb	r3, [r4, #13]
	_priq_run_add(thread_runq(thread), thread);
 8003892:	4808      	ldr	r0, [pc, #32]	; (80038b4 <move_thread_to_end_of_prio_q+0x40>)
	thread->base.thread_state |= _THREAD_QUEUED;
 8003894:	f063 037f 	orn	r3, r3, #127	; 0x7f
 8003898:	7363      	strb	r3, [r4, #13]
	_priq_run_add(thread_runq(thread), thread);
 800389a:	4621      	mov	r1, r4
 800389c:	f7ff fe7a 	bl	8003594 <z_priq_rb_add>
	update_cache(thread == _current);
 80038a0:	4b05      	ldr	r3, [pc, #20]	; (80038b8 <move_thread_to_end_of_prio_q+0x44>)
 80038a2:	6898      	ldr	r0, [r3, #8]
 80038a4:	1b03      	subs	r3, r0, r4
 80038a6:	4258      	negs	r0, r3
}
 80038a8:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	update_cache(thread == _current);
 80038ac:	4158      	adcs	r0, r3
 80038ae:	f7ff bc2d 	b.w	800310c <update_cache>
 80038b2:	bf00      	nop
 80038b4:	200007d4 	.word	0x200007d4
 80038b8:	200007b8 	.word	0x200007b8

080038bc <z_time_slice>:
{
 80038bc:	b570      	push	{r4, r5, r6, lr}
 80038be:	4605      	mov	r5, r0
	__asm__ volatile(
 80038c0:	f04f 0310 	mov.w	r3, #16
 80038c4:	f3ef 8611 	mrs	r6, BASEPRI
 80038c8:	f383 8812 	msr	BASEPRI_MAX, r3
 80038cc:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 80038d0:	4829      	ldr	r0, [pc, #164]	; (8003978 <z_time_slice+0xbc>)
 80038d2:	f7ff f89f 	bl	8002a14 <z_spin_lock_valid>
 80038d6:	b968      	cbnz	r0, 80038f4 <z_time_slice+0x38>
 80038d8:	4a28      	ldr	r2, [pc, #160]	; (800397c <z_time_slice+0xc0>)
 80038da:	4929      	ldr	r1, [pc, #164]	; (8003980 <z_time_slice+0xc4>)
 80038dc:	4829      	ldr	r0, [pc, #164]	; (8003984 <z_time_slice+0xc8>)
 80038de:	2394      	movs	r3, #148	; 0x94
 80038e0:	f001 f911 	bl	8004b06 <assert_print>
 80038e4:	4924      	ldr	r1, [pc, #144]	; (8003978 <z_time_slice+0xbc>)
 80038e6:	4828      	ldr	r0, [pc, #160]	; (8003988 <z_time_slice+0xcc>)
 80038e8:	f001 f90d 	bl	8004b06 <assert_print>
 80038ec:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80038ee:	4823      	ldr	r0, [pc, #140]	; (800397c <z_time_slice+0xc0>)
 80038f0:	f001 f902 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 80038f4:	4820      	ldr	r0, [pc, #128]	; (8003978 <z_time_slice+0xbc>)
 80038f6:	f7ff f8ab 	bl	8002a50 <z_spin_lock_set_owner>
	if (pending_current == _current) {
 80038fa:	4b24      	ldr	r3, [pc, #144]	; (800398c <z_time_slice+0xd0>)
 80038fc:	4a24      	ldr	r2, [pc, #144]	; (8003990 <z_time_slice+0xd4>)
 80038fe:	689c      	ldr	r4, [r3, #8]
 8003900:	6811      	ldr	r1, [r2, #0]
 8003902:	428c      	cmp	r4, r1
 8003904:	d112      	bne.n	800392c <z_time_slice+0x70>
		z_reset_time_slice(_current);
 8003906:	4620      	mov	r0, r4
 8003908:	f7ff fbec 	bl	80030e4 <z_reset_time_slice>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 800390c:	481a      	ldr	r0, [pc, #104]	; (8003978 <z_time_slice+0xbc>)
 800390e:	f7ff f88f 	bl	8002a30 <z_spin_unlock_valid>
 8003912:	bb58      	cbnz	r0, 800396c <z_time_slice+0xb0>
 8003914:	4a19      	ldr	r2, [pc, #100]	; (800397c <z_time_slice+0xc0>)
 8003916:	491f      	ldr	r1, [pc, #124]	; (8003994 <z_time_slice+0xd8>)
 8003918:	481a      	ldr	r0, [pc, #104]	; (8003984 <z_time_slice+0xc8>)
 800391a:	23c2      	movs	r3, #194	; 0xc2
 800391c:	f001 f8f3 	bl	8004b06 <assert_print>
 8003920:	4915      	ldr	r1, [pc, #84]	; (8003978 <z_time_slice+0xbc>)
 8003922:	481d      	ldr	r0, [pc, #116]	; (8003998 <z_time_slice+0xdc>)
 8003924:	f001 f8ef 	bl	8004b06 <assert_print>
 8003928:	21c2      	movs	r1, #194	; 0xc2
 800392a:	e7e0      	b.n	80038ee <z_time_slice+0x32>
	pending_current = NULL;
 800392c:	2100      	movs	r1, #0
 800392e:	6011      	str	r1, [r2, #0]
	int ret = slice_ticks;
 8003930:	4a1a      	ldr	r2, [pc, #104]	; (800399c <z_time_slice+0xe0>)
	if (slice_time(_current) && sliceable(_current)) {
 8003932:	6812      	ldr	r2, [r2, #0]
 8003934:	b1c2      	cbz	r2, 8003968 <z_time_slice+0xac>
		&& !z_is_idle_thread_object(thread);
 8003936:	89e2      	ldrh	r2, [r4, #14]
 8003938:	2a7f      	cmp	r2, #127	; 0x7f
 800393a:	d815      	bhi.n	8003968 <z_time_slice+0xac>
		&& !z_is_thread_prevented_from_running(thread)
 800393c:	7b62      	ldrb	r2, [r4, #13]
 800393e:	06d2      	lsls	r2, r2, #27
 8003940:	d112      	bne.n	8003968 <z_time_slice+0xac>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
 8003942:	4a17      	ldr	r2, [pc, #92]	; (80039a0 <z_time_slice+0xe4>)
 8003944:	f994 100e 	ldrsb.w	r1, [r4, #14]
 8003948:	6812      	ldr	r2, [r2, #0]
 800394a:	4291      	cmp	r1, r2
 800394c:	db0c      	blt.n	8003968 <z_time_slice+0xac>
		&& !z_is_idle_thread_object(thread);
 800394e:	4a15      	ldr	r2, [pc, #84]	; (80039a4 <z_time_slice+0xe8>)
 8003950:	4294      	cmp	r4, r2
 8003952:	d009      	beq.n	8003968 <z_time_slice+0xac>
		if (ticks >= _current_cpu->slice_ticks) {
 8003954:	691a      	ldr	r2, [r3, #16]
 8003956:	42aa      	cmp	r2, r5
 8003958:	dc03      	bgt.n	8003962 <z_time_slice+0xa6>
		move_thread_to_end_of_prio_q(curr);
 800395a:	4620      	mov	r0, r4
 800395c:	f7ff ff8a 	bl	8003874 <move_thread_to_end_of_prio_q>
	z_reset_time_slice(curr);
 8003960:	e7d1      	b.n	8003906 <z_time_slice+0x4a>
			_current_cpu->slice_ticks -= ticks;
 8003962:	1b52      	subs	r2, r2, r5
		_current_cpu->slice_ticks = 0;
 8003964:	611a      	str	r2, [r3, #16]
 8003966:	e7d1      	b.n	800390c <z_time_slice+0x50>
 8003968:	2200      	movs	r2, #0
 800396a:	e7fb      	b.n	8003964 <z_time_slice+0xa8>
	__asm__ volatile(
 800396c:	f386 8811 	msr	BASEPRI, r6
 8003970:	f3bf 8f6f 	isb	sy
}
 8003974:	bd70      	pop	{r4, r5, r6, pc}
 8003976:	bf00      	nop
 8003978:	200007fc 	.word	0x200007fc
 800397c:	080061b7 	.word	0x080061b7
 8003980:	080061e4 	.word	0x080061e4
 8003984:	08005ca7 	.word	0x08005ca7
 8003988:	080061f9 	.word	0x080061f9
 800398c:	200007b8 	.word	0x200007b8
 8003990:	200007f0 	.word	0x200007f0
 8003994:	08006211 	.word	0x08006211
 8003998:	08006228 	.word	0x08006228
 800399c:	200007f8 	.word	0x200007f8
 80039a0:	200007f4 	.word	0x200007f4
 80039a4:	20000480 	.word	0x20000480

080039a8 <unready_thread>:
{
 80039a8:	b510      	push	{r4, lr}
	if (z_is_thread_queued(thread)) {
 80039aa:	f990 200d 	ldrsb.w	r2, [r0, #13]
 80039ae:	7b43      	ldrb	r3, [r0, #13]
 80039b0:	2a00      	cmp	r2, #0
{
 80039b2:	4604      	mov	r4, r0
	if (z_is_thread_queued(thread)) {
 80039b4:	da06      	bge.n	80039c4 <unready_thread+0x1c>
	thread->base.thread_state &= ~_THREAD_QUEUED;
 80039b6:	f003 037f 	and.w	r3, r3, #127	; 0x7f
 80039ba:	7343      	strb	r3, [r0, #13]
	_priq_run_remove(thread_runq(thread), thread);
 80039bc:	4601      	mov	r1, r0
 80039be:	4806      	ldr	r0, [pc, #24]	; (80039d8 <unready_thread+0x30>)
 80039c0:	f7ff ff38 	bl	8003834 <z_priq_rb_remove>
	update_cache(thread == _current);
 80039c4:	4b05      	ldr	r3, [pc, #20]	; (80039dc <unready_thread+0x34>)
 80039c6:	6898      	ldr	r0, [r3, #8]
 80039c8:	1b03      	subs	r3, r0, r4
 80039ca:	4258      	negs	r0, r3
}
 80039cc:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	update_cache(thread == _current);
 80039d0:	4158      	adcs	r0, r3
 80039d2:	f7ff bb9b 	b.w	800310c <update_cache>
 80039d6:	bf00      	nop
 80039d8:	200007d4 	.word	0x200007d4
 80039dc:	200007b8 	.word	0x200007b8

080039e0 <add_to_waitq_locked>:
{
 80039e0:	b538      	push	{r3, r4, r5, lr}
 80039e2:	4604      	mov	r4, r0
 80039e4:	460d      	mov	r5, r1
	unready_thread(thread);
 80039e6:	f7ff ffdf 	bl	80039a8 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
 80039ea:	7b63      	ldrb	r3, [r4, #13]
 80039ec:	f043 0302 	orr.w	r3, r3, #2
 80039f0:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
 80039f2:	b34d      	cbz	r5, 8003a48 <add_to_waitq_locked+0x68>
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 80039f4:	4b15      	ldr	r3, [pc, #84]	; (8003a4c <add_to_waitq_locked+0x6c>)
		thread->base.pended_on = wait_q;
 80039f6:	60a5      	str	r5, [r4, #8]
	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));
 80039f8:	429c      	cmp	r4, r3
 80039fa:	d109      	bne.n	8003a10 <add_to_waitq_locked+0x30>
 80039fc:	4914      	ldr	r1, [pc, #80]	; (8003a50 <add_to_waitq_locked+0x70>)
 80039fe:	4815      	ldr	r0, [pc, #84]	; (8003a54 <add_to_waitq_locked+0x74>)
 8003a00:	4a15      	ldr	r2, [pc, #84]	; (8003a58 <add_to_waitq_locked+0x78>)
 8003a02:	23ba      	movs	r3, #186	; 0xba
 8003a04:	f001 f87f 	bl	8004b06 <assert_print>
 8003a08:	4813      	ldr	r0, [pc, #76]	; (8003a58 <add_to_waitq_locked+0x78>)
 8003a0a:	21ba      	movs	r1, #186	; 0xba
 8003a0c:	f001 f874 	bl	8004af8 <assert_post_action>
	return list->head == list;
 8003a10:	682b      	ldr	r3, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
 8003a12:	429d      	cmp	r5, r3
 8003a14:	d109      	bne.n	8003a2a <add_to_waitq_locked+0x4a>
	sys_dnode_t *const tail = list->tail;
 8003a16:	686b      	ldr	r3, [r5, #4]
	node->prev = tail;
 8003a18:	e9c4 5300 	strd	r5, r3, [r4]
	tail->next = node;
 8003a1c:	601c      	str	r4, [r3, #0]
	list->tail = node;
 8003a1e:	606c      	str	r4, [r5, #4]
}
 8003a20:	e012      	b.n	8003a48 <add_to_waitq_locked+0x68>
	return (node == list->tail) ? NULL : node->next;
 8003a22:	686a      	ldr	r2, [r5, #4]
 8003a24:	4293      	cmp	r3, r2
 8003a26:	d0f6      	beq.n	8003a16 <add_to_waitq_locked+0x36>
 8003a28:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
 8003a2a:	2b00      	cmp	r3, #0
 8003a2c:	d0f3      	beq.n	8003a16 <add_to_waitq_locked+0x36>
	int32_t b1 = thread_1->base.prio;
 8003a2e:	f994 200e 	ldrsb.w	r2, [r4, #14]
	int32_t b2 = thread_2->base.prio;
 8003a32:	f993 100e 	ldrsb.w	r1, [r3, #14]
	if (b1 != b2) {
 8003a36:	428a      	cmp	r2, r1
 8003a38:	d0f3      	beq.n	8003a22 <add_to_waitq_locked+0x42>
		if (z_sched_prio_cmp(thread, t) > 0) {
 8003a3a:	4291      	cmp	r1, r2
 8003a3c:	ddf1      	ble.n	8003a22 <add_to_waitq_locked+0x42>
	sys_dnode_t *const prev = successor->prev;
 8003a3e:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
 8003a40:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
 8003a44:	6014      	str	r4, [r2, #0]
	successor->prev = node;
 8003a46:	605c      	str	r4, [r3, #4]
}
 8003a48:	bd38      	pop	{r3, r4, r5, pc}
 8003a4a:	bf00      	nop
 8003a4c:	20000480 	.word	0x20000480
 8003a50:	08006632 	.word	0x08006632
 8003a54:	08005ca7 	.word	0x08005ca7
 8003a58:	08006559 	.word	0x08006559

08003a5c <pend_locked>:
{
 8003a5c:	b570      	push	{r4, r5, r6, lr}
 8003a5e:	4615      	mov	r5, r2
 8003a60:	461c      	mov	r4, r3
 8003a62:	4606      	mov	r6, r0
	add_to_waitq_locked(thread, wait_q);
 8003a64:	f7ff ffbc 	bl	80039e0 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
 8003a68:	f1b4 3fff 	cmp.w	r4, #4294967295	; 0xffffffff
 8003a6c:	bf08      	it	eq
 8003a6e:	f1b5 3fff 	cmpeq.w	r5, #4294967295	; 0xffffffff
 8003a72:	d008      	beq.n	8003a86 <pend_locked+0x2a>
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
 8003a74:	462a      	mov	r2, r5
 8003a76:	4623      	mov	r3, r4
 8003a78:	f106 0018 	add.w	r0, r6, #24
 8003a7c:	4902      	ldr	r1, [pc, #8]	; (8003a88 <pend_locked+0x2c>)
}
 8003a7e:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
 8003a82:	f000 bbdb 	b.w	800423c <z_add_timeout>
 8003a86:	bd70      	pop	{r4, r5, r6, pc}
 8003a88:	08003785 	.word	0x08003785

08003a8c <z_pend_curr>:
{
 8003a8c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	pending_current = _current;
 8003a90:	f8df a0b8 	ldr.w	sl, [pc, #184]	; 8003b4c <z_pend_curr+0xc0>
	__ASSERT_NO_MSG(sizeof(sched_spinlock) == 0 || lock != &sched_spinlock);
 8003a94:	4c2e      	ldr	r4, [pc, #184]	; (8003b50 <z_pend_curr+0xc4>)
	pending_current = _current;
 8003a96:	4b2f      	ldr	r3, [pc, #188]	; (8003b54 <z_pend_curr+0xc8>)
{
 8003a98:	4617      	mov	r7, r2
	__ASSERT_NO_MSG(sizeof(sched_spinlock) == 0 || lock != &sched_spinlock);
 8003a9a:	42a0      	cmp	r0, r4
	pending_current = _current;
 8003a9c:	f8da 2008 	ldr.w	r2, [sl, #8]
 8003aa0:	601a      	str	r2, [r3, #0]
{
 8003aa2:	e9dd 8908 	ldrd	r8, r9, [sp, #32]
 8003aa6:	4605      	mov	r5, r0
 8003aa8:	460e      	mov	r6, r1
	__ASSERT_NO_MSG(sizeof(sched_spinlock) == 0 || lock != &sched_spinlock);
 8003aaa:	d10b      	bne.n	8003ac4 <z_pend_curr+0x38>
 8003aac:	492a      	ldr	r1, [pc, #168]	; (8003b58 <z_pend_curr+0xcc>)
 8003aae:	482b      	ldr	r0, [pc, #172]	; (8003b5c <z_pend_curr+0xd0>)
 8003ab0:	4a2b      	ldr	r2, [pc, #172]	; (8003b60 <z_pend_curr+0xd4>)
 8003ab2:	f240 334e 	movw	r3, #846	; 0x34e
 8003ab6:	f001 f826 	bl	8004b06 <assert_print>
 8003aba:	4829      	ldr	r0, [pc, #164]	; (8003b60 <z_pend_curr+0xd4>)
 8003abc:	f240 314e 	movw	r1, #846	; 0x34e
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003ac0:	f001 f81a 	bl	8004af8 <assert_post_action>
	__asm__ volatile(
 8003ac4:	f04f 0210 	mov.w	r2, #16
 8003ac8:	f3ef 8311 	mrs	r3, BASEPRI
 8003acc:	f382 8812 	msr	BASEPRI_MAX, r2
 8003ad0:	f3bf 8f6f 	isb	sy
 8003ad4:	4620      	mov	r0, r4
 8003ad6:	f7fe ff9d 	bl	8002a14 <z_spin_lock_valid>
 8003ada:	b960      	cbnz	r0, 8003af6 <z_pend_curr+0x6a>
 8003adc:	4a21      	ldr	r2, [pc, #132]	; (8003b64 <z_pend_curr+0xd8>)
 8003ade:	4922      	ldr	r1, [pc, #136]	; (8003b68 <z_pend_curr+0xdc>)
 8003ae0:	481e      	ldr	r0, [pc, #120]	; (8003b5c <z_pend_curr+0xd0>)
 8003ae2:	2394      	movs	r3, #148	; 0x94
 8003ae4:	f001 f80f 	bl	8004b06 <assert_print>
 8003ae8:	4621      	mov	r1, r4
 8003aea:	4820      	ldr	r0, [pc, #128]	; (8003b6c <z_pend_curr+0xe0>)
 8003aec:	f001 f80b 	bl	8004b06 <assert_print>
 8003af0:	2194      	movs	r1, #148	; 0x94
 8003af2:	481c      	ldr	r0, [pc, #112]	; (8003b64 <z_pend_curr+0xd8>)
 8003af4:	e7e4      	b.n	8003ac0 <z_pend_curr+0x34>
	z_spin_lock_set_owner(l);
 8003af6:	4620      	mov	r0, r4
 8003af8:	f7fe ffaa 	bl	8002a50 <z_spin_lock_set_owner>
	pend_locked(_current, wait_q, timeout);
 8003afc:	f8da 0008 	ldr.w	r0, [sl, #8]
 8003b00:	4642      	mov	r2, r8
 8003b02:	464b      	mov	r3, r9
 8003b04:	4639      	mov	r1, r7
 8003b06:	f7ff ffa9 	bl	8003a5c <pend_locked>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003b0a:	4628      	mov	r0, r5
 8003b0c:	f7fe ff90 	bl	8002a30 <z_spin_unlock_valid>
 8003b10:	b958      	cbnz	r0, 8003b2a <z_pend_curr+0x9e>
 8003b12:	4917      	ldr	r1, [pc, #92]	; (8003b70 <z_pend_curr+0xe4>)
 8003b14:	4a13      	ldr	r2, [pc, #76]	; (8003b64 <z_pend_curr+0xd8>)
 8003b16:	4811      	ldr	r0, [pc, #68]	; (8003b5c <z_pend_curr+0xd0>)
 8003b18:	23e1      	movs	r3, #225	; 0xe1
 8003b1a:	f000 fff4 	bl	8004b06 <assert_print>
 8003b1e:	4629      	mov	r1, r5
 8003b20:	4814      	ldr	r0, [pc, #80]	; (8003b74 <z_pend_curr+0xe8>)
 8003b22:	f000 fff0 	bl	8004b06 <assert_print>
 8003b26:	21e1      	movs	r1, #225	; 0xe1
 8003b28:	e7e3      	b.n	8003af2 <z_pend_curr+0x66>
 8003b2a:	4620      	mov	r0, r4
 8003b2c:	f7fe ff80 	bl	8002a30 <z_spin_unlock_valid>
 8003b30:	b938      	cbnz	r0, 8003b42 <z_pend_curr+0xb6>
 8003b32:	490f      	ldr	r1, [pc, #60]	; (8003b70 <z_pend_curr+0xe4>)
 8003b34:	4a0b      	ldr	r2, [pc, #44]	; (8003b64 <z_pend_curr+0xd8>)
 8003b36:	4809      	ldr	r0, [pc, #36]	; (8003b5c <z_pend_curr+0xd0>)
 8003b38:	23e1      	movs	r3, #225	; 0xe1
 8003b3a:	f000 ffe4 	bl	8004b06 <assert_print>
 8003b3e:	4621      	mov	r1, r4
 8003b40:	e7ee      	b.n	8003b20 <z_pend_curr+0x94>
 8003b42:	4630      	mov	r0, r6
}
 8003b44:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
 8003b48:	f7fd bbdc 	b.w	8001304 <arch_swap>
 8003b4c:	200007b8 	.word	0x200007b8
 8003b50:	200007fc 	.word	0x200007fc
 8003b54:	200007f0 	.word	0x200007f0
 8003b58:	0800666a 	.word	0x0800666a
 8003b5c:	08005ca7 	.word	0x08005ca7
 8003b60:	08006559 	.word	0x08006559
 8003b64:	080061b7 	.word	0x080061b7
 8003b68:	080061e4 	.word	0x080061e4
 8003b6c:	080061f9 	.word	0x080061f9
 8003b70:	08006211 	.word	0x08006211
 8003b74:	08006228 	.word	0x08006228

08003b78 <z_set_prio>:
{
 8003b78:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
 8003b7a:	4604      	mov	r4, r0
 8003b7c:	460d      	mov	r5, r1
 8003b7e:	f04f 0310 	mov.w	r3, #16
 8003b82:	f3ef 8711 	mrs	r7, BASEPRI
 8003b86:	f383 8812 	msr	BASEPRI_MAX, r3
 8003b8a:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003b8e:	4824      	ldr	r0, [pc, #144]	; (8003c20 <z_set_prio+0xa8>)
 8003b90:	f7fe ff40 	bl	8002a14 <z_spin_lock_valid>
 8003b94:	4606      	mov	r6, r0
 8003b96:	b968      	cbnz	r0, 8003bb4 <z_set_prio+0x3c>
 8003b98:	4a22      	ldr	r2, [pc, #136]	; (8003c24 <z_set_prio+0xac>)
 8003b9a:	4923      	ldr	r1, [pc, #140]	; (8003c28 <z_set_prio+0xb0>)
 8003b9c:	4823      	ldr	r0, [pc, #140]	; (8003c2c <z_set_prio+0xb4>)
 8003b9e:	2394      	movs	r3, #148	; 0x94
 8003ba0:	f000 ffb1 	bl	8004b06 <assert_print>
 8003ba4:	491e      	ldr	r1, [pc, #120]	; (8003c20 <z_set_prio+0xa8>)
 8003ba6:	4822      	ldr	r0, [pc, #136]	; (8003c30 <z_set_prio+0xb8>)
 8003ba8:	f000 ffad 	bl	8004b06 <assert_print>
 8003bac:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003bae:	481d      	ldr	r0, [pc, #116]	; (8003c24 <z_set_prio+0xac>)
 8003bb0:	f000 ffa2 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 8003bb4:	481a      	ldr	r0, [pc, #104]	; (8003c20 <z_set_prio+0xa8>)
 8003bb6:	f7fe ff4b 	bl	8002a50 <z_spin_lock_set_owner>
	uint8_t state = thread->base.thread_state;
 8003bba:	7b63      	ldrb	r3, [r4, #13]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
 8003bbc:	06da      	lsls	r2, r3, #27
				thread->base.prio = prio;
 8003bbe:	b26d      	sxtb	r5, r5
 8003bc0:	d124      	bne.n	8003c0c <z_set_prio+0x94>
 8003bc2:	69a2      	ldr	r2, [r4, #24]
 8003bc4:	bb12      	cbnz	r2, 8003c0c <z_set_prio+0x94>
	thread->base.thread_state &= ~_THREAD_QUEUED;
 8003bc6:	f003 037f 	and.w	r3, r3, #127	; 0x7f
	_priq_run_remove(thread_runq(thread), thread);
 8003bca:	481a      	ldr	r0, [pc, #104]	; (8003c34 <z_set_prio+0xbc>)
	thread->base.thread_state &= ~_THREAD_QUEUED;
 8003bcc:	7363      	strb	r3, [r4, #13]
	_priq_run_remove(thread_runq(thread), thread);
 8003bce:	4621      	mov	r1, r4
 8003bd0:	f7ff fe30 	bl	8003834 <z_priq_rb_remove>
	thread->base.thread_state |= _THREAD_QUEUED;
 8003bd4:	7b63      	ldrb	r3, [r4, #13]
	_priq_run_add(thread_runq(thread), thread);
 8003bd6:	4817      	ldr	r0, [pc, #92]	; (8003c34 <z_set_prio+0xbc>)
				thread->base.prio = prio;
 8003bd8:	73a5      	strb	r5, [r4, #14]
	thread->base.thread_state |= _THREAD_QUEUED;
 8003bda:	f063 037f 	orn	r3, r3, #127	; 0x7f
 8003bde:	7363      	strb	r3, [r4, #13]
	_priq_run_add(thread_runq(thread), thread);
 8003be0:	4621      	mov	r1, r4
 8003be2:	f7ff fcd7 	bl	8003594 <z_priq_rb_add>
			update_cache(1);
 8003be6:	2001      	movs	r0, #1
 8003be8:	f7ff fa90 	bl	800310c <update_cache>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003bec:	480c      	ldr	r0, [pc, #48]	; (8003c20 <z_set_prio+0xa8>)
 8003bee:	f7fe ff1f 	bl	8002a30 <z_spin_unlock_valid>
 8003bf2:	b970      	cbnz	r0, 8003c12 <z_set_prio+0x9a>
 8003bf4:	4a0b      	ldr	r2, [pc, #44]	; (8003c24 <z_set_prio+0xac>)
 8003bf6:	4910      	ldr	r1, [pc, #64]	; (8003c38 <z_set_prio+0xc0>)
 8003bf8:	480c      	ldr	r0, [pc, #48]	; (8003c2c <z_set_prio+0xb4>)
 8003bfa:	23c2      	movs	r3, #194	; 0xc2
 8003bfc:	f000 ff83 	bl	8004b06 <assert_print>
 8003c00:	4907      	ldr	r1, [pc, #28]	; (8003c20 <z_set_prio+0xa8>)
 8003c02:	480e      	ldr	r0, [pc, #56]	; (8003c3c <z_set_prio+0xc4>)
 8003c04:	f000 ff7f 	bl	8004b06 <assert_print>
 8003c08:	21c2      	movs	r1, #194	; 0xc2
 8003c0a:	e7d0      	b.n	8003bae <z_set_prio+0x36>
			thread->base.prio = prio;
 8003c0c:	73a5      	strb	r5, [r4, #14]
 8003c0e:	2600      	movs	r6, #0
 8003c10:	e7ec      	b.n	8003bec <z_set_prio+0x74>
	__asm__ volatile(
 8003c12:	f387 8811 	msr	BASEPRI, r7
 8003c16:	f3bf 8f6f 	isb	sy
}
 8003c1a:	4630      	mov	r0, r6
 8003c1c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
 8003c1e:	bf00      	nop
 8003c20:	200007fc 	.word	0x200007fc
 8003c24:	080061b7 	.word	0x080061b7
 8003c28:	080061e4 	.word	0x080061e4
 8003c2c:	08005ca7 	.word	0x08005ca7
 8003c30:	080061f9 	.word	0x080061f9
 8003c34:	200007d4 	.word	0x200007d4
 8003c38:	08006211 	.word	0x08006211
 8003c3c:	08006228 	.word	0x08006228

08003c40 <z_impl_k_thread_suspend>:
{
 8003c40:	b570      	push	{r4, r5, r6, lr}
 8003c42:	4604      	mov	r4, r0
	return z_abort_timeout(&thread->base.timeout);
 8003c44:	3018      	adds	r0, #24
 8003c46:	f000 fbbf 	bl	80043c8 <z_abort_timeout>
	__asm__ volatile(
 8003c4a:	f04f 0310 	mov.w	r3, #16
 8003c4e:	f3ef 8611 	mrs	r6, BASEPRI
 8003c52:	f383 8812 	msr	BASEPRI_MAX, r3
 8003c56:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003c5a:	4824      	ldr	r0, [pc, #144]	; (8003cec <z_impl_k_thread_suspend+0xac>)
 8003c5c:	f7fe feda 	bl	8002a14 <z_spin_lock_valid>
 8003c60:	b968      	cbnz	r0, 8003c7e <z_impl_k_thread_suspend+0x3e>
 8003c62:	4a23      	ldr	r2, [pc, #140]	; (8003cf0 <z_impl_k_thread_suspend+0xb0>)
 8003c64:	4923      	ldr	r1, [pc, #140]	; (8003cf4 <z_impl_k_thread_suspend+0xb4>)
 8003c66:	4824      	ldr	r0, [pc, #144]	; (8003cf8 <z_impl_k_thread_suspend+0xb8>)
 8003c68:	2394      	movs	r3, #148	; 0x94
 8003c6a:	f000 ff4c 	bl	8004b06 <assert_print>
 8003c6e:	491f      	ldr	r1, [pc, #124]	; (8003cec <z_impl_k_thread_suspend+0xac>)
 8003c70:	4822      	ldr	r0, [pc, #136]	; (8003cfc <z_impl_k_thread_suspend+0xbc>)
 8003c72:	f000 ff48 	bl	8004b06 <assert_print>
 8003c76:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003c78:	481d      	ldr	r0, [pc, #116]	; (8003cf0 <z_impl_k_thread_suspend+0xb0>)
 8003c7a:	f000 ff3d 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 8003c7e:	481b      	ldr	r0, [pc, #108]	; (8003cec <z_impl_k_thread_suspend+0xac>)
 8003c80:	f7fe fee6 	bl	8002a50 <z_spin_lock_set_owner>
		if (z_is_thread_queued(thread)) {
 8003c84:	f994 200d 	ldrsb.w	r2, [r4, #13]
	return (thread->base.thread_state & state) != 0U;
 8003c88:	7b63      	ldrb	r3, [r4, #13]
 8003c8a:	2a00      	cmp	r2, #0
 8003c8c:	da06      	bge.n	8003c9c <z_impl_k_thread_suspend+0x5c>
	thread->base.thread_state &= ~_THREAD_QUEUED;
 8003c8e:	f003 037f 	and.w	r3, r3, #127	; 0x7f
	_priq_run_remove(thread_runq(thread), thread);
 8003c92:	481b      	ldr	r0, [pc, #108]	; (8003d00 <z_impl_k_thread_suspend+0xc0>)
	thread->base.thread_state &= ~_THREAD_QUEUED;
 8003c94:	7363      	strb	r3, [r4, #13]
	_priq_run_remove(thread_runq(thread), thread);
 8003c96:	4621      	mov	r1, r4
 8003c98:	f7ff fdcc 	bl	8003834 <z_priq_rb_remove>
		update_cache(thread == _current);
 8003c9c:	4d19      	ldr	r5, [pc, #100]	; (8003d04 <z_impl_k_thread_suspend+0xc4>)
	thread->base.thread_state |= _THREAD_SUSPENDED;
 8003c9e:	7b63      	ldrb	r3, [r4, #13]
 8003ca0:	68a8      	ldr	r0, [r5, #8]
 8003ca2:	f043 0310 	orr.w	r3, r3, #16
 8003ca6:	7363      	strb	r3, [r4, #13]
 8003ca8:	1b03      	subs	r3, r0, r4
 8003caa:	4258      	negs	r0, r3
 8003cac:	4158      	adcs	r0, r3
 8003cae:	f7ff fa2d 	bl	800310c <update_cache>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003cb2:	480e      	ldr	r0, [pc, #56]	; (8003cec <z_impl_k_thread_suspend+0xac>)
 8003cb4:	f7fe febc 	bl	8002a30 <z_spin_unlock_valid>
 8003cb8:	b958      	cbnz	r0, 8003cd2 <z_impl_k_thread_suspend+0x92>
 8003cba:	4a0d      	ldr	r2, [pc, #52]	; (8003cf0 <z_impl_k_thread_suspend+0xb0>)
 8003cbc:	4912      	ldr	r1, [pc, #72]	; (8003d08 <z_impl_k_thread_suspend+0xc8>)
 8003cbe:	480e      	ldr	r0, [pc, #56]	; (8003cf8 <z_impl_k_thread_suspend+0xb8>)
 8003cc0:	23c2      	movs	r3, #194	; 0xc2
 8003cc2:	f000 ff20 	bl	8004b06 <assert_print>
 8003cc6:	4909      	ldr	r1, [pc, #36]	; (8003cec <z_impl_k_thread_suspend+0xac>)
 8003cc8:	4810      	ldr	r0, [pc, #64]	; (8003d0c <z_impl_k_thread_suspend+0xcc>)
 8003cca:	f000 ff1c 	bl	8004b06 <assert_print>
 8003cce:	21c2      	movs	r1, #194	; 0xc2
 8003cd0:	e7d2      	b.n	8003c78 <z_impl_k_thread_suspend+0x38>
	__asm__ volatile(
 8003cd2:	f386 8811 	msr	BASEPRI, r6
 8003cd6:	f3bf 8f6f 	isb	sy
	if (thread == _current) {
 8003cda:	68ab      	ldr	r3, [r5, #8]
 8003cdc:	42a3      	cmp	r3, r4
 8003cde:	d103      	bne.n	8003ce8 <z_impl_k_thread_suspend+0xa8>
}
 8003ce0:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule_unlocked();
 8003ce4:	f001 bb0b 	b.w	80052fe <z_reschedule_unlocked>
}
 8003ce8:	bd70      	pop	{r4, r5, r6, pc}
 8003cea:	bf00      	nop
 8003cec:	200007fc 	.word	0x200007fc
 8003cf0:	080061b7 	.word	0x080061b7
 8003cf4:	080061e4 	.word	0x080061e4
 8003cf8:	08005ca7 	.word	0x08005ca7
 8003cfc:	080061f9 	.word	0x080061f9
 8003d00:	200007d4 	.word	0x200007d4
 8003d04:	200007b8 	.word	0x200007b8
 8003d08:	08006211 	.word	0x08006211
 8003d0c:	08006228 	.word	0x08006228

08003d10 <init_ready_q>:

	return need_sched;
}

void init_ready_q(struct _ready_q *rq)
{
 8003d10:	b510      	push	{r4, lr}
#if defined(CONFIG_SCHED_SCALABLE)
	rq->runq = (struct _priq_rb) {
 8003d12:	2210      	movs	r2, #16
{
 8003d14:	4604      	mov	r4, r0
	rq->runq = (struct _priq_rb) {
 8003d16:	2100      	movs	r1, #0
 8003d18:	3004      	adds	r0, #4
 8003d1a:	f000 ff44 	bl	8004ba6 <memset>
 8003d1e:	4b01      	ldr	r3, [pc, #4]	; (8003d24 <init_ready_q+0x14>)
 8003d20:	60a3      	str	r3, [r4, #8]
		sys_dlist_init(&rq->runq.queues[i]);
	}
#else
	sys_dlist_init(&rq->runq);
#endif
}
 8003d22:	bd10      	pop	{r4, pc}
 8003d24:	080052c3 	.word	0x080052c3

08003d28 <z_sched_init>:

void z_sched_init(void)
{
 8003d28:	b508      	push	{r3, lr}

	for (int i = 0; i < num_cpus; i++) {
		init_ready_q(&_kernel.cpus[i].ready_q);
	}
#else
	init_ready_q(&_kernel.ready_q);
 8003d2a:	4804      	ldr	r0, [pc, #16]	; (8003d3c <z_sched_init+0x14>)
 8003d2c:	f7ff fff0 	bl	8003d10 <init_ready_q>
#endif

#ifdef CONFIG_TIMESLICING
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
 8003d30:	2100      	movs	r1, #0
		CONFIG_TIMESLICE_PRIORITY);
#endif
}
 8003d32:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
 8003d36:	4608      	mov	r0, r1
 8003d38:	f7ff ba1e 	b.w	8003178 <k_sched_time_slice_set>
 8003d3c:	200007d0 	.word	0x200007d0

08003d40 <z_impl_k_yield>:
	return !(k_is_pre_kernel() || k_is_in_isr() ||
		 z_is_idle_thread_object(_current));
}

void z_impl_k_yield(void)
{
 8003d40:	b538      	push	{r3, r4, r5, lr}
 8003d42:	f3ef 8305 	mrs	r3, IPSR
	__ASSERT(!arch_is_in_isr(), "");
 8003d46:	b173      	cbz	r3, 8003d66 <z_impl_k_yield+0x26>
 8003d48:	492a      	ldr	r1, [pc, #168]	; (8003df4 <z_impl_k_yield+0xb4>)
 8003d4a:	4a2b      	ldr	r2, [pc, #172]	; (8003df8 <z_impl_k_yield+0xb8>)
 8003d4c:	482b      	ldr	r0, [pc, #172]	; (8003dfc <z_impl_k_yield+0xbc>)
 8003d4e:	f44f 63ae 	mov.w	r3, #1392	; 0x570
 8003d52:	f000 fed8 	bl	8004b06 <assert_print>
 8003d56:	482a      	ldr	r0, [pc, #168]	; (8003e00 <z_impl_k_yield+0xc0>)
 8003d58:	f000 fed5 	bl	8004b06 <assert_print>
 8003d5c:	4826      	ldr	r0, [pc, #152]	; (8003df8 <z_impl_k_yield+0xb8>)
 8003d5e:	f44f 61ae 	mov.w	r1, #1392	; 0x570
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003d62:	f000 fec9 	bl	8004af8 <assert_post_action>
	__asm__ volatile(
 8003d66:	f04f 0310 	mov.w	r3, #16
 8003d6a:	f3ef 8511 	mrs	r5, BASEPRI
 8003d6e:	f383 8812 	msr	BASEPRI_MAX, r3
 8003d72:	f3bf 8f6f 	isb	sy
 8003d76:	4823      	ldr	r0, [pc, #140]	; (8003e04 <z_impl_k_yield+0xc4>)
 8003d78:	f7fe fe4c 	bl	8002a14 <z_spin_lock_valid>
 8003d7c:	b960      	cbnz	r0, 8003d98 <z_impl_k_yield+0x58>
 8003d7e:	4a22      	ldr	r2, [pc, #136]	; (8003e08 <z_impl_k_yield+0xc8>)
 8003d80:	4922      	ldr	r1, [pc, #136]	; (8003e0c <z_impl_k_yield+0xcc>)
 8003d82:	481e      	ldr	r0, [pc, #120]	; (8003dfc <z_impl_k_yield+0xbc>)
 8003d84:	2394      	movs	r3, #148	; 0x94
 8003d86:	f000 febe 	bl	8004b06 <assert_print>
 8003d8a:	491e      	ldr	r1, [pc, #120]	; (8003e04 <z_impl_k_yield+0xc4>)
 8003d8c:	4820      	ldr	r0, [pc, #128]	; (8003e10 <z_impl_k_yield+0xd0>)
 8003d8e:	f000 feba 	bl	8004b06 <assert_print>
 8003d92:	2194      	movs	r1, #148	; 0x94
 8003d94:	481c      	ldr	r0, [pc, #112]	; (8003e08 <z_impl_k_yield+0xc8>)
 8003d96:	e7e4      	b.n	8003d62 <z_impl_k_yield+0x22>

	k_spinlock_key_t key = k_spin_lock(&sched_spinlock);

	if (!IS_ENABLED(CONFIG_SMP) ||
	    z_is_thread_queued(_current)) {
		dequeue_thread(_current);
 8003d98:	4c1e      	ldr	r4, [pc, #120]	; (8003e14 <z_impl_k_yield+0xd4>)
	z_spin_lock_set_owner(l);
 8003d9a:	481a      	ldr	r0, [pc, #104]	; (8003e04 <z_impl_k_yield+0xc4>)
 8003d9c:	f7fe fe58 	bl	8002a50 <z_spin_lock_set_owner>
 8003da0:	68a1      	ldr	r1, [r4, #8]
	thread->base.thread_state &= ~_THREAD_QUEUED;
 8003da2:	7b4b      	ldrb	r3, [r1, #13]
 8003da4:	f003 037f 	and.w	r3, r3, #127	; 0x7f
 8003da8:	734b      	strb	r3, [r1, #13]
	_priq_run_remove(thread_runq(thread), thread);
 8003daa:	f104 001c 	add.w	r0, r4, #28
 8003dae:	f7ff fd41 	bl	8003834 <z_priq_rb_remove>
	}
	queue_thread(_current);
 8003db2:	68a1      	ldr	r1, [r4, #8]
	thread->base.thread_state |= _THREAD_QUEUED;
 8003db4:	7b4b      	ldrb	r3, [r1, #13]
 8003db6:	f063 037f 	orn	r3, r3, #127	; 0x7f
 8003dba:	734b      	strb	r3, [r1, #13]
	_priq_run_add(thread_runq(thread), thread);
 8003dbc:	f104 001c 	add.w	r0, r4, #28
 8003dc0:	f7ff fbe8 	bl	8003594 <z_priq_rb_add>
	update_cache(1);
 8003dc4:	2001      	movs	r0, #1
 8003dc6:	f7ff f9a1 	bl	800310c <update_cache>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003dca:	480e      	ldr	r0, [pc, #56]	; (8003e04 <z_impl_k_yield+0xc4>)
 8003dcc:	f7fe fe30 	bl	8002a30 <z_spin_unlock_valid>
 8003dd0:	b958      	cbnz	r0, 8003dea <z_impl_k_yield+0xaa>
 8003dd2:	4a0d      	ldr	r2, [pc, #52]	; (8003e08 <z_impl_k_yield+0xc8>)
 8003dd4:	4910      	ldr	r1, [pc, #64]	; (8003e18 <z_impl_k_yield+0xd8>)
 8003dd6:	4809      	ldr	r0, [pc, #36]	; (8003dfc <z_impl_k_yield+0xbc>)
 8003dd8:	23e1      	movs	r3, #225	; 0xe1
 8003dda:	f000 fe94 	bl	8004b06 <assert_print>
 8003dde:	4909      	ldr	r1, [pc, #36]	; (8003e04 <z_impl_k_yield+0xc4>)
 8003de0:	480e      	ldr	r0, [pc, #56]	; (8003e1c <z_impl_k_yield+0xdc>)
 8003de2:	f000 fe90 	bl	8004b06 <assert_print>
 8003de6:	21e1      	movs	r1, #225	; 0xe1
 8003de8:	e7d4      	b.n	8003d94 <z_impl_k_yield+0x54>
 8003dea:	4628      	mov	r0, r5
	z_swap(&sched_spinlock, key);
}
 8003dec:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
 8003df0:	f7fd ba88 	b.w	8001304 <arch_swap>
 8003df4:	0800642f 	.word	0x0800642f
 8003df8:	08006559 	.word	0x08006559
 8003dfc:	08005ca7 	.word	0x08005ca7
 8003e00:	080065a2 	.word	0x080065a2
 8003e04:	200007fc 	.word	0x200007fc
 8003e08:	080061b7 	.word	0x080061b7
 8003e0c:	080061e4 	.word	0x080061e4
 8003e10:	080061f9 	.word	0x080061f9
 8003e14:	200007b8 	.word	0x200007b8
 8003e18:	08006211 	.word	0x08006211
 8003e1c:	08006228 	.word	0x08006228

08003e20 <z_tick_sleep>:
}
#include <syscalls/k_yield_mrsh.c>
#endif

static int32_t z_tick_sleep(k_ticks_t ticks)
{
 8003e20:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 8003e24:	4605      	mov	r5, r0
 8003e26:	460e      	mov	r6, r1
 8003e28:	f3ef 8305 	mrs	r3, IPSR
#ifdef CONFIG_MULTITHREADING
	uint32_t expected_wakeup_ticks;

	__ASSERT(!arch_is_in_isr(), "");
 8003e2c:	b16b      	cbz	r3, 8003e4a <z_tick_sleep+0x2a>
 8003e2e:	493f      	ldr	r1, [pc, #252]	; (8003f2c <z_tick_sleep+0x10c>)
 8003e30:	4a3f      	ldr	r2, [pc, #252]	; (8003f30 <z_tick_sleep+0x110>)
 8003e32:	4840      	ldr	r0, [pc, #256]	; (8003f34 <z_tick_sleep+0x114>)
 8003e34:	f240 538c 	movw	r3, #1420	; 0x58c
 8003e38:	f000 fe65 	bl	8004b06 <assert_print>
 8003e3c:	483e      	ldr	r0, [pc, #248]	; (8003f38 <z_tick_sleep+0x118>)
 8003e3e:	f000 fe62 	bl	8004b06 <assert_print>
 8003e42:	f240 518c 	movw	r1, #1420	; 0x58c
	z_add_thread_timeout(_current, timeout);
	z_mark_thread_as_suspended(_current);

	(void)z_swap(&sched_spinlock, key);

	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");
 8003e46:	483a      	ldr	r0, [pc, #232]	; (8003f30 <z_tick_sleep+0x110>)
 8003e48:	e025      	b.n	8003e96 <z_tick_sleep+0x76>
	if (ticks == 0) {
 8003e4a:	ea50 0301 	orrs.w	r3, r0, r1
 8003e4e:	d103      	bne.n	8003e58 <z_tick_sleep+0x38>
	z_impl_k_yield();
 8003e50:	f7ff ff76 	bl	8003d40 <z_impl_k_yield>
		return 0;
 8003e54:	2000      	movs	r0, #0
 8003e56:	e066      	b.n	8003f26 <z_tick_sleep+0x106>
	if (Z_TICK_ABS(ticks) <= 0) {
 8003e58:	1c82      	adds	r2, r0, #2
 8003e5a:	f171 33ff 	sbcs.w	r3, r1, #4294967295	; 0xffffffff
 8003e5e:	db1c      	blt.n	8003e9a <z_tick_sleep+0x7a>
		expected_wakeup_ticks = ticks + sys_clock_tick_get_32();
 8003e60:	f001 fa5a 	bl	8005318 <sys_clock_tick_get_32>
 8003e64:	182c      	adds	r4, r5, r0
 8003e66:	f04f 0310 	mov.w	r3, #16
 8003e6a:	f3ef 8811 	mrs	r8, BASEPRI
 8003e6e:	f383 8812 	msr	BASEPRI_MAX, r3
 8003e72:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003e76:	4831      	ldr	r0, [pc, #196]	; (8003f3c <z_tick_sleep+0x11c>)
 8003e78:	f7fe fdcc 	bl	8002a14 <z_spin_lock_valid>
 8003e7c:	b988      	cbnz	r0, 8003ea2 <z_tick_sleep+0x82>
 8003e7e:	4a30      	ldr	r2, [pc, #192]	; (8003f40 <z_tick_sleep+0x120>)
 8003e80:	4930      	ldr	r1, [pc, #192]	; (8003f44 <z_tick_sleep+0x124>)
 8003e82:	482c      	ldr	r0, [pc, #176]	; (8003f34 <z_tick_sleep+0x114>)
 8003e84:	2394      	movs	r3, #148	; 0x94
 8003e86:	f000 fe3e 	bl	8004b06 <assert_print>
 8003e8a:	492c      	ldr	r1, [pc, #176]	; (8003f3c <z_tick_sleep+0x11c>)
 8003e8c:	482e      	ldr	r0, [pc, #184]	; (8003f48 <z_tick_sleep+0x128>)
 8003e8e:	f000 fe3a 	bl	8004b06 <assert_print>
 8003e92:	2194      	movs	r1, #148	; 0x94
 8003e94:	482a      	ldr	r0, [pc, #168]	; (8003f40 <z_tick_sleep+0x120>)
 8003e96:	f000 fe2f 	bl	8004af8 <assert_post_action>
		expected_wakeup_ticks = Z_TICK_ABS(ticks);
 8003e9a:	f06f 0401 	mvn.w	r4, #1
 8003e9e:	1a24      	subs	r4, r4, r0
 8003ea0:	e7e1      	b.n	8003e66 <z_tick_sleep+0x46>
	pending_current = _current;
 8003ea2:	4f2a      	ldr	r7, [pc, #168]	; (8003f4c <z_tick_sleep+0x12c>)
	z_spin_lock_set_owner(l);
 8003ea4:	4825      	ldr	r0, [pc, #148]	; (8003f3c <z_tick_sleep+0x11c>)
 8003ea6:	f7fe fdd3 	bl	8002a50 <z_spin_lock_set_owner>
 8003eaa:	4b29      	ldr	r3, [pc, #164]	; (8003f50 <z_tick_sleep+0x130>)
 8003eac:	68b8      	ldr	r0, [r7, #8]
 8003eae:	6018      	str	r0, [r3, #0]
	unready_thread(_current);
 8003eb0:	f7ff fd7a 	bl	80039a8 <unready_thread>
	z_add_thread_timeout(_current, timeout);
 8003eb4:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
 8003eb6:	4927      	ldr	r1, [pc, #156]	; (8003f54 <z_tick_sleep+0x134>)
 8003eb8:	462a      	mov	r2, r5
 8003eba:	4633      	mov	r3, r6
 8003ebc:	3018      	adds	r0, #24
 8003ebe:	f000 f9bd 	bl	800423c <z_add_timeout>
	z_mark_thread_as_suspended(_current);
 8003ec2:	68ba      	ldr	r2, [r7, #8]
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8003ec4:	481d      	ldr	r0, [pc, #116]	; (8003f3c <z_tick_sleep+0x11c>)
 8003ec6:	7b53      	ldrb	r3, [r2, #13]
 8003ec8:	f043 0310 	orr.w	r3, r3, #16
 8003ecc:	7353      	strb	r3, [r2, #13]
 8003ece:	f7fe fdaf 	bl	8002a30 <z_spin_unlock_valid>
 8003ed2:	b958      	cbnz	r0, 8003eec <z_tick_sleep+0xcc>
 8003ed4:	4a1a      	ldr	r2, [pc, #104]	; (8003f40 <z_tick_sleep+0x120>)
 8003ed6:	4920      	ldr	r1, [pc, #128]	; (8003f58 <z_tick_sleep+0x138>)
 8003ed8:	4816      	ldr	r0, [pc, #88]	; (8003f34 <z_tick_sleep+0x114>)
 8003eda:	23e1      	movs	r3, #225	; 0xe1
 8003edc:	f000 fe13 	bl	8004b06 <assert_print>
 8003ee0:	4916      	ldr	r1, [pc, #88]	; (8003f3c <z_tick_sleep+0x11c>)
 8003ee2:	481e      	ldr	r0, [pc, #120]	; (8003f5c <z_tick_sleep+0x13c>)
 8003ee4:	f000 fe0f 	bl	8004b06 <assert_print>
 8003ee8:	21e1      	movs	r1, #225	; 0xe1
 8003eea:	e7d3      	b.n	8003e94 <z_tick_sleep+0x74>
 8003eec:	4640      	mov	r0, r8
 8003eee:	f7fd fa09 	bl	8001304 <arch_swap>
	return (thread->base.thread_state & state) != 0U;
 8003ef2:	68bb      	ldr	r3, [r7, #8]
	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");
 8003ef4:	7b5b      	ldrb	r3, [r3, #13]
 8003ef6:	06db      	lsls	r3, r3, #27
 8003ef8:	d50c      	bpl.n	8003f14 <z_tick_sleep+0xf4>
 8003efa:	4919      	ldr	r1, [pc, #100]	; (8003f60 <z_tick_sleep+0x140>)
 8003efc:	4a0c      	ldr	r2, [pc, #48]	; (8003f30 <z_tick_sleep+0x110>)
 8003efe:	480d      	ldr	r0, [pc, #52]	; (8003f34 <z_tick_sleep+0x114>)
 8003f00:	f44f 63b5 	mov.w	r3, #1448	; 0x5a8
 8003f04:	f000 fdff 	bl	8004b06 <assert_print>
 8003f08:	480b      	ldr	r0, [pc, #44]	; (8003f38 <z_tick_sleep+0x118>)
 8003f0a:	f000 fdfc 	bl	8004b06 <assert_print>
 8003f0e:	f44f 61b5 	mov.w	r1, #1448	; 0x5a8
 8003f12:	e798      	b.n	8003e46 <z_tick_sleep+0x26>

	ticks = (k_ticks_t)expected_wakeup_ticks - sys_clock_tick_get_32();
 8003f14:	f001 fa00 	bl	8005318 <sys_clock_tick_get_32>
 8003f18:	1a20      	subs	r0, r4, r0
 8003f1a:	eb63 0303 	sbc.w	r3, r3, r3
	if (ticks > 0) {
 8003f1e:	2801      	cmp	r0, #1
 8003f20:	f173 0300 	sbcs.w	r3, r3, #0
 8003f24:	db96      	blt.n	8003e54 <z_tick_sleep+0x34>
		return ticks;
	}
#endif

	return 0;
}
 8003f26:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
 8003f2a:	bf00      	nop
 8003f2c:	0800642f 	.word	0x0800642f
 8003f30:	08006559 	.word	0x08006559
 8003f34:	08005ca7 	.word	0x08005ca7
 8003f38:	080065a2 	.word	0x080065a2
 8003f3c:	200007fc 	.word	0x200007fc
 8003f40:	080061b7 	.word	0x080061b7
 8003f44:	080061e4 	.word	0x080061e4
 8003f48:	080061f9 	.word	0x080061f9
 8003f4c:	200007b8 	.word	0x200007b8
 8003f50:	200007f0 	.word	0x200007f0
 8003f54:	08003785 	.word	0x08003785
 8003f58:	08006211 	.word	0x08006211
 8003f5c:	08006228 	.word	0x08006228
 8003f60:	080066a1 	.word	0x080066a1

08003f64 <z_impl_k_sleep>:

int32_t z_impl_k_sleep(k_timeout_t timeout)
{
 8003f64:	b508      	push	{r3, lr}
 8003f66:	f3ef 8305 	mrs	r3, IPSR
	k_ticks_t ticks;

	__ASSERT(!arch_is_in_isr(), "");
 8003f6a:	b173      	cbz	r3, 8003f8a <z_impl_k_sleep+0x26>
 8003f6c:	4911      	ldr	r1, [pc, #68]	; (8003fb4 <z_impl_k_sleep+0x50>)
 8003f6e:	4a12      	ldr	r2, [pc, #72]	; (8003fb8 <z_impl_k_sleep+0x54>)
 8003f70:	4812      	ldr	r0, [pc, #72]	; (8003fbc <z_impl_k_sleep+0x58>)
 8003f72:	f240 53b7 	movw	r3, #1463	; 0x5b7
 8003f76:	f000 fdc6 	bl	8004b06 <assert_print>
 8003f7a:	4811      	ldr	r0, [pc, #68]	; (8003fc0 <z_impl_k_sleep+0x5c>)
 8003f7c:	f000 fdc3 	bl	8004b06 <assert_print>
 8003f80:	480d      	ldr	r0, [pc, #52]	; (8003fb8 <z_impl_k_sleep+0x54>)
 8003f82:	f240 51b7 	movw	r1, #1463	; 0x5b7
 8003f86:	f000 fdb7 	bl	8004af8 <assert_post_action>

	SYS_PORT_TRACING_FUNC_ENTER(k_thread, sleep, timeout);

	/* in case of K_FOREVER, we suspend */
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
 8003f8a:	f1b1 3fff 	cmp.w	r1, #4294967295	; 0xffffffff
 8003f8e:	bf08      	it	eq
 8003f90:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
 8003f94:	d106      	bne.n	8003fa4 <z_impl_k_sleep+0x40>
		k_thread_suspend(_current);
 8003f96:	4b0b      	ldr	r3, [pc, #44]	; (8003fc4 <z_impl_k_sleep+0x60>)
 8003f98:	6898      	ldr	r0, [r3, #8]
	z_impl_k_thread_suspend(thread);
 8003f9a:	f7ff fe51 	bl	8003c40 <z_impl_k_thread_suspend>

		SYS_PORT_TRACING_FUNC_EXIT(k_thread, sleep, timeout, (int32_t) K_TICKS_FOREVER);

		return (int32_t) K_TICKS_FOREVER;
 8003f9e:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
	int32_t ret = k_ticks_to_ms_floor64(ticks);

	SYS_PORT_TRACING_FUNC_EXIT(k_thread, sleep, timeout, ret);

	return ret;
}
 8003fa2:	bd08      	pop	{r3, pc}
	ticks = z_tick_sleep(ticks);
 8003fa4:	f7ff ff3c 	bl	8003e20 <z_tick_sleep>
			return t / ((uint64_t)from_hz / to_hz);
 8003fa8:	220a      	movs	r2, #10
 8003faa:	2300      	movs	r3, #0
 8003fac:	17c1      	asrs	r1, r0, #31
 8003fae:	f7fc f8f3 	bl	8000198 <__aeabi_uldivmod>
	return ret;
 8003fb2:	e7f6      	b.n	8003fa2 <z_impl_k_sleep+0x3e>
 8003fb4:	0800642f 	.word	0x0800642f
 8003fb8:	08006559 	.word	0x08006559
 8003fbc:	08005ca7 	.word	0x08005ca7
 8003fc0:	080065a2 	.word	0x080065a2
 8003fc4:	200007b8 	.word	0x200007b8

08003fc8 <z_impl_z_current_get>:

#ifdef CONFIG_SMP
	arch_irq_unlock(k);
#endif
	return ret;
}
 8003fc8:	4b01      	ldr	r3, [pc, #4]	; (8003fd0 <z_impl_z_current_get+0x8>)
 8003fca:	6898      	ldr	r0, [r3, #8]
 8003fcc:	4770      	bx	lr
 8003fce:	bf00      	nop
 8003fd0:	200007b8 	.word	0x200007b8

08003fd4 <z_thread_abort>:
#endif
	}
}

void z_thread_abort(struct k_thread *thread)
{
 8003fd4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 8003fd8:	4604      	mov	r4, r0
 8003fda:	f04f 0310 	mov.w	r3, #16
 8003fde:	f3ef 8611 	mrs	r6, BASEPRI
 8003fe2:	f383 8812 	msr	BASEPRI_MAX, r3
 8003fe6:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8003fea:	4853      	ldr	r0, [pc, #332]	; (8004138 <z_thread_abort+0x164>)
 8003fec:	f7fe fd12 	bl	8002a14 <z_spin_lock_valid>
 8003ff0:	b968      	cbnz	r0, 800400e <z_thread_abort+0x3a>
 8003ff2:	4a52      	ldr	r2, [pc, #328]	; (800413c <z_thread_abort+0x168>)
 8003ff4:	4952      	ldr	r1, [pc, #328]	; (8004140 <z_thread_abort+0x16c>)
 8003ff6:	4853      	ldr	r0, [pc, #332]	; (8004144 <z_thread_abort+0x170>)
 8003ff8:	2394      	movs	r3, #148	; 0x94
 8003ffa:	f000 fd84 	bl	8004b06 <assert_print>
 8003ffe:	494e      	ldr	r1, [pc, #312]	; (8004138 <z_thread_abort+0x164>)
 8004000:	4851      	ldr	r0, [pc, #324]	; (8004148 <z_thread_abort+0x174>)
 8004002:	f000 fd80 	bl	8004b06 <assert_print>
 8004006:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004008:	484c      	ldr	r0, [pc, #304]	; (800413c <z_thread_abort+0x168>)
 800400a:	f000 fd75 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 800400e:	484a      	ldr	r0, [pc, #296]	; (8004138 <z_thread_abort+0x164>)
 8004010:	f7fe fd1e 	bl	8002a50 <z_spin_lock_set_owner>
	k_spinlock_key_t key = k_spin_lock(&sched_spinlock);

	if ((thread->base.user_options & K_ESSENTIAL) != 0) {
 8004014:	7b23      	ldrb	r3, [r4, #12]
 8004016:	07d9      	lsls	r1, r3, #31
 8004018:	d522      	bpl.n	8004060 <z_thread_abort+0x8c>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 800401a:	4847      	ldr	r0, [pc, #284]	; (8004138 <z_thread_abort+0x164>)
 800401c:	f7fe fd08 	bl	8002a30 <z_spin_unlock_valid>
 8004020:	b958      	cbnz	r0, 800403a <z_thread_abort+0x66>
 8004022:	4a46      	ldr	r2, [pc, #280]	; (800413c <z_thread_abort+0x168>)
 8004024:	4949      	ldr	r1, [pc, #292]	; (800414c <z_thread_abort+0x178>)
 8004026:	4847      	ldr	r0, [pc, #284]	; (8004144 <z_thread_abort+0x170>)
 8004028:	23c2      	movs	r3, #194	; 0xc2
 800402a:	f000 fd6c 	bl	8004b06 <assert_print>
 800402e:	4942      	ldr	r1, [pc, #264]	; (8004138 <z_thread_abort+0x164>)
 8004030:	4847      	ldr	r0, [pc, #284]	; (8004150 <z_thread_abort+0x17c>)
 8004032:	f000 fd68 	bl	8004b06 <assert_print>
 8004036:	21c2      	movs	r1, #194	; 0xc2
 8004038:	e7e6      	b.n	8004008 <z_thread_abort+0x34>
	__asm__ volatile(
 800403a:	f386 8811 	msr	BASEPRI, r6
 800403e:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&sched_spinlock, key);
		__ASSERT(false, "aborting essential thread %p", thread);
 8004042:	4a44      	ldr	r2, [pc, #272]	; (8004154 <z_thread_abort+0x180>)
 8004044:	4944      	ldr	r1, [pc, #272]	; (8004158 <z_thread_abort+0x184>)
 8004046:	483f      	ldr	r0, [pc, #252]	; (8004144 <z_thread_abort+0x170>)
 8004048:	f240 63c3 	movw	r3, #1731	; 0x6c3
 800404c:	f000 fd5b 	bl	8004b06 <assert_print>
 8004050:	4621      	mov	r1, r4
 8004052:	4842      	ldr	r0, [pc, #264]	; (800415c <z_thread_abort+0x188>)
 8004054:	f000 fd57 	bl	8004b06 <assert_print>
 8004058:	f240 61c3 	movw	r1, #1731	; 0x6c3
	}
#endif
	end_thread(thread);
	if (thread == _current && !arch_is_in_isr()) {
		z_swap(&sched_spinlock, key);
		__ASSERT(false, "aborted _current back from dead");
 800405c:	483d      	ldr	r0, [pc, #244]	; (8004154 <z_thread_abort+0x180>)
 800405e:	e7d4      	b.n	800400a <z_thread_abort+0x36>
	if ((thread->base.thread_state & _THREAD_DEAD) != 0U) {
 8004060:	7b63      	ldrb	r3, [r4, #13]
 8004062:	071a      	lsls	r2, r3, #28
 8004064:	d50a      	bpl.n	800407c <z_thread_abort+0xa8>
 8004066:	4834      	ldr	r0, [pc, #208]	; (8004138 <z_thread_abort+0x164>)
 8004068:	f7fe fce2 	bl	8002a30 <z_spin_unlock_valid>
 800406c:	2800      	cmp	r0, #0
 800406e:	d0d8      	beq.n	8004022 <z_thread_abort+0x4e>
 8004070:	f386 8811 	msr	BASEPRI, r6
 8004074:	f3bf 8f6f 	isb	sy
	}
	k_spin_unlock(&sched_spinlock, key);
}
 8004078:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		thread->base.thread_state &= ~_THREAD_ABORTING;
 800407c:	f023 0220 	bic.w	r2, r3, #32
 8004080:	f042 0108 	orr.w	r1, r2, #8
		if (z_is_thread_queued(thread)) {
 8004084:	09d2      	lsrs	r2, r2, #7
 8004086:	d12f      	bne.n	80040e8 <z_thread_abort+0x114>
		thread->base.thread_state &= ~_THREAD_ABORTING;
 8004088:	7361      	strb	r1, [r4, #13]
		if (thread->base.pended_on != NULL) {
 800408a:	68a3      	ldr	r3, [r4, #8]
 800408c:	b113      	cbz	r3, 8004094 <z_thread_abort+0xc0>
			unpend_thread_no_timeout(thread);
 800408e:	4620      	mov	r0, r4
 8004090:	f7ff fa10 	bl	80034b4 <unpend_thread_no_timeout>
	return z_abort_timeout(&thread->base.timeout);
 8004094:	f104 0018 	add.w	r0, r4, #24
 8004098:	f000 f996 	bl	80043c8 <z_abort_timeout>
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
 800409c:	f104 0758 	add.w	r7, r4, #88	; 0x58
 80040a0:	f04f 0800 	mov.w	r8, #0
	return list->head == list;
 80040a4:	6da5      	ldr	r5, [r4, #88]	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
 80040a6:	42bd      	cmp	r5, r7
 80040a8:	d000      	beq.n	80040ac <z_thread_abort+0xd8>
	while ((thread = z_waitq_head(wait_q)) != NULL) {
 80040aa:	bb3d      	cbnz	r5, 80040fc <z_thread_abort+0x128>
		update_cache(1);
 80040ac:	2001      	movs	r0, #1
 80040ae:	f7ff f82d 	bl	800310c <update_cache>
		z_thread_monitor_exit(thread);
 80040b2:	4620      	mov	r0, r4
 80040b4:	f7fe fcd4 	bl	8002a60 <z_thread_monitor_exit>
	if (thread == _current && !arch_is_in_isr()) {
 80040b8:	4b29      	ldr	r3, [pc, #164]	; (8004160 <z_thread_abort+0x18c>)
 80040ba:	689b      	ldr	r3, [r3, #8]
 80040bc:	42a3      	cmp	r3, r4
 80040be:	d1d2      	bne.n	8004066 <z_thread_abort+0x92>
 80040c0:	f3ef 8305 	mrs	r3, IPSR
 80040c4:	2b00      	cmp	r3, #0
 80040c6:	d1ce      	bne.n	8004066 <z_thread_abort+0x92>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80040c8:	481b      	ldr	r0, [pc, #108]	; (8004138 <z_thread_abort+0x164>)
 80040ca:	f7fe fcb1 	bl	8002a30 <z_spin_unlock_valid>
 80040ce:	bb10      	cbnz	r0, 8004116 <z_thread_abort+0x142>
 80040d0:	4a1a      	ldr	r2, [pc, #104]	; (800413c <z_thread_abort+0x168>)
 80040d2:	491e      	ldr	r1, [pc, #120]	; (800414c <z_thread_abort+0x178>)
 80040d4:	481b      	ldr	r0, [pc, #108]	; (8004144 <z_thread_abort+0x170>)
 80040d6:	23e1      	movs	r3, #225	; 0xe1
 80040d8:	f000 fd15 	bl	8004b06 <assert_print>
 80040dc:	4916      	ldr	r1, [pc, #88]	; (8004138 <z_thread_abort+0x164>)
 80040de:	481c      	ldr	r0, [pc, #112]	; (8004150 <z_thread_abort+0x17c>)
 80040e0:	f000 fd11 	bl	8004b06 <assert_print>
 80040e4:	21e1      	movs	r1, #225	; 0xe1
 80040e6:	e78f      	b.n	8004008 <z_thread_abort+0x34>
	thread->base.thread_state &= ~_THREAD_QUEUED;
 80040e8:	f003 035f 	and.w	r3, r3, #95	; 0x5f
 80040ec:	f043 0308 	orr.w	r3, r3, #8
	_priq_run_remove(thread_runq(thread), thread);
 80040f0:	481c      	ldr	r0, [pc, #112]	; (8004164 <z_thread_abort+0x190>)
	thread->base.thread_state &= ~_THREAD_QUEUED;
 80040f2:	7363      	strb	r3, [r4, #13]
	_priq_run_remove(thread_runq(thread), thread);
 80040f4:	4621      	mov	r1, r4
 80040f6:	f7ff fb9d 	bl	8003834 <z_priq_rb_remove>
}
 80040fa:	e7c6      	b.n	800408a <z_thread_abort+0xb6>
		unpend_thread_no_timeout(thread);
 80040fc:	4628      	mov	r0, r5
 80040fe:	f7ff f9d9 	bl	80034b4 <unpend_thread_no_timeout>
 8004102:	f105 0018 	add.w	r0, r5, #24
 8004106:	f000 f95f 	bl	80043c8 <z_abort_timeout>
 800410a:	f8c5 80ac 	str.w	r8, [r5, #172]	; 0xac
		ready_thread(thread);
 800410e:	4628      	mov	r0, r5
 8004110:	f7ff fa86 	bl	8003620 <ready_thread>
 8004114:	e7c6      	b.n	80040a4 <z_thread_abort+0xd0>
 8004116:	4630      	mov	r0, r6
 8004118:	f7fd f8f4 	bl	8001304 <arch_swap>
		__ASSERT(false, "aborted _current back from dead");
 800411c:	490e      	ldr	r1, [pc, #56]	; (8004158 <z_thread_abort+0x184>)
 800411e:	4a0d      	ldr	r2, [pc, #52]	; (8004154 <z_thread_abort+0x180>)
 8004120:	4808      	ldr	r0, [pc, #32]	; (8004144 <z_thread_abort+0x170>)
 8004122:	f240 63f2 	movw	r3, #1778	; 0x6f2
 8004126:	f000 fcee 	bl	8004b06 <assert_print>
 800412a:	480f      	ldr	r0, [pc, #60]	; (8004168 <z_thread_abort+0x194>)
 800412c:	f000 fceb 	bl	8004b06 <assert_print>
 8004130:	f240 61f2 	movw	r1, #1778	; 0x6f2
 8004134:	e792      	b.n	800405c <z_thread_abort+0x88>
 8004136:	bf00      	nop
 8004138:	200007fc 	.word	0x200007fc
 800413c:	080061b7 	.word	0x080061b7
 8004140:	080061e4 	.word	0x080061e4
 8004144:	08005ca7 	.word	0x08005ca7
 8004148:	080061f9 	.word	0x080061f9
 800414c:	08006211 	.word	0x08006211
 8004150:	08006228 	.word	0x08006228
 8004154:	08006559 	.word	0x08006559
 8004158:	080064f9 	.word	0x080064f9
 800415c:	080066e1 	.word	0x080066e1
 8004160:	200007b8 	.word	0x200007b8
 8004164:	200007d4 	.word	0x200007d4
 8004168:	08006700 	.word	0x08006700

0800416c <z_data_copy>:
 * @brief Copy the data section from ROM to RAM
 *
 * This routine copies the data section from ROM to RAM.
 */
void z_data_copy(void)
{
 800416c:	b508      	push	{r3, lr}
	z_early_memcpy(&__data_region_start, &__data_region_load_start,
		       __data_region_end - __data_region_start);
 800416e:	4806      	ldr	r0, [pc, #24]	; (8004188 <z_data_copy+0x1c>)
	z_early_memcpy(&__data_region_start, &__data_region_load_start,
 8004170:	4a06      	ldr	r2, [pc, #24]	; (800418c <z_data_copy+0x20>)
 8004172:	4907      	ldr	r1, [pc, #28]	; (8004190 <z_data_copy+0x24>)
 8004174:	1a12      	subs	r2, r2, r0
 8004176:	f001 f891 	bl	800529c <z_early_memcpy>
#else
	z_early_memcpy(&_app_smem_start, &_app_smem_rom_start,
		       _app_smem_end - _app_smem_start);
#endif /* CONFIG_STACK_CANARIES */
#endif /* CONFIG_USERSPACE */
}
 800417a:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_early_memcpy(&__ramfunc_start, &__ramfunc_load_start,
 800417e:	4a05      	ldr	r2, [pc, #20]	; (8004194 <z_data_copy+0x28>)
 8004180:	4905      	ldr	r1, [pc, #20]	; (8004198 <z_data_copy+0x2c>)
 8004182:	4806      	ldr	r0, [pc, #24]	; (800419c <z_data_copy+0x30>)
 8004184:	f001 b88a 	b.w	800529c <z_early_memcpy>
 8004188:	20000000 	.word	0x20000000
 800418c:	2000005c 	.word	0x2000005c
 8004190:	080067a8 	.word	0x080067a8
 8004194:	00000000 	.word	0x00000000
 8004198:	080067a8 	.word	0x080067a8
 800419c:	20000000 	.word	0x20000000

080041a0 <elapsed>:
	sys_dlist_remove(&t->node);
}

static int32_t elapsed(void)
{
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
 80041a0:	4b03      	ldr	r3, [pc, #12]	; (80041b0 <elapsed+0x10>)
 80041a2:	681b      	ldr	r3, [r3, #0]
 80041a4:	b90b      	cbnz	r3, 80041aa <elapsed+0xa>
 80041a6:	f7fe b9a7 	b.w	80024f8 <sys_clock_elapsed>
}
 80041aa:	2000      	movs	r0, #0
 80041ac:	4770      	bx	lr
 80041ae:	bf00      	nop
 80041b0:	20000800 	.word	0x20000800

080041b4 <next_timeout>:

static int32_t next_timeout(void)
{
 80041b4:	b510      	push	{r4, lr}
	return list->head == list;
 80041b6:	4b11      	ldr	r3, [pc, #68]	; (80041fc <next_timeout+0x48>)
 80041b8:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
 80041ba:	429c      	cmp	r4, r3
 80041bc:	d10a      	bne.n	80041d4 <next_timeout+0x20>
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
 80041be:	f7ff ffef 	bl	80041a0 <elapsed>
	int32_t ret;

	if ((to == NULL) ||
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
		ret = MAX_WAIT;
 80041c2:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
	} else {
		ret = MAX(0, to->dticks - ticks_elapsed);
	}

#ifdef CONFIG_TIMESLICING
	if (_current_cpu->slice_ticks && _current_cpu->slice_ticks < ret) {
 80041c6:	4b0e      	ldr	r3, [pc, #56]	; (8004200 <next_timeout+0x4c>)
 80041c8:	691b      	ldr	r3, [r3, #16]
 80041ca:	b113      	cbz	r3, 80041d2 <next_timeout+0x1e>
 80041cc:	4298      	cmp	r0, r3
 80041ce:	bfa8      	it	ge
 80041d0:	4618      	movge	r0, r3
		ret = _current_cpu->slice_ticks;
	}
#endif
	return ret;
}
 80041d2:	bd10      	pop	{r4, pc}
	int32_t ticks_elapsed = elapsed();
 80041d4:	f7ff ffe4 	bl	80041a0 <elapsed>
	if ((to == NULL) ||
 80041d8:	2c00      	cmp	r4, #0
 80041da:	d0f2      	beq.n	80041c2 <next_timeout+0xe>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
 80041dc:	e9d4 3204 	ldrd	r3, r2, [r4, #16]
 80041e0:	1a1b      	subs	r3, r3, r0
 80041e2:	eb62 72e0 	sbc.w	r2, r2, r0, asr #31
	if ((to == NULL) ||
 80041e6:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
 80041ea:	f172 0100 	sbcs.w	r1, r2, #0
 80041ee:	dae8      	bge.n	80041c2 <next_timeout+0xe>
		ret = MAX(0, to->dticks - ticks_elapsed);
 80041f0:	2a00      	cmp	r2, #0
 80041f2:	bfac      	ite	ge
 80041f4:	4618      	movge	r0, r3
 80041f6:	2000      	movlt	r0, #0
 80041f8:	e7e5      	b.n	80041c6 <next_timeout+0x12>
 80041fa:	bf00      	nop
 80041fc:	2000003c 	.word	0x2000003c
 8004200:	200007b8 	.word	0x200007b8

08004204 <remove_timeout>:
{
 8004204:	b530      	push	{r4, r5, lr}
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
 8004206:	b170      	cbz	r0, 8004226 <remove_timeout+0x22>
	return (node == list->tail) ? NULL : node->next;
 8004208:	4b0b      	ldr	r3, [pc, #44]	; (8004238 <remove_timeout+0x34>)
 800420a:	685b      	ldr	r3, [r3, #4]
 800420c:	4298      	cmp	r0, r3
 800420e:	d00a      	beq.n	8004226 <remove_timeout+0x22>
 8004210:	6803      	ldr	r3, [r0, #0]
	if (next(t) != NULL) {
 8004212:	b143      	cbz	r3, 8004226 <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
 8004214:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
 8004218:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
 800421c:	1912      	adds	r2, r2, r4
 800421e:	eb41 0105 	adc.w	r1, r1, r5
 8004222:	e9c3 2104 	strd	r2, r1, [r3, #16]
	sys_dnode_t *const next = node->next;
 8004226:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
 800422a:	6013      	str	r3, [r2, #0]
	next->prev = prev;
 800422c:	605a      	str	r2, [r3, #4]
	node->next = NULL;
 800422e:	2300      	movs	r3, #0
	node->prev = NULL;
 8004230:	e9c0 3300 	strd	r3, r3, [r0]
}
 8004234:	bd30      	pop	{r4, r5, pc}
 8004236:	bf00      	nop
 8004238:	2000003c 	.word	0x2000003c

0800423c <z_add_timeout>:

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
 800423c:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
 8004240:	bf08      	it	eq
 8004242:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
{
 8004246:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
 800424a:	4604      	mov	r4, r0
 800424c:	4692      	mov	sl, r2
 800424e:	461d      	mov	r5, r3
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
 8004250:	f000 809e 	beq.w	8004390 <z_add_timeout+0x154>
	return node->next != NULL;
 8004254:	6806      	ldr	r6, [r0, #0]

#ifdef CONFIG_KERNEL_COHERENCE
	__ASSERT_NO_MSG(arch_mem_coherent(to));
#endif

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
 8004256:	b166      	cbz	r6, 8004272 <z_add_timeout+0x36>
 8004258:	494e      	ldr	r1, [pc, #312]	; (8004394 <z_add_timeout+0x158>)
 800425a:	4a4f      	ldr	r2, [pc, #316]	; (8004398 <z_add_timeout+0x15c>)
 800425c:	484f      	ldr	r0, [pc, #316]	; (800439c <z_add_timeout+0x160>)
 800425e:	2363      	movs	r3, #99	; 0x63
 8004260:	f000 fc51 	bl	8004b06 <assert_print>
 8004264:	484e      	ldr	r0, [pc, #312]	; (80043a0 <z_add_timeout+0x164>)
 8004266:	f000 fc4e 	bl	8004b06 <assert_print>
 800426a:	484b      	ldr	r0, [pc, #300]	; (8004398 <z_add_timeout+0x15c>)
 800426c:	2163      	movs	r1, #99	; 0x63
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 800426e:	f000 fc43 	bl	8004af8 <assert_post_action>
	to->fn = fn;
 8004272:	6081      	str	r1, [r0, #8]
	__asm__ volatile(
 8004274:	f04f 0310 	mov.w	r3, #16
 8004278:	f3ef 8711 	mrs	r7, BASEPRI
 800427c:	f383 8812 	msr	BASEPRI_MAX, r3
 8004280:	f3bf 8f6f 	isb	sy
 8004284:	4847      	ldr	r0, [pc, #284]	; (80043a4 <z_add_timeout+0x168>)
 8004286:	f7fe fbc5 	bl	8002a14 <z_spin_lock_valid>
 800428a:	b960      	cbnz	r0, 80042a6 <z_add_timeout+0x6a>
 800428c:	4a46      	ldr	r2, [pc, #280]	; (80043a8 <z_add_timeout+0x16c>)
 800428e:	4947      	ldr	r1, [pc, #284]	; (80043ac <z_add_timeout+0x170>)
 8004290:	4842      	ldr	r0, [pc, #264]	; (800439c <z_add_timeout+0x160>)
 8004292:	2394      	movs	r3, #148	; 0x94
 8004294:	f000 fc37 	bl	8004b06 <assert_print>
 8004298:	4942      	ldr	r1, [pc, #264]	; (80043a4 <z_add_timeout+0x168>)
 800429a:	4845      	ldr	r0, [pc, #276]	; (80043b0 <z_add_timeout+0x174>)
 800429c:	f000 fc33 	bl	8004b06 <assert_print>
 80042a0:	2194      	movs	r1, #148	; 0x94
 80042a2:	4841      	ldr	r0, [pc, #260]	; (80043a8 <z_add_timeout+0x16c>)
 80042a4:	e7e3      	b.n	800426e <z_add_timeout+0x32>
	z_spin_lock_set_owner(l);
 80042a6:	483f      	ldr	r0, [pc, #252]	; (80043a4 <z_add_timeout+0x168>)
 80042a8:	f7fe fbd2 	bl	8002a50 <z_spin_lock_set_owner>

	LOCKED(&timeout_lock) {
		struct _timeout *t;

		if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) &&
 80042ac:	f1ba 3fff 	cmp.w	sl, #4294967295	; 0xffffffff
 80042b0:	f175 33ff 	sbcs.w	r3, r5, #4294967295	; 0xffffffff
 80042b4:	da23      	bge.n	80042fe <z_add_timeout+0xc2>
		    Z_TICK_ABS(timeout.ticks) >= 0) {
			k_ticks_t ticks = Z_TICK_ABS(timeout.ticks) - curr_tick;
 80042b6:	493f      	ldr	r1, [pc, #252]	; (80043b4 <z_add_timeout+0x178>)
 80042b8:	e9d1 2000 	ldrd	r2, r0, [r1]
 80042bc:	f06f 0301 	mvn.w	r3, #1
 80042c0:	1a9b      	subs	r3, r3, r2
 80042c2:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
 80042c6:	eb62 0000 	sbc.w	r0, r2, r0
 80042ca:	ebb3 030a 	subs.w	r3, r3, sl
 80042ce:	eb60 0005 	sbc.w	r0, r0, r5

			to->dticks = MAX(1, ticks);
 80042d2:	2b01      	cmp	r3, #1
 80042d4:	f170 0200 	sbcs.w	r2, r0, #0
 80042d8:	da01      	bge.n	80042de <z_add_timeout+0xa2>
 80042da:	2301      	movs	r3, #1
 80042dc:	4630      	mov	r0, r6
 80042de:	e9c4 3004 	strd	r3, r0, [r4, #16]
	return list->head == list;
 80042e2:	4b35      	ldr	r3, [pc, #212]	; (80043b8 <z_add_timeout+0x17c>)
 80042e4:	681a      	ldr	r2, [r3, #0]
	return (node == list->tail) ? NULL : node->next;
 80042e6:	f8d3 c004 	ldr.w	ip, [r3, #4]
	return sys_dlist_is_empty(list) ? NULL : list->head;
 80042ea:	429a      	cmp	r2, r3
 80042ec:	bf18      	it	ne
 80042ee:	4616      	movne	r6, r2
		} else {
			to->dticks = timeout.ticks + 1 + elapsed();
		}

		for (t = first(); t != NULL; t = next(t)) {
 80042f0:	b986      	cbnz	r6, 8004314 <z_add_timeout+0xd8>
	node->prev = tail;
 80042f2:	e9c4 3c00 	strd	r3, ip, [r4]
	tail->next = node;
 80042f6:	f8cc 4000 	str.w	r4, [ip]
	list->tail = node;
 80042fa:	605c      	str	r4, [r3, #4]
}
 80042fc:	e01c      	b.n	8004338 <z_add_timeout+0xfc>
			to->dticks = timeout.ticks + 1 + elapsed();
 80042fe:	f7ff ff4f 	bl	80041a0 <elapsed>
 8004302:	f11a 0801 	adds.w	r8, sl, #1
 8004306:	f145 0500 	adc.w	r5, r5, #0
 800430a:	eb18 0300 	adds.w	r3, r8, r0
 800430e:	eb45 70e0 	adc.w	r0, r5, r0, asr #31
 8004312:	e7e4      	b.n	80042de <z_add_timeout+0xa2>
			if (t->dticks > to->dticks) {
 8004314:	e9d6 1504 	ldrd	r1, r5, [r6, #16]
 8004318:	e9d4 2004 	ldrd	r2, r0, [r4, #16]
 800431c:	428a      	cmp	r2, r1
 800431e:	eb70 0e05 	sbcs.w	lr, r0, r5
 8004322:	da28      	bge.n	8004376 <z_add_timeout+0x13a>
				t->dticks -= to->dticks;
 8004324:	1a89      	subs	r1, r1, r2
	sys_dnode_t *const prev = successor->prev;
 8004326:	6872      	ldr	r2, [r6, #4]
 8004328:	eb65 0500 	sbc.w	r5, r5, r0
 800432c:	e9c6 1504 	strd	r1, r5, [r6, #16]
	node->next = successor;
 8004330:	e9c4 6200 	strd	r6, r2, [r4]
	prev->next = node;
 8004334:	6014      	str	r4, [r2, #0]
	successor->prev = node;
 8004336:	6074      	str	r4, [r6, #4]
	return list->head == list;
 8004338:	681a      	ldr	r2, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
 800433a:	429a      	cmp	r2, r3
 800433c:	d00b      	beq.n	8004356 <z_add_timeout+0x11a>

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first()) {
 800433e:	4294      	cmp	r4, r2
 8004340:	d109      	bne.n	8004356 <z_add_timeout+0x11a>
			 * last announcement, and slice_ticks is based
			 * on that. It means that the time remaining for
			 * the next announcement can be less than
			 * slice_ticks.
			 */
			int32_t next_time = next_timeout();
 8004342:	f7ff ff37 	bl	80041b4 <next_timeout>

			if (next_time == 0 ||
 8004346:	b118      	cbz	r0, 8004350 <z_add_timeout+0x114>
			    _current_cpu->slice_ticks != next_time) {
 8004348:	4b1c      	ldr	r3, [pc, #112]	; (80043bc <z_add_timeout+0x180>)
			if (next_time == 0 ||
 800434a:	691b      	ldr	r3, [r3, #16]
 800434c:	4283      	cmp	r3, r0
 800434e:	d002      	beq.n	8004356 <z_add_timeout+0x11a>
				sys_clock_set_timeout(next_time, false);
 8004350:	2100      	movs	r1, #0
 8004352:	f7fe f82f 	bl	80023b4 <sys_clock_set_timeout>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004356:	4813      	ldr	r0, [pc, #76]	; (80043a4 <z_add_timeout+0x168>)
 8004358:	f7fe fb6a 	bl	8002a30 <z_spin_unlock_valid>
 800435c:	b9a0      	cbnz	r0, 8004388 <z_add_timeout+0x14c>
 800435e:	4a12      	ldr	r2, [pc, #72]	; (80043a8 <z_add_timeout+0x16c>)
 8004360:	4917      	ldr	r1, [pc, #92]	; (80043c0 <z_add_timeout+0x184>)
 8004362:	480e      	ldr	r0, [pc, #56]	; (800439c <z_add_timeout+0x160>)
 8004364:	23c2      	movs	r3, #194	; 0xc2
 8004366:	f000 fbce 	bl	8004b06 <assert_print>
 800436a:	490e      	ldr	r1, [pc, #56]	; (80043a4 <z_add_timeout+0x168>)
 800436c:	4815      	ldr	r0, [pc, #84]	; (80043c4 <z_add_timeout+0x188>)
 800436e:	f000 fbca 	bl	8004b06 <assert_print>
 8004372:	21c2      	movs	r1, #194	; 0xc2
 8004374:	e795      	b.n	80042a2 <z_add_timeout+0x66>
			to->dticks -= t->dticks;
 8004376:	1a52      	subs	r2, r2, r1
 8004378:	eb60 0005 	sbc.w	r0, r0, r5
	return (node == list->tail) ? NULL : node->next;
 800437c:	4566      	cmp	r6, ip
 800437e:	e9c4 2004 	strd	r2, r0, [r4, #16]
 8004382:	d0b6      	beq.n	80042f2 <z_add_timeout+0xb6>
 8004384:	6836      	ldr	r6, [r6, #0]
 8004386:	e7b3      	b.n	80042f0 <z_add_timeout+0xb4>
	__asm__ volatile(
 8004388:	f387 8811 	msr	BASEPRI, r7
 800438c:	f3bf 8f6f 	isb	sy
#else
			sys_clock_set_timeout(next_timeout(), false);
#endif	/* CONFIG_TIMESLICING */
		}
	}
}
 8004390:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 8004394:	08006746 	.word	0x08006746
 8004398:	08006722 	.word	0x08006722
 800439c:	08005ca7 	.word	0x08005ca7
 80043a0:	080065a2 	.word	0x080065a2
 80043a4:	20000804 	.word	0x20000804
 80043a8:	080061b7 	.word	0x080061b7
 80043ac:	080061e4 	.word	0x080061e4
 80043b0:	080061f9 	.word	0x080061f9
 80043b4:	200005e0 	.word	0x200005e0
 80043b8:	2000003c 	.word	0x2000003c
 80043bc:	200007b8 	.word	0x200007b8
 80043c0:	08006211 	.word	0x08006211
 80043c4:	08006228 	.word	0x08006228

080043c8 <z_abort_timeout>:

int z_abort_timeout(struct _timeout *to)
{
 80043c8:	b538      	push	{r3, r4, r5, lr}
 80043ca:	4604      	mov	r4, r0
	__asm__ volatile(
 80043cc:	f04f 0310 	mov.w	r3, #16
 80043d0:	f3ef 8511 	mrs	r5, BASEPRI
 80043d4:	f383 8812 	msr	BASEPRI_MAX, r3
 80043d8:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 80043dc:	4819      	ldr	r0, [pc, #100]	; (8004444 <z_abort_timeout+0x7c>)
 80043de:	f7fe fb19 	bl	8002a14 <z_spin_lock_valid>
 80043e2:	b968      	cbnz	r0, 8004400 <z_abort_timeout+0x38>
 80043e4:	4a18      	ldr	r2, [pc, #96]	; (8004448 <z_abort_timeout+0x80>)
 80043e6:	4919      	ldr	r1, [pc, #100]	; (800444c <z_abort_timeout+0x84>)
 80043e8:	4819      	ldr	r0, [pc, #100]	; (8004450 <z_abort_timeout+0x88>)
 80043ea:	2394      	movs	r3, #148	; 0x94
 80043ec:	f000 fb8b 	bl	8004b06 <assert_print>
 80043f0:	4914      	ldr	r1, [pc, #80]	; (8004444 <z_abort_timeout+0x7c>)
 80043f2:	4818      	ldr	r0, [pc, #96]	; (8004454 <z_abort_timeout+0x8c>)
 80043f4:	f000 fb87 	bl	8004b06 <assert_print>
 80043f8:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80043fa:	4813      	ldr	r0, [pc, #76]	; (8004448 <z_abort_timeout+0x80>)
 80043fc:	f000 fb7c 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 8004400:	4810      	ldr	r0, [pc, #64]	; (8004444 <z_abort_timeout+0x7c>)
 8004402:	f7fe fb25 	bl	8002a50 <z_spin_lock_set_owner>
	int ret = -EINVAL;

	LOCKED(&timeout_lock) {
		if (sys_dnode_is_linked(&to->node)) {
 8004406:	6823      	ldr	r3, [r4, #0]
 8004408:	b19b      	cbz	r3, 8004432 <z_abort_timeout+0x6a>
			remove_timeout(to);
 800440a:	4620      	mov	r0, r4
 800440c:	f7ff fefa 	bl	8004204 <remove_timeout>
			ret = 0;
 8004410:	2400      	movs	r4, #0
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004412:	480c      	ldr	r0, [pc, #48]	; (8004444 <z_abort_timeout+0x7c>)
 8004414:	f7fe fb0c 	bl	8002a30 <z_spin_unlock_valid>
 8004418:	b970      	cbnz	r0, 8004438 <z_abort_timeout+0x70>
 800441a:	4a0b      	ldr	r2, [pc, #44]	; (8004448 <z_abort_timeout+0x80>)
 800441c:	490e      	ldr	r1, [pc, #56]	; (8004458 <z_abort_timeout+0x90>)
 800441e:	480c      	ldr	r0, [pc, #48]	; (8004450 <z_abort_timeout+0x88>)
 8004420:	23c2      	movs	r3, #194	; 0xc2
 8004422:	f000 fb70 	bl	8004b06 <assert_print>
 8004426:	4907      	ldr	r1, [pc, #28]	; (8004444 <z_abort_timeout+0x7c>)
 8004428:	480c      	ldr	r0, [pc, #48]	; (800445c <z_abort_timeout+0x94>)
 800442a:	f000 fb6c 	bl	8004b06 <assert_print>
 800442e:	21c2      	movs	r1, #194	; 0xc2
 8004430:	e7e3      	b.n	80043fa <z_abort_timeout+0x32>
	int ret = -EINVAL;
 8004432:	f06f 0415 	mvn.w	r4, #21
 8004436:	e7ec      	b.n	8004412 <z_abort_timeout+0x4a>
	__asm__ volatile(
 8004438:	f385 8811 	msr	BASEPRI, r5
 800443c:	f3bf 8f6f 	isb	sy
		}
	}

	return ret;
}
 8004440:	4620      	mov	r0, r4
 8004442:	bd38      	pop	{r3, r4, r5, pc}
 8004444:	20000804 	.word	0x20000804
 8004448:	080061b7 	.word	0x080061b7
 800444c:	080061e4 	.word	0x080061e4
 8004450:	08005ca7 	.word	0x08005ca7
 8004454:	080061f9 	.word	0x080061f9
 8004458:	08006211 	.word	0x08006211
 800445c:	08006228 	.word	0x08006228

08004460 <z_set_timeout_expiry>:
	}
	return ret;
}

void z_set_timeout_expiry(int32_t ticks, bool is_idle)
{
 8004460:	b570      	push	{r4, r5, r6, lr}
 8004462:	4604      	mov	r4, r0
 8004464:	460d      	mov	r5, r1
	__asm__ volatile(
 8004466:	f04f 0310 	mov.w	r3, #16
 800446a:	f3ef 8611 	mrs	r6, BASEPRI
 800446e:	f383 8812 	msr	BASEPRI_MAX, r3
 8004472:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8004476:	481b      	ldr	r0, [pc, #108]	; (80044e4 <z_set_timeout_expiry+0x84>)
 8004478:	f7fe facc 	bl	8002a14 <z_spin_lock_valid>
 800447c:	b968      	cbnz	r0, 800449a <z_set_timeout_expiry+0x3a>
 800447e:	4a1a      	ldr	r2, [pc, #104]	; (80044e8 <z_set_timeout_expiry+0x88>)
 8004480:	491a      	ldr	r1, [pc, #104]	; (80044ec <z_set_timeout_expiry+0x8c>)
 8004482:	481b      	ldr	r0, [pc, #108]	; (80044f0 <z_set_timeout_expiry+0x90>)
 8004484:	2394      	movs	r3, #148	; 0x94
 8004486:	f000 fb3e 	bl	8004b06 <assert_print>
 800448a:	4916      	ldr	r1, [pc, #88]	; (80044e4 <z_set_timeout_expiry+0x84>)
 800448c:	4819      	ldr	r0, [pc, #100]	; (80044f4 <z_set_timeout_expiry+0x94>)
 800448e:	f000 fb3a 	bl	8004b06 <assert_print>
 8004492:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004494:	4814      	ldr	r0, [pc, #80]	; (80044e8 <z_set_timeout_expiry+0x88>)
 8004496:	f000 fb2f 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 800449a:	4812      	ldr	r0, [pc, #72]	; (80044e4 <z_set_timeout_expiry+0x84>)
 800449c:	f7fe fad8 	bl	8002a50 <z_spin_lock_set_owner>
	LOCKED(&timeout_lock) {
		int next_to = next_timeout();
 80044a0:	f7ff fe88 	bl	80041b4 <next_timeout>
		bool sooner = (next_to == K_TICKS_FOREVER)
			      || (ticks <= next_to);
 80044a4:	2801      	cmp	r0, #1
 80044a6:	dd07      	ble.n	80044b8 <z_set_timeout_expiry+0x58>
 80044a8:	42a0      	cmp	r0, r4
 80044aa:	db05      	blt.n	80044b8 <z_set_timeout_expiry+0x58>
		 * know when context switches happen until interrupt
		 * exit and so can't get the timeslicing clamp folded
		 * in.
		 */
		if (!imminent && (sooner || IS_ENABLED(CONFIG_SMP))) {
			sys_clock_set_timeout(MIN(ticks, next_to), is_idle);
 80044ac:	42a0      	cmp	r0, r4
 80044ae:	4629      	mov	r1, r5
 80044b0:	bfa8      	it	ge
 80044b2:	4620      	movge	r0, r4
 80044b4:	f7fd ff7e 	bl	80023b4 <sys_clock_set_timeout>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 80044b8:	480a      	ldr	r0, [pc, #40]	; (80044e4 <z_set_timeout_expiry+0x84>)
 80044ba:	f7fe fab9 	bl	8002a30 <z_spin_unlock_valid>
 80044be:	b958      	cbnz	r0, 80044d8 <z_set_timeout_expiry+0x78>
 80044c0:	4a09      	ldr	r2, [pc, #36]	; (80044e8 <z_set_timeout_expiry+0x88>)
 80044c2:	490d      	ldr	r1, [pc, #52]	; (80044f8 <z_set_timeout_expiry+0x98>)
 80044c4:	480a      	ldr	r0, [pc, #40]	; (80044f0 <z_set_timeout_expiry+0x90>)
 80044c6:	23c2      	movs	r3, #194	; 0xc2
 80044c8:	f000 fb1d 	bl	8004b06 <assert_print>
 80044cc:	4905      	ldr	r1, [pc, #20]	; (80044e4 <z_set_timeout_expiry+0x84>)
 80044ce:	480b      	ldr	r0, [pc, #44]	; (80044fc <z_set_timeout_expiry+0x9c>)
 80044d0:	f000 fb19 	bl	8004b06 <assert_print>
 80044d4:	21c2      	movs	r1, #194	; 0xc2
 80044d6:	e7dd      	b.n	8004494 <z_set_timeout_expiry+0x34>
	__asm__ volatile(
 80044d8:	f386 8811 	msr	BASEPRI, r6
 80044dc:	f3bf 8f6f 	isb	sy
		}
	}
}
 80044e0:	bd70      	pop	{r4, r5, r6, pc}
 80044e2:	bf00      	nop
 80044e4:	20000804 	.word	0x20000804
 80044e8:	080061b7 	.word	0x080061b7
 80044ec:	080061e4 	.word	0x080061e4
 80044f0:	08005ca7 	.word	0x08005ca7
 80044f4:	080061f9 	.word	0x080061f9
 80044f8:	08006211 	.word	0x08006211
 80044fc:	08006228 	.word	0x08006228

08004500 <sys_clock_announce>:

void sys_clock_announce(int32_t ticks)
{
 8004500:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
 8004504:	4604      	mov	r4, r0
#ifdef CONFIG_TIMESLICING
	z_time_slice(ticks);
 8004506:	f7ff f9d9 	bl	80038bc <z_time_slice>
	__asm__ volatile(
 800450a:	f04f 0310 	mov.w	r3, #16
 800450e:	f3ef 8711 	mrs	r7, BASEPRI
 8004512:	f383 8812 	msr	BASEPRI_MAX, r3
 8004516:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 800451a:	483f      	ldr	r0, [pc, #252]	; (8004618 <sys_clock_announce+0x118>)
 800451c:	f7fe fa7a 	bl	8002a14 <z_spin_lock_valid>
 8004520:	b968      	cbnz	r0, 800453e <sys_clock_announce+0x3e>
 8004522:	4a3e      	ldr	r2, [pc, #248]	; (800461c <sys_clock_announce+0x11c>)
 8004524:	493e      	ldr	r1, [pc, #248]	; (8004620 <sys_clock_announce+0x120>)
 8004526:	483f      	ldr	r0, [pc, #252]	; (8004624 <sys_clock_announce+0x124>)
 8004528:	2394      	movs	r3, #148	; 0x94
 800452a:	f000 faec 	bl	8004b06 <assert_print>
 800452e:	493a      	ldr	r1, [pc, #232]	; (8004618 <sys_clock_announce+0x118>)
 8004530:	483d      	ldr	r0, [pc, #244]	; (8004628 <sys_clock_announce+0x128>)
 8004532:	f000 fae8 	bl	8004b06 <assert_print>
 8004536:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004538:	4838      	ldr	r0, [pc, #224]	; (800461c <sys_clock_announce+0x11c>)
 800453a:	f000 fadd 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 800453e:	4836      	ldr	r0, [pc, #216]	; (8004618 <sys_clock_announce+0x118>)
		announce_remaining += ticks;
		k_spin_unlock(&timeout_lock, key);
		return;
	}

	announce_remaining = ticks;
 8004540:	f8df 80e8 	ldr.w	r8, [pc, #232]	; 800462c <sys_clock_announce+0x12c>
	return list->head == list;
 8004544:	f8df 90e8 	ldr.w	r9, [pc, #232]	; 8004630 <sys_clock_announce+0x130>
 8004548:	f7fe fa82 	bl	8002a50 <z_spin_lock_set_owner>
 800454c:	f8d9 5000 	ldr.w	r5, [r9]

	while (first() != NULL && first()->dticks <= announce_remaining) {
		struct _timeout *t = first();
		int dt = t->dticks;

		curr_tick += dt;
 8004550:	4a38      	ldr	r2, [pc, #224]	; (8004634 <sys_clock_announce+0x134>)
	announce_remaining = ticks;
 8004552:	f8c8 4000 	str.w	r4, [r8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
 8004556:	454d      	cmp	r5, r9
		curr_tick += dt;
 8004558:	e9d2 3c00 	ldrd	r3, ip, [r2]
 800455c:	ea4f 71e4 	mov.w	r1, r4, asr #31
 8004560:	d00b      	beq.n	800457a <sys_clock_announce+0x7a>
	while (first() != NULL && first()->dticks <= announce_remaining) {
 8004562:	b155      	cbz	r5, 800457a <sys_clock_announce+0x7a>
 8004564:	e9d5 6004 	ldrd	r6, r0, [r5, #16]
 8004568:	42b4      	cmp	r4, r6
 800456a:	eb71 0e00 	sbcs.w	lr, r1, r0
 800456e:	da1b      	bge.n	80045a8 <sys_clock_announce+0xa8>
		key = k_spin_lock(&timeout_lock);
		announce_remaining -= dt;
	}

	if (first() != NULL) {
		first()->dticks -= announce_remaining;
 8004570:	1b36      	subs	r6, r6, r4
 8004572:	eb60 0001 	sbc.w	r0, r0, r1
 8004576:	e9c5 6004 	strd	r6, r0, [r5, #16]
	}

	curr_tick += announce_remaining;
 800457a:	18e3      	adds	r3, r4, r3
 800457c:	eb4c 0101 	adc.w	r1, ip, r1
	announce_remaining = 0;
 8004580:	2400      	movs	r4, #0
	curr_tick += announce_remaining;
 8004582:	e9c2 3100 	strd	r3, r1, [r2]
	announce_remaining = 0;
 8004586:	f8c8 4000 	str.w	r4, [r8]

	sys_clock_set_timeout(next_timeout(), false);
 800458a:	f7ff fe13 	bl	80041b4 <next_timeout>
 800458e:	4621      	mov	r1, r4
 8004590:	f7fd ff10 	bl	80023b4 <sys_clock_set_timeout>
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004594:	4820      	ldr	r0, [pc, #128]	; (8004618 <sys_clock_announce+0x118>)
 8004596:	f7fe fa4b 	bl	8002a30 <z_spin_unlock_valid>
 800459a:	b1a8      	cbz	r0, 80045c8 <sys_clock_announce+0xc8>
	__asm__ volatile(
 800459c:	f387 8811 	msr	BASEPRI, r7
 80045a0:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&timeout_lock, key);
}
 80045a4:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
		curr_tick += dt;
 80045a8:	18f3      	adds	r3, r6, r3
 80045aa:	eb4c 71e6 	adc.w	r1, ip, r6, asr #31
 80045ae:	e9c2 3100 	strd	r3, r1, [r2]
		t->dticks = 0;
 80045b2:	2200      	movs	r2, #0
 80045b4:	2300      	movs	r3, #0
		remove_timeout(t);
 80045b6:	4628      	mov	r0, r5
		t->dticks = 0;
 80045b8:	e9c5 2304 	strd	r2, r3, [r5, #16]
		remove_timeout(t);
 80045bc:	f7ff fe22 	bl	8004204 <remove_timeout>
 80045c0:	4815      	ldr	r0, [pc, #84]	; (8004618 <sys_clock_announce+0x118>)
 80045c2:	f7fe fa35 	bl	8002a30 <z_spin_unlock_valid>
 80045c6:	b958      	cbnz	r0, 80045e0 <sys_clock_announce+0xe0>
 80045c8:	4a14      	ldr	r2, [pc, #80]	; (800461c <sys_clock_announce+0x11c>)
 80045ca:	491b      	ldr	r1, [pc, #108]	; (8004638 <sys_clock_announce+0x138>)
 80045cc:	4815      	ldr	r0, [pc, #84]	; (8004624 <sys_clock_announce+0x124>)
 80045ce:	23c2      	movs	r3, #194	; 0xc2
 80045d0:	f000 fa99 	bl	8004b06 <assert_print>
 80045d4:	4910      	ldr	r1, [pc, #64]	; (8004618 <sys_clock_announce+0x118>)
 80045d6:	4819      	ldr	r0, [pc, #100]	; (800463c <sys_clock_announce+0x13c>)
 80045d8:	f000 fa95 	bl	8004b06 <assert_print>
 80045dc:	21c2      	movs	r1, #194	; 0xc2
 80045de:	e7ab      	b.n	8004538 <sys_clock_announce+0x38>
 80045e0:	f387 8811 	msr	BASEPRI, r7
 80045e4:	f3bf 8f6f 	isb	sy
		t->fn(t);
 80045e8:	68ab      	ldr	r3, [r5, #8]
 80045ea:	4628      	mov	r0, r5
 80045ec:	4798      	blx	r3
	__asm__ volatile(
 80045ee:	f04f 0310 	mov.w	r3, #16
 80045f2:	f3ef 8711 	mrs	r7, BASEPRI
 80045f6:	f383 8812 	msr	BASEPRI_MAX, r3
 80045fa:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 80045fe:	4806      	ldr	r0, [pc, #24]	; (8004618 <sys_clock_announce+0x118>)
 8004600:	f7fe fa08 	bl	8002a14 <z_spin_lock_valid>
 8004604:	2800      	cmp	r0, #0
 8004606:	d08c      	beq.n	8004522 <sys_clock_announce+0x22>
	z_spin_lock_set_owner(l);
 8004608:	4803      	ldr	r0, [pc, #12]	; (8004618 <sys_clock_announce+0x118>)
 800460a:	f7fe fa21 	bl	8002a50 <z_spin_lock_set_owner>
		announce_remaining -= dt;
 800460e:	f8d8 4000 	ldr.w	r4, [r8]
 8004612:	1ba4      	subs	r4, r4, r6
 8004614:	e79a      	b.n	800454c <sys_clock_announce+0x4c>
 8004616:	bf00      	nop
 8004618:	20000804 	.word	0x20000804
 800461c:	080061b7 	.word	0x080061b7
 8004620:	080061e4 	.word	0x080061e4
 8004624:	08005ca7 	.word	0x08005ca7
 8004628:	080061f9 	.word	0x080061f9
 800462c:	20000800 	.word	0x20000800
 8004630:	2000003c 	.word	0x2000003c
 8004634:	200005e0 	.word	0x200005e0
 8004638:	08006211 	.word	0x08006211
 800463c:	08006228 	.word	0x08006228

08004640 <sys_clock_tick_get>:

int64_t sys_clock_tick_get(void)
{
 8004640:	b570      	push	{r4, r5, r6, lr}
 8004642:	f04f 0310 	mov.w	r3, #16
 8004646:	f3ef 8611 	mrs	r6, BASEPRI
 800464a:	f383 8812 	msr	BASEPRI_MAX, r3
 800464e:	f3bf 8f6f 	isb	sy
	__ASSERT(z_spin_lock_valid(l), "Recursive spinlock %p", l);
 8004652:	481a      	ldr	r0, [pc, #104]	; (80046bc <sys_clock_tick_get+0x7c>)
 8004654:	f7fe f9de 	bl	8002a14 <z_spin_lock_valid>
 8004658:	b968      	cbnz	r0, 8004676 <sys_clock_tick_get+0x36>
 800465a:	4a19      	ldr	r2, [pc, #100]	; (80046c0 <sys_clock_tick_get+0x80>)
 800465c:	4919      	ldr	r1, [pc, #100]	; (80046c4 <sys_clock_tick_get+0x84>)
 800465e:	481a      	ldr	r0, [pc, #104]	; (80046c8 <sys_clock_tick_get+0x88>)
 8004660:	2394      	movs	r3, #148	; 0x94
 8004662:	f000 fa50 	bl	8004b06 <assert_print>
 8004666:	4915      	ldr	r1, [pc, #84]	; (80046bc <sys_clock_tick_get+0x7c>)
 8004668:	4818      	ldr	r0, [pc, #96]	; (80046cc <sys_clock_tick_get+0x8c>)
 800466a:	f000 fa4c 	bl	8004b06 <assert_print>
 800466e:	2194      	movs	r1, #148	; 0x94
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 8004670:	4813      	ldr	r0, [pc, #76]	; (80046c0 <sys_clock_tick_get+0x80>)
 8004672:	f000 fa41 	bl	8004af8 <assert_post_action>
	z_spin_lock_set_owner(l);
 8004676:	4811      	ldr	r0, [pc, #68]	; (80046bc <sys_clock_tick_get+0x7c>)
 8004678:	f7fe f9ea 	bl	8002a50 <z_spin_lock_set_owner>
	uint64_t t = 0U;

	LOCKED(&timeout_lock) {
		t = curr_tick + elapsed();
 800467c:	f7ff fd90 	bl	80041a0 <elapsed>
 8004680:	4a13      	ldr	r2, [pc, #76]	; (80046d0 <sys_clock_tick_get+0x90>)
 8004682:	e9d2 4500 	ldrd	r4, r5, [r2]
 8004686:	1904      	adds	r4, r0, r4
 8004688:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
	__ASSERT(z_spin_unlock_valid(l), "Not my spinlock %p", l);
 800468c:	480b      	ldr	r0, [pc, #44]	; (80046bc <sys_clock_tick_get+0x7c>)
 800468e:	f7fe f9cf 	bl	8002a30 <z_spin_unlock_valid>
 8004692:	b958      	cbnz	r0, 80046ac <sys_clock_tick_get+0x6c>
 8004694:	4a0a      	ldr	r2, [pc, #40]	; (80046c0 <sys_clock_tick_get+0x80>)
 8004696:	490f      	ldr	r1, [pc, #60]	; (80046d4 <sys_clock_tick_get+0x94>)
 8004698:	480b      	ldr	r0, [pc, #44]	; (80046c8 <sys_clock_tick_get+0x88>)
 800469a:	23c2      	movs	r3, #194	; 0xc2
 800469c:	f000 fa33 	bl	8004b06 <assert_print>
 80046a0:	4906      	ldr	r1, [pc, #24]	; (80046bc <sys_clock_tick_get+0x7c>)
 80046a2:	480d      	ldr	r0, [pc, #52]	; (80046d8 <sys_clock_tick_get+0x98>)
 80046a4:	f000 fa2f 	bl	8004b06 <assert_print>
 80046a8:	21c2      	movs	r1, #194	; 0xc2
 80046aa:	e7e1      	b.n	8004670 <sys_clock_tick_get+0x30>
	__asm__ volatile(
 80046ac:	f386 8811 	msr	BASEPRI, r6
 80046b0:	f3bf 8f6f 	isb	sy
	}
	return t;
}
 80046b4:	4620      	mov	r0, r4
 80046b6:	4629      	mov	r1, r5
 80046b8:	bd70      	pop	{r4, r5, r6, pc}
 80046ba:	bf00      	nop
 80046bc:	20000804 	.word	0x20000804
 80046c0:	080061b7 	.word	0x080061b7
 80046c4:	080061e4 	.word	0x080061e4
 80046c8:	08005ca7 	.word	0x08005ca7
 80046cc:	080061f9 	.word	0x080061f9
 80046d0:	200005e0 	.word	0x200005e0
 80046d4:	08006211 	.word	0x08006211
 80046d8:	08006228 	.word	0x08006228

080046dc <boot_banner>:
	printk("***** delaying boot " DELAY_STR "ms (per build configuration) *****\n");
	k_busy_wait(CONFIG_BOOT_DELAY * USEC_PER_MSEC);
#endif /* defined(CONFIG_BOOT_DELAY) && (CONFIG_BOOT_DELAY > 0) */

#if CONFIG_BOOT_BANNER
	printk("*** Booting Zephyr OS build " BANNER_VERSION BANNER_POSTFIX " ***\n");
 80046dc:	4801      	ldr	r0, [pc, #4]	; (80046e4 <boot_banner+0x8>)
 80046de:	f000 b820 	b.w	8004722 <printk>
 80046e2:	bf00      	nop
 80046e4:	08006766 	.word	0x08006766

080046e8 <_OffsetAbsSyms>:

#include <gen_offset.h>

#include "offsets_aarch32.c"

GEN_ABS_SYM_END
 80046e8:	4770      	bx	lr

080046ea <k_msleep.isra.0>:
	return k_sleep(Z_TIMEOUT_MS(ms));
 80046ea:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
			return t * ((uint64_t)to_hz / from_hz);
 80046ee:	210a      	movs	r1, #10
 80046f0:	fb80 0101 	smull	r0, r1, r0, r1
	return z_impl_k_sleep(timeout);
 80046f4:	f7ff bc36 	b.w	8003f64 <z_impl_k_sleep>

080046f8 <arch_printk_char_out>:
}
 80046f8:	2000      	movs	r0, #0
 80046fa:	4770      	bx	lr

080046fc <str_out>:
{
 80046fc:	b530      	push	{r4, r5, lr}
	if (ctx->str == NULL || ctx->count >= ctx->max) {
 80046fe:	688a      	ldr	r2, [r1, #8]
 8004700:	680c      	ldr	r4, [r1, #0]
		ctx->str[ctx->count++] = '\0';
 8004702:	1c55      	adds	r5, r2, #1
	if (ctx->str == NULL || ctx->count >= ctx->max) {
 8004704:	b114      	cbz	r4, 800470c <str_out+0x10>
 8004706:	684b      	ldr	r3, [r1, #4]
 8004708:	4293      	cmp	r3, r2
 800470a:	dc01      	bgt.n	8004710 <str_out+0x14>
		ctx->count++;
 800470c:	608d      	str	r5, [r1, #8]
}
 800470e:	bd30      	pop	{r4, r5, pc}
	if (ctx->count == ctx->max - 1) {
 8004710:	3b01      	subs	r3, #1
 8004712:	4293      	cmp	r3, r2
		ctx->str[ctx->count++] = '\0';
 8004714:	bf08      	it	eq
 8004716:	2200      	moveq	r2, #0
 8004718:	608d      	str	r5, [r1, #8]
 800471a:	bf0c      	ite	eq
 800471c:	54e2      	strbeq	r2, [r4, r3]
		ctx->str[ctx->count++] = c;
 800471e:	54a0      	strbne	r0, [r4, r2]
 8004720:	e7f5      	b.n	800470e <str_out+0x12>

08004722 <printk>:
{
 8004722:	b40f      	push	{r0, r1, r2, r3}
 8004724:	b507      	push	{r0, r1, r2, lr}
 8004726:	a904      	add	r1, sp, #16
 8004728:	f851 0b04 	ldr.w	r0, [r1], #4
	va_start(ap, fmt);
 800472c:	9101      	str	r1, [sp, #4]
	vprintk(fmt, ap);
 800472e:	f7fb ffb9 	bl	80006a4 <vprintk>
}
 8004732:	b003      	add	sp, #12
 8004734:	f85d eb04 	ldr.w	lr, [sp], #4
 8004738:	b004      	add	sp, #16
 800473a:	4770      	bx	lr

0800473c <snprintk>:
{
 800473c:	b40c      	push	{r2, r3}
 800473e:	b507      	push	{r0, r1, r2, lr}
 8004740:	ab04      	add	r3, sp, #16
 8004742:	f853 2b04 	ldr.w	r2, [r3], #4
	va_start(ap, fmt);
 8004746:	9301      	str	r3, [sp, #4]
	ret = vsnprintk(str, size, fmt, ap);
 8004748:	f7fb ffba 	bl	80006c0 <vsnprintk>
}
 800474c:	b003      	add	sp, #12
 800474e:	f85d eb04 	ldr.w	lr, [sp], #4
 8004752:	b002      	add	sp, #8
 8004754:	4770      	bx	lr

08004756 <find_and_stack>:
{
 8004756:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	stack[sz++] = tree->root;
 8004758:	6803      	ldr	r3, [r0, #0]
 800475a:	6013      	str	r3, [r2, #0]
{
 800475c:	4606      	mov	r6, r0
 800475e:	460d      	mov	r5, r1
 8004760:	4614      	mov	r4, r2
	stack[sz++] = tree->root;
 8004762:	2701      	movs	r7, #1
	while (stack[sz - 1] != node) {
 8004764:	f854 1b04 	ldr.w	r1, [r4], #4
 8004768:	42a9      	cmp	r1, r5
 800476a:	d101      	bne.n	8004770 <find_and_stack+0x1a>
}
 800476c:	4638      	mov	r0, r7
 800476e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		uint8_t side = tree->lessthan_fn(node, stack[sz - 1]) ? 0U : 1U;
 8004770:	6873      	ldr	r3, [r6, #4]
 8004772:	4628      	mov	r0, r5
 8004774:	4798      	blx	r3
		struct rbnode *ch = get_child(stack[sz - 1], side);
 8004776:	f854 3c04 	ldr.w	r3, [r4, #-4]
	if (side != 0U) {
 800477a:	b928      	cbnz	r0, 8004788 <find_and_stack+0x32>
		return n->children[1];
 800477c:	685b      	ldr	r3, [r3, #4]
		if (ch != NULL) {
 800477e:	2b00      	cmp	r3, #0
 8004780:	d0f4      	beq.n	800476c <find_and_stack+0x16>
			stack[sz++] = ch;
 8004782:	3701      	adds	r7, #1
 8004784:	6023      	str	r3, [r4, #0]
 8004786:	e7ed      	b.n	8004764 <find_and_stack+0xe>
	uintptr_t l = (uintptr_t) n->children[0];
 8004788:	681b      	ldr	r3, [r3, #0]
	l &= ~1UL;
 800478a:	f023 0301 	bic.w	r3, r3, #1
	return (struct rbnode *) l;
 800478e:	e7f6      	b.n	800477e <find_and_stack+0x28>

08004790 <stack_left_limb>:
 * or the root, so is_left must be false.
 */
static inline struct rbnode *stack_left_limb(struct rbnode *n,
					     struct _rb_foreach *f)
{
	f->top++;
 8004790:	688b      	ldr	r3, [r1, #8]
	f->stack[f->top] = n;
 8004792:	680a      	ldr	r2, [r1, #0]
	f->top++;
 8004794:	3301      	adds	r3, #1
{
 8004796:	b530      	push	{r4, r5, lr}
	f->top++;
 8004798:	608b      	str	r3, [r1, #8]
	f->stack[f->top] = n;
 800479a:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
	f->is_left[f->top] = 0U;
 800479e:	e9d1 2301 	ldrd	r2, r3, [r1, #4]
 80047a2:	2400      	movs	r4, #0
 80047a4:	54d4      	strb	r4, [r2, r3]

	while ((n = get_child(n, 0U)) != NULL) {
		f->top++;
		f->stack[f->top] = n;
		f->is_left[f->top] = 1;
 80047a6:	2501      	movs	r5, #1
	uintptr_t l = (uintptr_t) n->children[0];
 80047a8:	6804      	ldr	r4, [r0, #0]
		f->top++;
 80047aa:	688b      	ldr	r3, [r1, #8]
	}

	return f->stack[f->top];
 80047ac:	680a      	ldr	r2, [r1, #0]
	while ((n = get_child(n, 0U)) != NULL) {
 80047ae:	2c01      	cmp	r4, #1
	l &= ~1UL;
 80047b0:	f024 0001 	bic.w	r0, r4, #1
	while ((n = get_child(n, 0U)) != NULL) {
 80047b4:	d802      	bhi.n	80047bc <stack_left_limb+0x2c>
}
 80047b6:	f852 0023 	ldr.w	r0, [r2, r3, lsl #2]
 80047ba:	bd30      	pop	{r4, r5, pc}
		f->top++;
 80047bc:	3301      	adds	r3, #1
 80047be:	608b      	str	r3, [r1, #8]
		f->stack[f->top] = n;
 80047c0:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
		f->is_left[f->top] = 1;
 80047c4:	e9d1 2301 	ldrd	r2, r3, [r1, #4]
 80047c8:	54d5      	strb	r5, [r2, r3]
 80047ca:	e7ed      	b.n	80047a8 <stack_left_limb+0x18>

080047cc <set_child>:
	if (side != 0U) {
 80047cc:	b109      	cbz	r1, 80047d2 <set_child+0x6>
		n->children[1] = val;
 80047ce:	6042      	str	r2, [r0, #4]
 80047d0:	4770      	bx	lr
		n->children[0] = (void *) (new | (old & 1UL));
 80047d2:	6803      	ldr	r3, [r0, #0]
 80047d4:	f003 0301 	and.w	r3, r3, #1
 80047d8:	431a      	orrs	r2, r3
 80047da:	6002      	str	r2, [r0, #0]
}
 80047dc:	4770      	bx	lr

080047de <rotate>:
{
 80047de:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	struct rbnode *parent = stack[stacksz - 2];
 80047e2:	f101 4880 	add.w	r8, r1, #1073741824	; 0x40000000
 80047e6:	f1a8 0802 	sub.w	r8, r8, #2
 80047ea:	ea4f 0388 	mov.w	r3, r8, lsl #2
	struct rbnode *child = stack[stacksz - 1];
 80047ee:	f103 0b04 	add.w	fp, r3, #4
	struct rbnode *parent = stack[stacksz - 2];
 80047f2:	f850 a028 	ldr.w	sl, [r0, r8, lsl #2]
	struct rbnode *child = stack[stacksz - 1];
 80047f6:	f850 500b 	ldr.w	r5, [r0, fp]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 80047fa:	f8da 2004 	ldr.w	r2, [sl, #4]
	l &= ~1UL;
 80047fe:	682f      	ldr	r7, [r5, #0]
		return n->children[1];
 8004800:	f8d5 9004 	ldr.w	r9, [r5, #4]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8004804:	4295      	cmp	r5, r2
{
 8004806:	4606      	mov	r6, r0
	l &= ~1UL;
 8004808:	f027 0701 	bic.w	r7, r7, #1
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 800480c:	d118      	bne.n	8004840 <rotate+0x62>
	if (stacksz >= 3) {
 800480e:	2902      	cmp	r1, #2
 8004810:	dc20      	bgt.n	8004854 <rotate+0x76>
	set_child(child, side, a);
 8004812:	2101      	movs	r1, #1
 8004814:	464a      	mov	r2, r9
 8004816:	4628      	mov	r0, r5
 8004818:	f7ff ffd8 	bl	80047cc <set_child>
 800481c:	460c      	mov	r4, r1
	return (struct rbnode *) l;
 800481e:	46b9      	mov	r9, r7
	set_child(child, (side == 0U) ? 1U : 0U, parent);
 8004820:	2100      	movs	r1, #0
 8004822:	4652      	mov	r2, sl
 8004824:	4628      	mov	r0, r5
 8004826:	f7ff ffd1 	bl	80047cc <set_child>
	set_child(parent, side, b);
 800482a:	464a      	mov	r2, r9
 800482c:	4621      	mov	r1, r4
 800482e:	4650      	mov	r0, sl
 8004830:	f7ff ffcc 	bl	80047cc <set_child>
	stack[stacksz - 2] = child;
 8004834:	f846 5028 	str.w	r5, [r6, r8, lsl #2]
	stack[stacksz - 1] = parent;
 8004838:	f846 a00b 	str.w	sl, [r6, fp]
}
 800483c:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	if (stacksz >= 3) {
 8004840:	2902      	cmp	r1, #2
 8004842:	dc1e      	bgt.n	8004882 <rotate+0xa4>
	set_child(child, side, a);
 8004844:	2100      	movs	r1, #0
 8004846:	463a      	mov	r2, r7
 8004848:	4628      	mov	r0, r5
 800484a:	f7ff ffbf 	bl	80047cc <set_child>
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 800484e:	460c      	mov	r4, r1
	set_child(child, (side == 0U) ? 1U : 0U, parent);
 8004850:	2101      	movs	r1, #1
 8004852:	e7e6      	b.n	8004822 <rotate+0x44>
	if (stacksz >= 3) {
 8004854:	463a      	mov	r2, r7
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8004856:	2401      	movs	r4, #1
		return n->children[1];
 8004858:	464f      	mov	r7, r9
	return (struct rbnode *) l;
 800485a:	4691      	mov	r9, r2
		struct rbnode *grandparent = stack[stacksz - 3];
 800485c:	4433      	add	r3, r6
		set_child(grandparent, get_side(grandparent, parent), child);
 800485e:	462a      	mov	r2, r5
		struct rbnode *grandparent = stack[stacksz - 3];
 8004860:	f853 0c04 	ldr.w	r0, [r3, #-4]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8004864:	6841      	ldr	r1, [r0, #4]
		set_child(grandparent, get_side(grandparent, parent), child);
 8004866:	eba1 030a 	sub.w	r3, r1, sl
 800486a:	4259      	negs	r1, r3
 800486c:	4159      	adcs	r1, r3
 800486e:	f7ff ffad 	bl	80047cc <set_child>
	set_child(child, side, a);
 8004872:	4621      	mov	r1, r4
 8004874:	463a      	mov	r2, r7
 8004876:	4628      	mov	r0, r5
 8004878:	f7ff ffa8 	bl	80047cc <set_child>
	set_child(child, (side == 0U) ? 1U : 0U, parent);
 800487c:	f084 0101 	eor.w	r1, r4, #1
 8004880:	e7cf      	b.n	8004822 <rotate+0x44>
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8004882:	2400      	movs	r4, #0
 8004884:	e7ea      	b.n	800485c <rotate+0x7e>

08004886 <z_rb_get_minmax>:
	for (n = tree->root; (n != NULL) && (get_child(n, side) != NULL);
 8004886:	6800      	ldr	r0, [r0, #0]
 8004888:	b908      	cbnz	r0, 800488e <z_rb_get_minmax+0x8>
 800488a:	4770      	bx	lr
 800488c:	4618      	mov	r0, r3
	if (side != 0U) {
 800488e:	b119      	cbz	r1, 8004898 <z_rb_get_minmax+0x12>
		return n->children[1];
 8004890:	6843      	ldr	r3, [r0, #4]
	for (n = tree->root; (n != NULL) && (get_child(n, side) != NULL);
 8004892:	2b00      	cmp	r3, #0
 8004894:	d1fa      	bne.n	800488c <z_rb_get_minmax+0x6>
}
 8004896:	4770      	bx	lr
	uintptr_t l = (uintptr_t) n->children[0];
 8004898:	6803      	ldr	r3, [r0, #0]
	l &= ~1UL;
 800489a:	f023 0301 	bic.w	r3, r3, #1
	return (struct rbnode *) l;
 800489e:	e7f8      	b.n	8004892 <z_rb_get_minmax+0xc>

080048a0 <rb_insert>:
{
 80048a0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
 80048a4:	b083      	sub	sp, #12
		n->children[0] = (void *) (new | (old & 1UL));
 80048a6:	680b      	ldr	r3, [r1, #0]
 80048a8:	f003 0301 	and.w	r3, r3, #1
 80048ac:	600b      	str	r3, [r1, #0]
		n->children[1] = val;
 80048ae:	2300      	movs	r3, #0
 80048b0:	604b      	str	r3, [r1, #4]
{
 80048b2:	af00      	add	r7, sp, #0
	if (tree->root == NULL) {
 80048b4:	6803      	ldr	r3, [r0, #0]
{
 80048b6:	f8c7 d004 	str.w	sp, [r7, #4]
 80048ba:	4606      	mov	r6, r0
 80048bc:	460d      	mov	r5, r1
	if (tree->root == NULL) {
 80048be:	b953      	cbnz	r3, 80048d6 <rb_insert+0x36>
		tree->max_depth = 1;
 80048c0:	2301      	movs	r3, #1
		tree->root = node;
 80048c2:	6001      	str	r1, [r0, #0]
		tree->max_depth = 1;
 80048c4:	6083      	str	r3, [r0, #8]
	*p = (*p & ~1UL) | (uint8_t)color;
 80048c6:	680b      	ldr	r3, [r1, #0]
 80048c8:	f043 0301 	orr.w	r3, r3, #1
 80048cc:	600b      	str	r3, [r1, #0]
}
 80048ce:	370c      	adds	r7, #12
 80048d0:	46bd      	mov	sp, r7
 80048d2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	struct rbnode *stack[tree->max_depth + 1];
 80048d6:	6883      	ldr	r3, [r0, #8]
 80048d8:	009b      	lsls	r3, r3, #2
 80048da:	330b      	adds	r3, #11
 80048dc:	f023 0307 	bic.w	r3, r3, #7
 80048e0:	ebad 0d03 	sub.w	sp, sp, r3
 80048e4:	466b      	mov	r3, sp
	int stacksz = find_and_stack(tree, node, stack);
 80048e6:	461a      	mov	r2, r3
	struct rbnode *stack[tree->max_depth + 1];
 80048e8:	ea4f 0993 	mov.w	r9, r3, lsr #2
	int stacksz = find_and_stack(tree, node, stack);
 80048ec:	f7ff ff33 	bl	8004756 <find_and_stack>
	struct rbnode *stack[tree->max_depth + 1];
 80048f0:	46e8      	mov	r8, sp
	int stacksz = find_and_stack(tree, node, stack);
 80048f2:	eb08 0280 	add.w	r2, r8, r0, lsl #2
 80048f6:	4604      	mov	r4, r0
	struct rbnode *parent = stack[stacksz - 1];
 80048f8:	f852 ac04 	ldr.w	sl, [r2, #-4]
	uint8_t side = tree->lessthan_fn(node, parent) ? 0U : 1U;
 80048fc:	6872      	ldr	r2, [r6, #4]
 80048fe:	4651      	mov	r1, sl
 8004900:	ea4f 0b80 	mov.w	fp, r0, lsl #2
 8004904:	4628      	mov	r0, r5
 8004906:	4790      	blx	r2
 8004908:	f080 0101 	eor.w	r1, r0, #1
	set_child(parent, side, node);
 800490c:	462a      	mov	r2, r5
 800490e:	4650      	mov	r0, sl
 8004910:	b2c9      	uxtb	r1, r1
 8004912:	f7ff ff5b 	bl	80047cc <set_child>
	*p = (*p & ~1UL) | (uint8_t)color;
 8004916:	682a      	ldr	r2, [r5, #0]
	stack[stacksz++] = node;
 8004918:	f84b 5029 	str.w	r5, [fp, r9, lsl #2]
 800491c:	f104 0a01 	add.w	sl, r4, #1
 8004920:	f104 4480 	add.w	r4, r4, #1073741824	; 0x40000000
	*p = (*p & ~1UL) | (uint8_t)color;
 8004924:	f022 0201 	bic.w	r2, r2, #1
 8004928:	3c01      	subs	r4, #1
 800492a:	602a      	str	r2, [r5, #0]
	while (stacksz > 1) {
 800492c:	eb08 0484 	add.w	r4, r8, r4, lsl #2
	stack[stacksz++] = node;
 8004930:	4655      	mov	r5, sl
	while (stacksz > 1) {
 8004932:	2d01      	cmp	r5, #1
 8004934:	dc05      	bgt.n	8004942 <rb_insert+0xa2>
	set_color(stack[0], BLACK);
 8004936:	f8d8 2000 	ldr.w	r2, [r8]
	*p = (*p & ~1UL) | (uint8_t)color;
 800493a:	6813      	ldr	r3, [r2, #0]
 800493c:	f043 0301 	orr.w	r3, r3, #1
 8004940:	e03c      	b.n	80049bc <rb_insert+0x11c>
		struct rbnode *parent = stack[stacksz - 2];
 8004942:	e9d4 0e00 	ldrd	r0, lr, [r4]
	return get_color(n) == BLACK;
 8004946:	6803      	ldr	r3, [r0, #0]
		if (is_black(parent)) {
 8004948:	f013 0301 	ands.w	r3, r3, #1
 800494c:	d137      	bne.n	80049be <rb_insert+0x11e>
		struct rbnode *grandparent = stack[stacksz - 3];
 800494e:	f854 2c04 	ldr.w	r2, [r4, #-4]
		return n->children[1];
 8004952:	6851      	ldr	r1, [r2, #4]
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 8004954:	4288      	cmp	r0, r1
	uintptr_t l = (uintptr_t) n->children[0];
 8004956:	bf02      	ittt	eq
 8004958:	6811      	ldreq	r1, [r2, #0]
	l &= ~1UL;
 800495a:	f021 0101 	biceq.w	r1, r1, #1
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 800495e:	2301      	moveq	r3, #1
		if ((aunt != NULL) && is_red(aunt)) {
 8004960:	b199      	cbz	r1, 800498a <rb_insert+0xea>
 8004962:	f8d1 c000 	ldr.w	ip, [r1]
 8004966:	f01c 0f01 	tst.w	ip, #1
 800496a:	d10e      	bne.n	800498a <rb_insert+0xea>
	*p = (*p & ~1UL) | (uint8_t)color;
 800496c:	6813      	ldr	r3, [r2, #0]
 800496e:	f023 0301 	bic.w	r3, r3, #1
 8004972:	6013      	str	r3, [r2, #0]
 8004974:	6803      	ldr	r3, [r0, #0]
 8004976:	f043 0301 	orr.w	r3, r3, #1
 800497a:	6003      	str	r3, [r0, #0]
 800497c:	680b      	ldr	r3, [r1, #0]
 800497e:	f043 0301 	orr.w	r3, r3, #1
		if ((aunt != NULL) && is_red(aunt)) {
 8004982:	3c08      	subs	r4, #8
	*p = (*p & ~1UL) | (uint8_t)color;
 8004984:	600b      	str	r3, [r1, #0]
			stacksz -= 2;
 8004986:	3d02      	subs	r5, #2
			continue;
 8004988:	e7d3      	b.n	8004932 <rb_insert+0x92>
	return (get_child(parent, 1U) == child) ? 1U : 0U;
 800498a:	6842      	ldr	r2, [r0, #4]
		if (parent_side != side) {
 800498c:	eba2 010e 	sub.w	r1, r2, lr
 8004990:	424a      	negs	r2, r1
 8004992:	414a      	adcs	r2, r1
 8004994:	429a      	cmp	r2, r3
 8004996:	d003      	beq.n	80049a0 <rb_insert+0x100>
			rotate(stack, stacksz);
 8004998:	4629      	mov	r1, r5
 800499a:	4640      	mov	r0, r8
 800499c:	f7ff ff1f 	bl	80047de <rotate>
		rotate(stack, stacksz - 1);
 80049a0:	1e69      	subs	r1, r5, #1
 80049a2:	4640      	mov	r0, r8
 80049a4:	f7ff ff1b 	bl	80047de <rotate>
		set_color(stack[stacksz - 3], BLACK);
 80049a8:	f854 2c04 	ldr.w	r2, [r4, #-4]
	*p = (*p & ~1UL) | (uint8_t)color;
 80049ac:	6813      	ldr	r3, [r2, #0]
 80049ae:	f043 0301 	orr.w	r3, r3, #1
 80049b2:	6013      	str	r3, [r2, #0]
		set_color(stack[stacksz - 2], RED);
 80049b4:	6822      	ldr	r2, [r4, #0]
	*p = (*p & ~1UL) | (uint8_t)color;
 80049b6:	6813      	ldr	r3, [r2, #0]
 80049b8:	f023 0301 	bic.w	r3, r3, #1
 80049bc:	6013      	str	r3, [r2, #0]
	if (stacksz > tree->max_depth) {
 80049be:	68b3      	ldr	r3, [r6, #8]
 80049c0:	4553      	cmp	r3, sl
	tree->root = stack[0];
 80049c2:	f8d8 3000 	ldr.w	r3, [r8]
		tree->max_depth = stacksz;
 80049c6:	bfb8      	it	lt
 80049c8:	f8c6 a008 	strlt.w	sl, [r6, #8]
	tree->root = stack[0];
 80049cc:	6033      	str	r3, [r6, #0]
	CHECK(is_black(tree->root));
 80049ce:	f8d7 d004 	ldr.w	sp, [r7, #4]
 80049d2:	e77c      	b.n	80048ce <rb_insert+0x2e>

080049d4 <z_rb_foreach_next>:
 * node/stack[top] is the left child of stack[top-1]).  The special
 * case of top == -1 indicates that the stack is uninitialized and we
 * need to push an initial stack starting at the root.
 */
struct rbnode *z_rb_foreach_next(struct rbtree *tree, struct _rb_foreach *f)
{
 80049d4:	b430      	push	{r4, r5}
	struct rbnode *n;

	if (tree->root == NULL) {
 80049d6:	6800      	ldr	r0, [r0, #0]
{
 80049d8:	460b      	mov	r3, r1
	if (tree->root == NULL) {
 80049da:	b910      	cbnz	r0, 80049e2 <z_rb_foreach_next+0xe>
		return NULL;
 80049dc:	2000      	movs	r0, #0
		f->top--;
	}

	f->top--;
	return (f->top >= 0) ? f->stack[f->top] : NULL;
}
 80049de:	bc30      	pop	{r4, r5}
 80049e0:	4770      	bx	lr
	if (f->top == -1) {
 80049e2:	688a      	ldr	r2, [r1, #8]
 80049e4:	1c54      	adds	r4, r2, #1
 80049e6:	d102      	bne.n	80049ee <z_rb_foreach_next+0x1a>
}
 80049e8:	bc30      	pop	{r4, r5}
		return stack_left_limb(n, f);
 80049ea:	f7ff bed1 	b.w	8004790 <stack_left_limb>
	n = get_child(f->stack[f->top], 1U);
 80049ee:	680c      	ldr	r4, [r1, #0]
		return n->children[1];
 80049f0:	f854 0022 	ldr.w	r0, [r4, r2, lsl #2]
 80049f4:	6840      	ldr	r0, [r0, #4]
	n = get_child(f->stack[f->top], 1U);
 80049f6:	0095      	lsls	r5, r2, #2
	if (n != NULL) {
 80049f8:	2800      	cmp	r0, #0
 80049fa:	d1f5      	bne.n	80049e8 <z_rb_foreach_next+0x14>
	if (f->is_left[f->top] != 0U) {
 80049fc:	6848      	ldr	r0, [r1, #4]
 80049fe:	5c81      	ldrb	r1, [r0, r2]
 8004a00:	b129      	cbz	r1, 8004a0e <z_rb_foreach_next+0x3a>
		return f->stack[--f->top];
 8004a02:	3a01      	subs	r2, #1
 8004a04:	442c      	add	r4, r5
 8004a06:	609a      	str	r2, [r3, #8]
 8004a08:	f854 0c04 	ldr.w	r0, [r4, #-4]
 8004a0c:	e7e7      	b.n	80049de <z_rb_foreach_next+0xa>
	while ((f->top > 0) && (f->is_left[f->top] == 0U)) {
 8004a0e:	6899      	ldr	r1, [r3, #8]
 8004a10:	2900      	cmp	r1, #0
		f->top--;
 8004a12:	f101 32ff 	add.w	r2, r1, #4294967295	; 0xffffffff
	while ((f->top > 0) && (f->is_left[f->top] == 0U)) {
 8004a16:	dd06      	ble.n	8004a26 <z_rb_foreach_next+0x52>
 8004a18:	5c41      	ldrb	r1, [r0, r1]
		f->top--;
 8004a1a:	609a      	str	r2, [r3, #8]
	while ((f->top > 0) && (f->is_left[f->top] == 0U)) {
 8004a1c:	2900      	cmp	r1, #0
 8004a1e:	d0f6      	beq.n	8004a0e <z_rb_foreach_next+0x3a>
	return (f->top >= 0) ? f->stack[f->top] : NULL;
 8004a20:	f854 0022 	ldr.w	r0, [r4, r2, lsl #2]
 8004a24:	e7db      	b.n	80049de <z_rb_foreach_next+0xa>
	f->top--;
 8004a26:	609a      	str	r2, [r3, #8]
	return (f->top >= 0) ? f->stack[f->top] : NULL;
 8004a28:	e7d8      	b.n	80049dc <z_rb_foreach_next+0x8>

08004a2a <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
 8004a2a:	4604      	mov	r4, r0
 8004a2c:	b508      	push	{r3, lr}
 8004a2e:	4608      	mov	r0, r1
 8004a30:	4611      	mov	r1, r2
#ifdef CONFIG_THREAD_LOCAL_STORAGE
	z_tls_current = z_current_get();
#endif
	entry(p1, p2, p3);
 8004a32:	461a      	mov	r2, r3
 8004a34:	47a0      	blx	r4
	return z_impl_z_current_get();
 8004a36:	f7ff fac7 	bl	8003fc8 <z_impl_z_current_get>
	z_impl_k_thread_abort(thread);
 8004a3a:	f7fc fea1 	bl	8001780 <z_impl_k_thread_abort>

08004a3e <encode_uint>:
{
 8004a3e:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
 8004a42:	469a      	mov	sl, r3
	bool upcase = isupper((int)conv->specifier);
 8004a44:	78d3      	ldrb	r3, [r2, #3]
	switch (specifier) {
 8004a46:	2b6f      	cmp	r3, #111	; 0x6f
{
 8004a48:	4680      	mov	r8, r0
 8004a4a:	460f      	mov	r7, r1
 8004a4c:	4615      	mov	r5, r2
	return (int)(((unsigned)(a)-(unsigned)'A') < 26U);
 8004a4e:	f1a3 0b41 	sub.w	fp, r3, #65	; 0x41
	switch (specifier) {
 8004a52:	d029      	beq.n	8004aa8 <encode_uint+0x6a>
 8004a54:	d824      	bhi.n	8004aa0 <encode_uint+0x62>
		return 10;
 8004a56:	2b58      	cmp	r3, #88	; 0x58
 8004a58:	bf0c      	ite	eq
 8004a5a:	2610      	moveq	r6, #16
 8004a5c:	260a      	movne	r6, #10
	char *bp = bps + (bpe - bps);
 8004a5e:	f8dd 9028 	ldr.w	r9, [sp, #40]	; 0x28
		unsigned int lsv = (unsigned int)(value % radix);
 8004a62:	4632      	mov	r2, r6
 8004a64:	2300      	movs	r3, #0
 8004a66:	4640      	mov	r0, r8
 8004a68:	4639      	mov	r1, r7
 8004a6a:	f7fb fb95 	bl	8000198 <__aeabi_uldivmod>
		*--bp = (lsv <= 9) ? ('0' + lsv)
 8004a6e:	2a09      	cmp	r2, #9
 8004a70:	b2d4      	uxtb	r4, r2
 8004a72:	d81e      	bhi.n	8004ab2 <encode_uint+0x74>
 8004a74:	3430      	adds	r4, #48	; 0x30
	} while ((value != 0) && (bps < bp));
 8004a76:	45b0      	cmp	r8, r6
		*--bp = (lsv <= 9) ? ('0' + lsv)
 8004a78:	b2e4      	uxtb	r4, r4
	} while ((value != 0) && (bps < bp));
 8004a7a:	f177 0700 	sbcs.w	r7, r7, #0
		*--bp = (lsv <= 9) ? ('0' + lsv)
 8004a7e:	f809 4d01 	strb.w	r4, [r9, #-1]!
	} while ((value != 0) && (bps < bp));
 8004a82:	d301      	bcc.n	8004a88 <encode_uint+0x4a>
 8004a84:	45d1      	cmp	r9, sl
 8004a86:	d811      	bhi.n	8004aac <encode_uint+0x6e>
	if (conv->flag_hash) {
 8004a88:	782b      	ldrb	r3, [r5, #0]
 8004a8a:	069b      	lsls	r3, r3, #26
 8004a8c:	d505      	bpl.n	8004a9a <encode_uint+0x5c>
		if (radix == 8) {
 8004a8e:	2e08      	cmp	r6, #8
 8004a90:	d115      	bne.n	8004abe <encode_uint+0x80>
			conv->altform_0 = true;
 8004a92:	78ab      	ldrb	r3, [r5, #2]
 8004a94:	f043 0308 	orr.w	r3, r3, #8
			conv->altform_0c = true;
 8004a98:	70ab      	strb	r3, [r5, #2]
}
 8004a9a:	4648      	mov	r0, r9
 8004a9c:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	switch (specifier) {
 8004aa0:	f003 03f7 	and.w	r3, r3, #247	; 0xf7
		return 10;
 8004aa4:	2b70      	cmp	r3, #112	; 0x70
 8004aa6:	e7d7      	b.n	8004a58 <encode_uint+0x1a>
	switch (specifier) {
 8004aa8:	2608      	movs	r6, #8
 8004aaa:	e7d8      	b.n	8004a5e <encode_uint+0x20>
		value /= radix;
 8004aac:	4680      	mov	r8, r0
 8004aae:	460f      	mov	r7, r1
 8004ab0:	e7d7      	b.n	8004a62 <encode_uint+0x24>
		*--bp = (lsv <= 9) ? ('0' + lsv)
 8004ab2:	f1bb 0f19 	cmp.w	fp, #25
 8004ab6:	bf94      	ite	ls
 8004ab8:	3437      	addls	r4, #55	; 0x37
 8004aba:	3457      	addhi	r4, #87	; 0x57
 8004abc:	e7db      	b.n	8004a76 <encode_uint+0x38>
		} else if (radix == 16) {
 8004abe:	2e10      	cmp	r6, #16
 8004ac0:	d1eb      	bne.n	8004a9a <encode_uint+0x5c>
			conv->altform_0c = true;
 8004ac2:	78ab      	ldrb	r3, [r5, #2]
 8004ac4:	f043 0310 	orr.w	r3, r3, #16
 8004ac8:	e7e6      	b.n	8004a98 <encode_uint+0x5a>

08004aca <outs>:
{
 8004aca:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 8004ace:	4607      	mov	r7, r0
 8004ad0:	4688      	mov	r8, r1
 8004ad2:	4615      	mov	r5, r2
 8004ad4:	461e      	mov	r6, r3
	while ((sp < ep) || ((ep == NULL) && *sp)) {
 8004ad6:	4614      	mov	r4, r2
 8004ad8:	42b4      	cmp	r4, r6
 8004ada:	d305      	bcc.n	8004ae8 <outs+0x1e>
 8004adc:	b10e      	cbz	r6, 8004ae2 <outs+0x18>
	return (int)count;
 8004ade:	1b60      	subs	r0, r4, r5
 8004ae0:	e008      	b.n	8004af4 <outs+0x2a>
	while ((sp < ep) || ((ep == NULL) && *sp)) {
 8004ae2:	7823      	ldrb	r3, [r4, #0]
 8004ae4:	2b00      	cmp	r3, #0
 8004ae6:	d0fa      	beq.n	8004ade <outs+0x14>
		int rc = out((int)*sp++, ctx);
 8004ae8:	f814 0b01 	ldrb.w	r0, [r4], #1
 8004aec:	4641      	mov	r1, r8
 8004aee:	47b8      	blx	r7
		if (rc < 0) {
 8004af0:	2800      	cmp	r0, #0
 8004af2:	daf1      	bge.n	8004ad8 <outs+0xe>
}
 8004af4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

08004af8 <assert_post_action>:
	if (k_is_user_context()) {
		k_oops();
	}
#endif

	k_panic();
 8004af8:	4040      	eors	r0, r0
 8004afa:	f380 8811 	msr	BASEPRI, r0
 8004afe:	f04f 0004 	mov.w	r0, #4
 8004b02:	df02      	svc	2
}
 8004b04:	4770      	bx	lr

08004b06 <assert_print>:

void assert_print(const char *fmt, ...)
{
 8004b06:	b40f      	push	{r0, r1, r2, r3}
 8004b08:	b507      	push	{r0, r1, r2, lr}
 8004b0a:	a904      	add	r1, sp, #16
 8004b0c:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
 8004b10:	9101      	str	r1, [sp, #4]

	vprintk(fmt, ap);
 8004b12:	f7fb fdc7 	bl	80006a4 <vprintk>

	va_end(ap);
}
 8004b16:	b003      	add	sp, #12
 8004b18:	f85d eb04 	ldr.w	lr, [sp], #4
 8004b1c:	b004      	add	sp, #16
 8004b1e:	4770      	bx	lr

08004b20 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_BUILD_OUTPUT_BIN, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_WARN_DEPRECATED, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_ENFORCE_ZEPHYR_STDINT, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_COMPAT_INCLUDES, 1);

GEN_ABS_SYM_END
 8004b20:	4770      	bx	lr

08004b22 <st_stm32_common_config>:
#endif /* CONFIG_SOC_SERIES_STM32H7X || CONFIG_SOC_SERIES_STM32MP1X */

#endif /* CONFIG_USE_SEGGER_RTT */

	return 0;
}
 8004b22:	2000      	movs	r0, #0
 8004b24:	4770      	bx	lr

08004b26 <z_arm_fatal_error>:
{

	if (esf != NULL) {
		esf_dump(esf);
	}
	z_fatal_error(reason, esf);
 8004b26:	f7fd be43 	b.w	80027b0 <z_fatal_error>

08004b2a <z_do_kernel_oops>:
 *
 * @param esf exception frame
 * @param callee_regs Callee-saved registers (R4-R11)
 */
void z_do_kernel_oops(const z_arch_esf_t *esf, _callee_saved_t *callee_regs)
{
 8004b2a:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
 8004b2c:	6800      	ldr	r0, [r0, #0]
 8004b2e:	f7fd be3f 	b.w	80027b0 <z_fatal_error>

08004b32 <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
 8004b32:	2100      	movs	r1, #0
 8004b34:	2001      	movs	r0, #1
 8004b36:	f7ff bff6 	b.w	8004b26 <z_arm_fatal_error>

08004b3a <z_arm_nmi>:
 * Simply call what is installed in 'static void(*handler)(void)'.
 *
 */

void z_arm_nmi(void)
{
 8004b3a:	b508      	push	{r3, lr}
	handler();
 8004b3c:	f7fc fbba 	bl	80012b4 <z_SysNmiOnReset>
	z_arm_int_exit();
}
 8004b40:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
 8004b44:	f7fc bc94 	b.w	8001470 <z_arm_exc_exit>

08004b48 <strncpy>:
 *
 * @return pointer to destination buffer <d>
 */

char *strncpy(char *ZRESTRICT d, const char *ZRESTRICT s, size_t n)
{
 8004b48:	b510      	push	{r4, lr}
 8004b4a:	3901      	subs	r1, #1
	char *dest = d;

	while ((n > 0) && *s != '\0') {
 8004b4c:	4603      	mov	r3, r0
 8004b4e:	b922      	cbnz	r2, 8004b5a <strncpy+0x12>
 8004b50:	441a      	add	r2, r3
		d++;
		n--;
	}

	while (n > 0) {
		*d = '\0';
 8004b52:	2100      	movs	r1, #0
	while (n > 0) {
 8004b54:	4293      	cmp	r3, r2
 8004b56:	d108      	bne.n	8004b6a <strncpy+0x22>
		d++;
		n--;
	}

	return dest;
}
 8004b58:	bd10      	pop	{r4, pc}
	while ((n > 0) && *s != '\0') {
 8004b5a:	f811 4f01 	ldrb.w	r4, [r1, #1]!
 8004b5e:	2c00      	cmp	r4, #0
 8004b60:	d0f6      	beq.n	8004b50 <strncpy+0x8>
		*d = *s;
 8004b62:	f803 4b01 	strb.w	r4, [r3], #1
		n--;
 8004b66:	3a01      	subs	r2, #1
 8004b68:	e7f1      	b.n	8004b4e <strncpy+0x6>
		*d = '\0';
 8004b6a:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
 8004b6e:	e7f1      	b.n	8004b54 <strncpy+0xc>

08004b70 <strlen>:
 *
 * @return number of bytes in string <s>
 */

size_t strlen(const char *s)
{
 8004b70:	4603      	mov	r3, r0
	size_t n = 0;
 8004b72:	2000      	movs	r0, #0

	while (*s != '\0') {
 8004b74:	5c1a      	ldrb	r2, [r3, r0]
 8004b76:	b902      	cbnz	r2, 8004b7a <strlen+0xa>
		s++;
		n++;
	}

	return n;
}
 8004b78:	4770      	bx	lr
		n++;
 8004b7a:	3001      	adds	r0, #1
 8004b7c:	e7fa      	b.n	8004b74 <strlen+0x4>

08004b7e <strnlen>:
 *
 * @return number of bytes in fixed-size string <s>
 */

size_t strnlen(const char *s, size_t maxlen)
{
 8004b7e:	4603      	mov	r3, r0
	size_t n = 0;
 8004b80:	2000      	movs	r0, #0

	while (*s != '\0' && n < maxlen) {
 8004b82:	5c1a      	ldrb	r2, [r3, r0]
 8004b84:	b10a      	cbz	r2, 8004b8a <strnlen+0xc>
 8004b86:	4288      	cmp	r0, r1
 8004b88:	d100      	bne.n	8004b8c <strnlen+0xe>
		s++;
		n++;
	}

	return n;
}
 8004b8a:	4770      	bx	lr
		n++;
 8004b8c:	3001      	adds	r0, #1
 8004b8e:	e7f8      	b.n	8004b82 <strnlen+0x4>

08004b90 <memcpy>:
 *
 * @return pointer to start of destination buffer
 */

void *memcpy(void *ZRESTRICT d, const void *ZRESTRICT s, size_t n)
{
 8004b90:	b510      	push	{r4, lr}
 8004b92:	1e43      	subs	r3, r0, #1
 8004b94:	440a      	add	r2, r1
	}
#endif

	/* do byte-sized copying until finished */

	while (n > 0) {
 8004b96:	4291      	cmp	r1, r2
 8004b98:	d100      	bne.n	8004b9c <memcpy+0xc>
		*(d_byte++) = *(s_byte++);
		n--;
	}

	return d;
}
 8004b9a:	bd10      	pop	{r4, pc}
		*(d_byte++) = *(s_byte++);
 8004b9c:	f811 4b01 	ldrb.w	r4, [r1], #1
 8004ba0:	f803 4f01 	strb.w	r4, [r3, #1]!
		n--;
 8004ba4:	e7f7      	b.n	8004b96 <memcpy+0x6>

08004ba6 <memset>:
void *memset(void *buf, int c, size_t n)
{
	/* do byte-sized initialization until word-aligned or finished */

	unsigned char *d_byte = (unsigned char *)buf;
	unsigned char c_byte = (unsigned char)c;
 8004ba6:	b2c9      	uxtb	r1, r1
	/* do byte-sized initialization until finished */

	d_byte = (unsigned char *)d_word;
#endif

	while (n > 0) {
 8004ba8:	4402      	add	r2, r0
	unsigned char *d_byte = (unsigned char *)buf;
 8004baa:	4603      	mov	r3, r0
	while (n > 0) {
 8004bac:	4293      	cmp	r3, r2
 8004bae:	d100      	bne.n	8004bb2 <memset+0xc>
		*(d_byte++) = c_byte;
		n--;
	}

	return buf;
}
 8004bb0:	4770      	bx	lr
		*(d_byte++) = c_byte;
 8004bb2:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
 8004bb6:	e7f9      	b.n	8004bac <memset+0x6>

08004bb8 <stm32_exti_init>:
	defined(CONFIG_SOC_SERIES_STM32MP1X) || \
	defined(CONFIG_SOC_SERIES_STM32U5X) || \
	defined(CONFIG_SOC_SERIES_STM32WBX) || \
	defined(CONFIG_SOC_SERIES_STM32G4X) || \
	defined(CONFIG_SOC_SERIES_STM32WLX)
	IRQ_CONNECT(EXTI0_IRQn,
 8004bb8:	2200      	movs	r2, #0
{
 8004bba:	b508      	push	{r3, lr}
	IRQ_CONNECT(EXTI0_IRQn,
 8004bbc:	4611      	mov	r1, r2
 8004bbe:	2006      	movs	r0, #6
 8004bc0:	f7fc fb44 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_EXTI0_IRQ_PRI,
		__stm32_exti_isr_0, DEVICE_DT_GET(EXTI_NODE),
		0);
	IRQ_CONNECT(EXTI1_IRQn,
 8004bc4:	2200      	movs	r2, #0
 8004bc6:	4611      	mov	r1, r2
 8004bc8:	2007      	movs	r0, #7
 8004bca:	f7fc fb3f 	bl	800124c <z_arm_irq_priority_set>
	IRQ_CONNECT(EXTI2_TSC_IRQn,
		CONFIG_EXTI_STM32_EXTI2_IRQ_PRI,
		__stm32_exti_isr_2, DEVICE_DT_GET(EXTI_NODE),
		0);
#else
	IRQ_CONNECT(EXTI2_IRQn,
 8004bce:	2200      	movs	r2, #0
 8004bd0:	4611      	mov	r1, r2
 8004bd2:	2008      	movs	r0, #8
 8004bd4:	f7fc fb3a 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_EXTI2_IRQ_PRI,
		__stm32_exti_isr_2, DEVICE_DT_GET(EXTI_NODE),
		0);
#endif /* CONFIG_SOC_SERIES_STM32F3X */
	IRQ_CONNECT(EXTI3_IRQn,
 8004bd8:	2200      	movs	r2, #0
 8004bda:	4611      	mov	r1, r2
 8004bdc:	2009      	movs	r0, #9
 8004bde:	f7fc fb35 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_EXTI3_IRQ_PRI,
		__stm32_exti_isr_3, DEVICE_DT_GET(EXTI_NODE),
		0);
	IRQ_CONNECT(EXTI4_IRQn,
 8004be2:	2200      	movs	r2, #0
 8004be4:	4611      	mov	r1, r2
 8004be6:	200a      	movs	r0, #10
 8004be8:	f7fc fb30 	bl	800124c <z_arm_irq_priority_set>
		__stm32_exti_isr_4, DEVICE_DT_GET(EXTI_NODE),
		0);
#if !defined(CONFIG_SOC_SERIES_STM32MP1X) && \
	!defined(CONFIG_SOC_SERIES_STM32L5X) && \
	!defined(CONFIG_SOC_SERIES_STM32U5X)
	IRQ_CONNECT(EXTI9_5_IRQn,
 8004bec:	2200      	movs	r2, #0
 8004bee:	4611      	mov	r1, r2
 8004bf0:	2017      	movs	r0, #23
 8004bf2:	f7fc fb2b 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_EXTI9_5_IRQ_PRI,
		__stm32_exti_isr_9_5, DEVICE_DT_GET(EXTI_NODE),
		0);
	IRQ_CONNECT(EXTI15_10_IRQn,
 8004bf6:	2200      	movs	r2, #0
 8004bf8:	4611      	mov	r1, r2
 8004bfa:	2028      	movs	r0, #40	; 0x28
 8004bfc:	f7fc fb26 	bl	800124c <z_arm_irq_priority_set>
#endif /* CONFIG_SOC_SERIES_STM32MP1X || CONFIG_SOC_SERIES_STM32L5X */

#if defined(CONFIG_SOC_SERIES_STM32F2X) || \
	defined(CONFIG_SOC_SERIES_STM32F4X) || \
	defined(CONFIG_SOC_SERIES_STM32F7X)
	IRQ_CONNECT(PVD_IRQn,
 8004c00:	2200      	movs	r2, #0
 8004c02:	4611      	mov	r1, r2
 8004c04:	2001      	movs	r0, #1
 8004c06:	f7fc fb21 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_PVD_IRQ_PRI,
		__stm32_exti_isr_16, DEVICE_DT_GET(EXTI_NODE),
		0);
#if !defined(CONFIG_SOC_STM32F410RX)
	IRQ_CONNECT(OTG_FS_WKUP_IRQn,
 8004c0a:	2200      	movs	r2, #0
 8004c0c:	4611      	mov	r1, r2
 8004c0e:	202a      	movs	r0, #42	; 0x2a
 8004c10:	f7fc fb1c 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_OTG_FS_WKUP_IRQ_PRI,
		__stm32_exti_isr_18, DEVICE_DT_GET(EXTI_NODE),
		0);
#endif
	IRQ_CONNECT(TAMP_STAMP_IRQn,
 8004c14:	2200      	movs	r2, #0
 8004c16:	4611      	mov	r1, r2
 8004c18:	2002      	movs	r0, #2
 8004c1a:	f7fc fb17 	bl	800124c <z_arm_irq_priority_set>
		CONFIG_EXTI_STM32_TAMP_STAMP_IRQ_PRI,
		__stm32_exti_isr_21, DEVICE_DT_GET(EXTI_NODE),
		0);
	IRQ_CONNECT(RTC_WKUP_IRQn,
 8004c1e:	2200      	movs	r2, #0
 8004c20:	4611      	mov	r1, r2
 8004c22:	2003      	movs	r0, #3
 8004c24:	f7fc fb12 	bl	800124c <z_arm_irq_priority_set>
}
 8004c28:	2000      	movs	r0, #0
 8004c2a:	bd08      	pop	{r3, pc}

08004c2c <__stm32_exti_isr_22>:
	__stm32_exti_isr(22, 23, dev);
 8004c2c:	6902      	ldr	r2, [r0, #16]
 8004c2e:	2117      	movs	r1, #23
 8004c30:	2016      	movs	r0, #22
 8004c32:	f7fc bee7 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c36 <__stm32_exti_isr_21>:
	__stm32_exti_isr(21, 22, dev);
 8004c36:	6902      	ldr	r2, [r0, #16]
 8004c38:	2116      	movs	r1, #22
 8004c3a:	2015      	movs	r0, #21
 8004c3c:	f7fc bee2 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c40 <__stm32_exti_isr_18>:
	__stm32_exti_isr(18, 19, dev);
 8004c40:	6902      	ldr	r2, [r0, #16]
 8004c42:	2113      	movs	r1, #19
 8004c44:	2012      	movs	r0, #18
 8004c46:	f7fc bedd 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c4a <__stm32_exti_isr_16>:
	__stm32_exti_isr(16, 17, dev);
 8004c4a:	6902      	ldr	r2, [r0, #16]
 8004c4c:	2111      	movs	r1, #17
 8004c4e:	2010      	movs	r0, #16
 8004c50:	f7fc bed8 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c54 <__stm32_exti_isr_15_10>:
	__stm32_exti_isr(10, 16, dev);
 8004c54:	6902      	ldr	r2, [r0, #16]
 8004c56:	2110      	movs	r1, #16
 8004c58:	200a      	movs	r0, #10
 8004c5a:	f7fc bed3 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c5e <__stm32_exti_isr_9_5>:
	__stm32_exti_isr(5, 10, dev);
 8004c5e:	6902      	ldr	r2, [r0, #16]
 8004c60:	210a      	movs	r1, #10
 8004c62:	2005      	movs	r0, #5
 8004c64:	f7fc bece 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c68 <__stm32_exti_isr_4>:
	__stm32_exti_isr(4, 5, dev);
 8004c68:	6902      	ldr	r2, [r0, #16]
 8004c6a:	2105      	movs	r1, #5
 8004c6c:	2004      	movs	r0, #4
 8004c6e:	f7fc bec9 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c72 <__stm32_exti_isr_3>:
	__stm32_exti_isr(3, 4, dev);
 8004c72:	6902      	ldr	r2, [r0, #16]
 8004c74:	2104      	movs	r1, #4
 8004c76:	2003      	movs	r0, #3
 8004c78:	f7fc bec4 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c7c <__stm32_exti_isr_2>:
	__stm32_exti_isr(2, 3, dev);
 8004c7c:	6902      	ldr	r2, [r0, #16]
 8004c7e:	2103      	movs	r1, #3
 8004c80:	2002      	movs	r0, #2
 8004c82:	f7fc bebf 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c86 <__stm32_exti_isr_1>:
	__stm32_exti_isr(1, 2, dev);
 8004c86:	6902      	ldr	r2, [r0, #16]
 8004c88:	2102      	movs	r1, #2
 8004c8a:	2001      	movs	r0, #1
 8004c8c:	f7fc beba 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c90 <__stm32_exti_isr_0>:
	__stm32_exti_isr(0, 1, dev);
 8004c90:	6902      	ldr	r2, [r0, #16]
 8004c92:	2101      	movs	r1, #1
 8004c94:	2000      	movs	r0, #0
 8004c96:	f7fc beb5 	b.w	8001a04 <__stm32_exti_isr.isra.0>

08004c9a <stm32_clock_control_on>:
	if (IN_RANGE(pclken->bus, STM32_PERIPH_BUS_MIN, STM32_PERIPH_BUS_MAX) == 0) {
 8004c9a:	680b      	ldr	r3, [r1, #0]
 8004c9c:	f1a3 0230 	sub.w	r2, r3, #48	; 0x30
 8004ca0:	2a78      	cmp	r2, #120	; 0x78
	sys_set_bits(DT_REG_ADDR(DT_NODELABEL(rcc)) + pclken->bus,
 8004ca2:	bf9f      	itttt	ls
 8004ca4:	f103 4380 	addls.w	r3, r3, #1073741824	; 0x40000000
 8004ca8:	f503 330e 	addls.w	r3, r3, #145408	; 0x23800

static ALWAYS_INLINE void sys_set_bits(mem_addr_t addr, unsigned int mask)
{
	uint32_t temp = *(volatile uint32_t *)addr;

	*(volatile uint32_t *)addr = temp | mask;
 8004cac:	6849      	ldrls	r1, [r1, #4]
	uint32_t temp = *(volatile uint32_t *)addr;
 8004cae:	681a      	ldrls	r2, [r3, #0]
	*(volatile uint32_t *)addr = temp | mask;
 8004cb0:	bf9d      	ittte	ls
 8004cb2:	430a      	orrls	r2, r1
	return 0;
 8004cb4:	2000      	movls	r0, #0
 8004cb6:	601a      	strls	r2, [r3, #0]
		return -ENOTSUP;
 8004cb8:	f06f 0085 	mvnhi.w	r0, #133	; 0x85
}
 8004cbc:	4770      	bx	lr

08004cbe <stm32_clock_control_off>:
	if (IN_RANGE(pclken->bus, STM32_PERIPH_BUS_MIN, STM32_PERIPH_BUS_MAX) == 0) {
 8004cbe:	680b      	ldr	r3, [r1, #0]
 8004cc0:	f1a3 0230 	sub.w	r2, r3, #48	; 0x30
 8004cc4:	2a78      	cmp	r2, #120	; 0x78
	sys_clear_bits(DT_REG_ADDR(DT_NODELABEL(rcc)) + pclken->bus,
 8004cc6:	bf9f      	itttt	ls
 8004cc8:	f103 4380 	addls.w	r3, r3, #1073741824	; 0x40000000
 8004ccc:	f503 330e 	addls.w	r3, r3, #145408	; 0x23800

static ALWAYS_INLINE void sys_clear_bits(mem_addr_t addr, unsigned int mask)
{
	uint32_t temp = *(volatile uint32_t *)addr;

	*(volatile uint32_t *)addr = temp & ~mask;
 8004cd0:	6849      	ldrls	r1, [r1, #4]
	uint32_t temp = *(volatile uint32_t *)addr;
 8004cd2:	681a      	ldrls	r2, [r3, #0]
	*(volatile uint32_t *)addr = temp & ~mask;
 8004cd4:	bf9d      	ittte	ls
 8004cd6:	438a      	bicls	r2, r1
	return 0;
 8004cd8:	2000      	movls	r0, #0
 8004cda:	601a      	strls	r2, [r3, #0]
		return -ENOTSUP;
 8004cdc:	f06f 0085 	mvnhi.w	r0, #133	; 0x85
}
 8004ce0:	4770      	bx	lr

08004ce2 <stm32_clock_control_configure>:
	err = enabled_clock(pclken->bus);
 8004ce2:	680b      	ldr	r3, [r1, #0]
	switch (src_clk) {
 8004ce4:	2b02      	cmp	r3, #2
 8004ce6:	d803      	bhi.n	8004cf0 <stm32_clock_control_configure+0xe>
 8004ce8:	b92b      	cbnz	r3, 8004cf6 <stm32_clock_control_configure+0x14>
 8004cea:	f06f 0085 	mvn.w	r0, #133	; 0x85
}
 8004cee:	4770      	bx	lr
	switch (src_clk) {
 8004cf0:	3b05      	subs	r3, #5
 8004cf2:	2b01      	cmp	r3, #1
 8004cf4:	d8f9      	bhi.n	8004cea <stm32_clock_control_configure+0x8>
	sys_set_bits(DT_REG_ADDR(DT_NODELABEL(rcc)) + STM32_CLOCK_REG_GET(pclken->enr),
 8004cf6:	6849      	ldr	r1, [r1, #4]
 8004cf8:	b2cb      	uxtb	r3, r1
 8004cfa:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
 8004cfe:	f503 330e 	add.w	r3, r3, #145408	; 0x23800
		     STM32_CLOCK_VAL_GET(pclken->enr) << STM32_CLOCK_SHIFT_GET(pclken->enr));
 8004d02:	f3c1 4202 	ubfx	r2, r1, #16, #3
	uint32_t temp = *(volatile uint32_t *)addr;
 8004d06:	6818      	ldr	r0, [r3, #0]
 8004d08:	f3c1 2104 	ubfx	r1, r1, #8, #5
	sys_set_bits(DT_REG_ADDR(DT_NODELABEL(rcc)) + STM32_CLOCK_REG_GET(pclken->enr),
 8004d0c:	408a      	lsls	r2, r1
	*(volatile uint32_t *)addr = temp | mask;
 8004d0e:	4302      	orrs	r2, r0
 8004d10:	601a      	str	r2, [r3, #0]
	return 0;
 8004d12:	2000      	movs	r0, #0
 8004d14:	4770      	bx	lr

08004d16 <gpio_stm32_port_get_raw>:
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004d16:	6843      	ldr	r3, [r0, #4]
 8004d18:	685b      	ldr	r3, [r3, #4]
  * @param  GPIOx GPIO Port
  * @retval Input data register value of port
  */
__STATIC_INLINE uint32_t LL_GPIO_ReadInputPort(GPIO_TypeDef *GPIOx)
{
  return (uint32_t)(READ_REG(GPIOx->IDR));
 8004d1a:	691b      	ldr	r3, [r3, #16]
	*value = LL_GPIO_ReadInputPort(gpio);
 8004d1c:	600b      	str	r3, [r1, #0]
}
 8004d1e:	2000      	movs	r0, #0
 8004d20:	4770      	bx	lr

08004d22 <gpio_stm32_port_set_masked_raw>:
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004d22:	6843      	ldr	r3, [r0, #4]
 8004d24:	685b      	ldr	r3, [r3, #4]
  * @param  GPIOx GPIO Port
  * @retval Output data register value of port
  */
__STATIC_INLINE uint32_t LL_GPIO_ReadOutputPort(GPIO_TypeDef *GPIOx)
{
  return (uint32_t)(READ_REG(GPIOx->ODR));
 8004d26:	6958      	ldr	r0, [r3, #20]
	LL_GPIO_WriteOutputPort(gpio, (port_value & ~mask) | (mask & value));
 8004d28:	4042      	eors	r2, r0
 8004d2a:	400a      	ands	r2, r1
 8004d2c:	4042      	eors	r2, r0
  WRITE_REG(GPIOx->ODR, PortValue);
 8004d2e:	615a      	str	r2, [r3, #20]
}
 8004d30:	2000      	movs	r0, #0
 8004d32:	4770      	bx	lr

08004d34 <gpio_stm32_port_set_bits_raw>:
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004d34:	6843      	ldr	r3, [r0, #4]
 8004d36:	685b      	ldr	r3, [r3, #4]
}
 8004d38:	2000      	movs	r0, #0
	WRITE_REG(gpio->BSRR, pins);
 8004d3a:	6199      	str	r1, [r3, #24]
}
 8004d3c:	4770      	bx	lr

08004d3e <gpio_stm32_port_clear_bits_raw>:
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004d3e:	6843      	ldr	r3, [r0, #4]
 8004d40:	685b      	ldr	r3, [r3, #4]
  *         @arg @ref LL_GPIO_PIN_ALL
  * @retval None
  */
__STATIC_INLINE void LL_GPIO_ResetOutputPin(GPIO_TypeDef *GPIOx, uint32_t PinMask)
{
  WRITE_REG(GPIOx->BSRR, (PinMask << 16));
 8004d42:	0409      	lsls	r1, r1, #16
 8004d44:	6199      	str	r1, [r3, #24]
}
 8004d46:	2000      	movs	r0, #0
 8004d48:	4770      	bx	lr

08004d4a <gpio_stm32_port_toggle_bits>:
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004d4a:	6843      	ldr	r3, [r0, #4]
 8004d4c:	685a      	ldr	r2, [r3, #4]
	WRITE_REG(gpio->ODR, READ_REG(gpio->ODR) ^ pins);
 8004d4e:	6953      	ldr	r3, [r2, #20]
 8004d50:	404b      	eors	r3, r1
 8004d52:	6153      	str	r3, [r2, #20]
}
 8004d54:	2000      	movs	r0, #0
 8004d56:	4770      	bx	lr

08004d58 <gpio_stm32_configure_raw.isra.0>:
static void gpio_stm32_configure_raw(const struct device *dev, int pin,
 8004d58:	b5f0      	push	{r4, r5, r6, r7, lr}
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004d5a:	6844      	ldr	r4, [r0, #4]
	pinval = 1 << pin;
 8004d5c:	2001      	movs	r0, #1
  MODIFY_REG(GPIOx->OTYPER, PinMask, (PinMask * OutputType));
 8004d5e:	6867      	ldr	r7, [r4, #4]
 8004d60:	4088      	lsls	r0, r1
static void gpio_stm32_configure_raw(const struct device *dev, int pin,
 8004d62:	461e      	mov	r6, r3
	LL_GPIO_SetPinOutputType(gpio, pin_ll, otype >> STM32_OTYPER_SHIFT);
 8004d64:	f3c2 1380 	ubfx	r3, r2, #6, #1
 8004d68:	ea27 0700 	bic.w	r7, r7, r0
 8004d6c:	408b      	lsls	r3, r1
 8004d6e:	433b      	orrs	r3, r7
 8004d70:	6063      	str	r3, [r4, #4]
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004d72:	fa90 f7a0 	rbit	r7, r0
  return __builtin_clz(value);
 8004d76:	fab7 f787 	clz	r7, r7
  MODIFY_REG(GPIOx->OSPEEDR, (GPIO_OSPEEDER_OSPEEDR0 << (POSITION_VAL(Pin) * 2U)),
 8004d7a:	f8d4 c008 	ldr.w	ip, [r4, #8]
 8004d7e:	f04f 0e03 	mov.w	lr, #3
 8004d82:	007f      	lsls	r7, r7, #1
 8004d84:	fa0e f707 	lsl.w	r7, lr, r7
 8004d88:	ea2c 0c07 	bic.w	ip, ip, r7
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004d8c:	fa90 f7a0 	rbit	r7, r0
  return __builtin_clz(value);
 8004d90:	fab7 f787 	clz	r7, r7
	LL_GPIO_SetPinSpeed(gpio, pin_ll, ospeed >> STM32_OSPEEDR_SHIFT);
 8004d94:	f3c2 13c1 	ubfx	r3, r2, #7, #2
 8004d98:	007f      	lsls	r7, r7, #1
 8004d9a:	40bb      	lsls	r3, r7
 8004d9c:	ea43 030c 	orr.w	r3, r3, ip
 8004da0:	60a3      	str	r3, [r4, #8]
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004da2:	fa90 f3a0 	rbit	r3, r0
  return __builtin_clz(value);
 8004da6:	fab3 f383 	clz	r3, r3
  MODIFY_REG(GPIOx->PUPDR, (GPIO_PUPDR_PUPDR0 << (POSITION_VAL(Pin) * 2U)), (Pull << (POSITION_VAL(Pin) * 2U)));
 8004daa:	68e7      	ldr	r7, [r4, #12]
 8004dac:	005b      	lsls	r3, r3, #1
 8004dae:	fa0e f303 	lsl.w	r3, lr, r3
 8004db2:	ea27 0703 	bic.w	r7, r7, r3
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004db6:	fa90 f3a0 	rbit	r3, r0
  return __builtin_clz(value);
 8004dba:	fab3 f383 	clz	r3, r3
 8004dbe:	f002 0530 	and.w	r5, r2, #48	; 0x30
 8004dc2:	005b      	lsls	r3, r3, #1
	LL_GPIO_SetPinPull(gpio, pin_ll, pupd >> STM32_PUPDR_SHIFT);
 8004dc4:	f3c2 2241 	ubfx	r2, r2, #9, #2
 8004dc8:	409a      	lsls	r2, r3
 8004dca:	433a      	orrs	r2, r7
	if (mode == STM32_MODER_ALT_MODE) {
 8004dcc:	2d20      	cmp	r5, #32
 8004dce:	60e2      	str	r2, [r4, #12]
 8004dd0:	d116      	bne.n	8004e00 <gpio_stm32_configure_raw.isra.0+0xa8>
		if (pin < 8) {
 8004dd2:	2907      	cmp	r1, #7
 8004dd4:	dc2b      	bgt.n	8004e2e <gpio_stm32_configure_raw.isra.0+0xd6>
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004dd6:	fa90 f3a0 	rbit	r3, r0
  MODIFY_REG(GPIOx->AFR[0], (GPIO_AFRL_AFSEL0 << (POSITION_VAL(Pin) * 4U)),
 8004dda:	6a22      	ldr	r2, [r4, #32]
  if (value == 0U)
 8004ddc:	b32b      	cbz	r3, 8004e2a <gpio_stm32_configure_raw.isra.0+0xd2>
  return __builtin_clz(value);
 8004dde:	fab3 f383 	clz	r3, r3
 8004de2:	009b      	lsls	r3, r3, #2
 8004de4:	210f      	movs	r1, #15
 8004de6:	fa01 f303 	lsl.w	r3, r1, r3
 8004dea:	ea22 0203 	bic.w	r2, r2, r3
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004dee:	fa90 f3a0 	rbit	r3, r0
  return __builtin_clz(value);
 8004df2:	fab3 f383 	clz	r3, r3
 8004df6:	009b      	lsls	r3, r3, #2
 8004df8:	fa06 f303 	lsl.w	r3, r6, r3
 8004dfc:	4313      	orrs	r3, r2
 8004dfe:	6223      	str	r3, [r4, #32]
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004e00:	fa90 f3a0 	rbit	r3, r0
  return __builtin_clz(value);
 8004e04:	fab3 f383 	clz	r3, r3
  MODIFY_REG(GPIOx->MODER, (GPIO_MODER_MODER0 << (POSITION_VAL(Pin) * 2U)), (Mode << (POSITION_VAL(Pin) * 2U)));
 8004e08:	6822      	ldr	r2, [r4, #0]
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004e0a:	fa90 f0a0 	rbit	r0, r0
 8004e0e:	005b      	lsls	r3, r3, #1
 8004e10:	2103      	movs	r1, #3
  return __builtin_clz(value);
 8004e12:	fab0 f080 	clz	r0, r0
	LL_GPIO_SetPinMode(gpio, pin_ll, mode >> STM32_MODER_SHIFT);
 8004e16:	092d      	lsrs	r5, r5, #4
 8004e18:	fa01 f303 	lsl.w	r3, r1, r3
 8004e1c:	0040      	lsls	r0, r0, #1
 8004e1e:	ea22 0303 	bic.w	r3, r2, r3
 8004e22:	4085      	lsls	r5, r0
 8004e24:	431d      	orrs	r5, r3
 8004e26:	6025      	str	r5, [r4, #0]
}
 8004e28:	bdf0      	pop	{r4, r5, r6, r7, pc}
    return 32U;
 8004e2a:	462b      	mov	r3, r5
 8004e2c:	e7d9      	b.n	8004de2 <gpio_stm32_configure_raw.isra.0+0x8a>
  MODIFY_REG(GPIOx->AFR[1], (GPIO_AFRH_AFSEL8 << (POSITION_VAL(Pin >> 8U) * 4U)),
 8004e2e:	0a03      	lsrs	r3, r0, #8
 8004e30:	6a61      	ldr	r1, [r4, #36]	; 0x24
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004e32:	fa93 f2a3 	rbit	r2, r3
  if (value == 0U)
 8004e36:	b182      	cbz	r2, 8004e5a <gpio_stm32_configure_raw.isra.0+0x102>
  return __builtin_clz(value);
 8004e38:	fab2 f282 	clz	r2, r2
 8004e3c:	0092      	lsls	r2, r2, #2
 8004e3e:	270f      	movs	r7, #15
   __ASM ("rbit %0, %1" : "=r" (result) : "r" (value) );
 8004e40:	fa93 f3a3 	rbit	r3, r3
  return __builtin_clz(value);
 8004e44:	fab3 f383 	clz	r3, r3
 8004e48:	fa07 f202 	lsl.w	r2, r7, r2
 8004e4c:	009b      	lsls	r3, r3, #2
 8004e4e:	ea21 0202 	bic.w	r2, r1, r2
 8004e52:	409e      	lsls	r6, r3
 8004e54:	4316      	orrs	r6, r2
 8004e56:	6266      	str	r6, [r4, #36]	; 0x24
}
 8004e58:	e7d2      	b.n	8004e00 <gpio_stm32_configure_raw.isra.0+0xa8>
    return 32U;
 8004e5a:	462a      	mov	r2, r5
 8004e5c:	e7ee      	b.n	8004e3c <gpio_stm32_configure_raw.isra.0+0xe4>

08004e5e <gpio_stm32_config>:
{
 8004e5e:	b538      	push	{r3, r4, r5, lr}
 8004e60:	4604      	mov	r4, r0
	if ((flags & GPIO_OUTPUT) != 0) {
 8004e62:	0390      	lsls	r0, r2, #14
{
 8004e64:	460d      	mov	r5, r1
 8004e66:	4613      	mov	r3, r2
	if ((flags & GPIO_OUTPUT) != 0) {
 8004e68:	d517      	bpl.n	8004e9a <gpio_stm32_config+0x3c>
		if ((flags & GPIO_SINGLE_ENDED) != 0) {
 8004e6a:	0791      	lsls	r1, r2, #30
 8004e6c:	d50e      	bpl.n	8004e8c <gpio_stm32_config+0x2e>
			if (flags & GPIO_LINE_OPEN_DRAIN) {
 8004e6e:	075a      	lsls	r2, r3, #29
 8004e70:	d52e      	bpl.n	8004ed0 <gpio_stm32_config+0x72>
				*pincfg |= STM32_PINCFG_OPEN_DRAIN;
 8004e72:	2250      	movs	r2, #80	; 0x50
		if ((flags & GPIO_PULL_UP) != 0) {
 8004e74:	06d8      	lsls	r0, r3, #27
 8004e76:	d50b      	bpl.n	8004e90 <gpio_stm32_config+0x32>
			*pincfg |= STM32_PINCFG_PULL_UP;
 8004e78:	f442 7200 	orr.w	r2, r2, #512	; 0x200
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
 8004e7c:	0319      	lsls	r1, r3, #12
 8004e7e:	d51a      	bpl.n	8004eb6 <gpio_stm32_config+0x58>
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004e80:	6861      	ldr	r1, [r4, #4]
			gpio_stm32_port_set_bits_raw(dev, BIT(pin));
 8004e82:	2301      	movs	r3, #1
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004e84:	6849      	ldr	r1, [r1, #4]
			gpio_stm32_port_set_bits_raw(dev, BIT(pin));
 8004e86:	40ab      	lsls	r3, r5
	WRITE_REG(gpio->BSRR, pins);
 8004e88:	618b      	str	r3, [r1, #24]
	return 0;
 8004e8a:	e00d      	b.n	8004ea8 <gpio_stm32_config+0x4a>
		*pincfg = STM32_PINCFG_MODE_OUTPUT;
 8004e8c:	2210      	movs	r2, #16
 8004e8e:	e7f1      	b.n	8004e74 <gpio_stm32_config+0x16>
		} else if ((flags & GPIO_PULL_DOWN) != 0) {
 8004e90:	0699      	lsls	r1, r3, #26
 8004e92:	d5f3      	bpl.n	8004e7c <gpio_stm32_config+0x1e>
			*pincfg |= STM32_PINCFG_PULL_DOWN;
 8004e94:	f442 6280 	orr.w	r2, r2, #1024	; 0x400
	if (err != 0) {
 8004e98:	e7f0      	b.n	8004e7c <gpio_stm32_config+0x1e>
	} else if  ((flags & GPIO_INPUT) != 0) {
 8004e9a:	03da      	lsls	r2, r3, #15
 8004e9c:	d513      	bpl.n	8004ec6 <gpio_stm32_config+0x68>
		if ((flags & GPIO_PULL_UP) != 0) {
 8004e9e:	06d8      	lsls	r0, r3, #27
 8004ea0:	d413      	bmi.n	8004eca <gpio_stm32_config+0x6c>
		} else if ((flags & GPIO_PULL_DOWN) != 0) {
 8004ea2:	f3c3 1340 	ubfx	r3, r3, #5, #1
 8004ea6:	029a      	lsls	r2, r3, #10
	gpio_stm32_configure_raw(dev, pin, pincfg, 0);
 8004ea8:	6860      	ldr	r0, [r4, #4]
 8004eaa:	2300      	movs	r3, #0
 8004eac:	4629      	mov	r1, r5
 8004eae:	f7ff ff53 	bl	8004d58 <gpio_stm32_configure_raw.isra.0>
	return 0;
 8004eb2:	2000      	movs	r0, #0
}
 8004eb4:	bd38      	pop	{r3, r4, r5, pc}
		} else if ((flags & GPIO_OUTPUT_INIT_LOW) != 0) {
 8004eb6:	035b      	lsls	r3, r3, #13
 8004eb8:	d5f6      	bpl.n	8004ea8 <gpio_stm32_config+0x4a>
			gpio_stm32_port_clear_bits_raw(dev, BIT(pin));
 8004eba:	2101      	movs	r1, #1
 8004ebc:	40a9      	lsls	r1, r5
 8004ebe:	4620      	mov	r0, r4
 8004ec0:	f7ff ff3d 	bl	8004d3e <gpio_stm32_port_clear_bits_raw>
 8004ec4:	e7f0      	b.n	8004ea8 <gpio_stm32_config+0x4a>
		*pincfg = STM32_PINCFG_MODE_ANALOG;
 8004ec6:	2230      	movs	r2, #48	; 0x30
 8004ec8:	e7ee      	b.n	8004ea8 <gpio_stm32_config+0x4a>
			*pincfg |= STM32_PINCFG_PULL_UP;
 8004eca:	f44f 7200 	mov.w	r2, #512	; 0x200
 8004ece:	e7eb      	b.n	8004ea8 <gpio_stm32_config+0x4a>
				return -ENOTSUP;
 8004ed0:	f06f 0085 	mvn.w	r0, #133	; 0x85
 8004ed4:	e7ee      	b.n	8004eb4 <gpio_stm32_config+0x56>

08004ed6 <gpio_stm32_configure>:
{
 8004ed6:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
 8004ed8:	461f      	mov	r7, r3
 8004eda:	4604      	mov	r4, r0
	gpio_stm32_configure_raw(dev, pin, conf, func);
 8004edc:	6840      	ldr	r0, [r0, #4]
{
 8004ede:	460e      	mov	r6, r1
 8004ee0:	4615      	mov	r5, r2
	gpio_stm32_configure_raw(dev, pin, conf, func);
 8004ee2:	f7ff ff39 	bl	8004d58 <gpio_stm32_configure_raw.isra.0>
	if (func == IS_GPIO_OUT) {
 8004ee6:	2f11      	cmp	r7, #17
 8004ee8:	d107      	bne.n	8004efa <gpio_stm32_configure+0x24>
			gpio_stm32_port_set_bits_raw(dev, BIT(pin));
 8004eea:	2101      	movs	r1, #1
		if (gpio_out == STM32_ODR_1) {
 8004eec:	052b      	lsls	r3, r5, #20
			gpio_stm32_port_set_bits_raw(dev, BIT(pin));
 8004eee:	fa01 f106 	lsl.w	r1, r1, r6
		if (gpio_out == STM32_ODR_1) {
 8004ef2:	d504      	bpl.n	8004efe <gpio_stm32_configure+0x28>
	GPIO_TypeDef *gpio = (GPIO_TypeDef *)cfg->base;
 8004ef4:	6863      	ldr	r3, [r4, #4]
 8004ef6:	685b      	ldr	r3, [r3, #4]
	WRITE_REG(gpio->BSRR, pins);
 8004ef8:	6199      	str	r1, [r3, #24]
}
 8004efa:	2000      	movs	r0, #0
 8004efc:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
			gpio_stm32_port_clear_bits_raw(dev, BIT(pin));
 8004efe:	4620      	mov	r0, r4
 8004f00:	f7ff ff1d 	bl	8004d3e <gpio_stm32_port_clear_bits_raw>
 8004f04:	e7f9      	b.n	8004efa <gpio_stm32_configure+0x24>

08004f06 <LL_USART_ClearFlag_FE>:
{
 8004f06:	b082      	sub	sp, #8
  tmpreg = USARTx->SR;
 8004f08:	6803      	ldr	r3, [r0, #0]
 8004f0a:	9301      	str	r3, [sp, #4]
  (void) tmpreg;
 8004f0c:	9b01      	ldr	r3, [sp, #4]
  tmpreg = USARTx->DR;
 8004f0e:	6843      	ldr	r3, [r0, #4]
 8004f10:	9301      	str	r3, [sp, #4]
  (void) tmpreg;
 8004f12:	9b01      	ldr	r3, [sp, #4]
}
 8004f14:	b002      	add	sp, #8
 8004f16:	4770      	bx	lr

08004f18 <uart_stm32_poll_in>:
{
 8004f18:	b508      	push	{r3, lr}
	if (LL_USART_IsActiveFlag_ORE(config->usart)) {
 8004f1a:	6843      	ldr	r3, [r0, #4]
 8004f1c:	6818      	ldr	r0, [r3, #0]
  return (READ_BIT(USARTx->SR, USART_SR_ORE) == (USART_SR_ORE));
 8004f1e:	6803      	ldr	r3, [r0, #0]
 8004f20:	071a      	lsls	r2, r3, #28
 8004f22:	d501      	bpl.n	8004f28 <uart_stm32_poll_in+0x10>
		LL_USART_ClearFlag_ORE(config->usart);
 8004f24:	f7ff ffef 	bl	8004f06 <LL_USART_ClearFlag_FE>
  return (READ_BIT(USARTx->SR, USART_SR_RXNE) == (USART_SR_RXNE));
 8004f28:	6803      	ldr	r3, [r0, #0]
	if (!LL_USART_IsActiveFlag_RXNE(config->usart)) {
 8004f2a:	069b      	lsls	r3, r3, #26
  * @param  USARTx USART Instance
  * @retval Value between Min_Data=0x00 and Max_Data=0xFF
  */
__STATIC_INLINE uint8_t LL_USART_ReceiveData8(USART_TypeDef *USARTx)
{
  return (uint8_t)(READ_BIT(USARTx->DR, USART_DR_DR));
 8004f2c:	bf43      	ittte	mi
 8004f2e:	6843      	ldrmi	r3, [r0, #4]
 8004f30:	700b      	strbmi	r3, [r1, #0]
	return 0;
 8004f32:	2000      	movmi	r0, #0
		return -1;
 8004f34:	f04f 30ff 	movpl.w	r0, #4294967295	; 0xffffffff
}
 8004f38:	bd08      	pop	{r3, pc}

08004f3a <uart_stm32_poll_out>:
{
 8004f3a:	b510      	push	{r4, lr}
	const struct uart_stm32_config *config = dev->config;
 8004f3c:	6840      	ldr	r0, [r0, #4]
		if (LL_USART_IsActiveFlag_TXE(config->usart)) {
 8004f3e:	6802      	ldr	r2, [r0, #0]
  return (READ_BIT(USARTx->SR, USART_SR_TXE) == (USART_SR_TXE));
 8004f40:	6813      	ldr	r3, [r2, #0]
 8004f42:	061b      	lsls	r3, r3, #24
 8004f44:	d5fc      	bpl.n	8004f40 <uart_stm32_poll_out+0x6>
	__asm__ volatile(
 8004f46:	f04f 0210 	mov.w	r2, #16
 8004f4a:	f3ef 8311 	mrs	r3, BASEPRI
 8004f4e:	f382 8812 	msr	BASEPRI_MAX, r2
 8004f52:	f3bf 8f6f 	isb	sy
			if (LL_USART_IsActiveFlag_TXE(config->usart)) {
 8004f56:	6802      	ldr	r2, [r0, #0]
 8004f58:	6814      	ldr	r4, [r2, #0]
 8004f5a:	0624      	lsls	r4, r4, #24
 8004f5c:	d404      	bmi.n	8004f68 <uart_stm32_poll_out+0x2e>
	__asm__ volatile(
 8004f5e:	f383 8811 	msr	BASEPRI, r3
 8004f62:	f3bf 8f6f 	isb	sy
		"cpsie i;"
		: : : "memory", "cc");
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
}
 8004f66:	e7ea      	b.n	8004f3e <uart_stm32_poll_out+0x4>
  * @param  Value between Min_Data=0x00 and Max_Data=0xFF
  * @retval None
  */
__STATIC_INLINE void LL_USART_TransmitData8(USART_TypeDef *USARTx, uint8_t Value)
{
  USARTx->DR = Value;
 8004f68:	6051      	str	r1, [r2, #4]
	__asm__ volatile(
 8004f6a:	f383 8811 	msr	BASEPRI, r3
 8004f6e:	f3bf 8f6f 	isb	sy
}
 8004f72:	bd10      	pop	{r4, pc}

08004f74 <uart_stm32_err_check>:
{
 8004f74:	b508      	push	{r3, lr}
	const struct uart_stm32_config *config = dev->config;
 8004f76:	6841      	ldr	r1, [r0, #4]
	if (LL_USART_IsActiveFlag_ORE(config->usart)) {
 8004f78:	680b      	ldr	r3, [r1, #0]
  return (READ_BIT(USARTx->SR, USART_SR_ORE) == (USART_SR_ORE));
 8004f7a:	681a      	ldr	r2, [r3, #0]
  return (READ_BIT(USARTx->SR, USART_SR_PE) == (USART_SR_PE));
 8004f7c:	6818      	ldr	r0, [r3, #0]
	if (LL_USART_IsActiveFlag_PE(config->usart)) {
 8004f7e:	07c0      	lsls	r0, r0, #31
  return (READ_BIT(USARTx->SR, USART_SR_FE) == (USART_SR_FE));
 8004f80:	6818      	ldr	r0, [r3, #0]
	if (LL_USART_IsActiveFlag_ORE(config->usart)) {
 8004f82:	f3c2 02c0 	ubfx	r2, r2, #3, #1
		err |= UART_ERROR_PARITY;
 8004f86:	bf48      	it	mi
 8004f88:	f042 0202 	orrmi.w	r2, r2, #2
	if (LL_USART_IsActiveFlag_FE(config->usart)) {
 8004f8c:	0780      	lsls	r0, r0, #30
  return (READ_BIT(USARTx->SR, USART_SR_NE) == (USART_SR_NE));
 8004f8e:	6818      	ldr	r0, [r3, #0]
		err |= UART_ERROR_FRAMING;
 8004f90:	bf48      	it	mi
 8004f92:	f042 0204 	orrmi.w	r2, r2, #4
	if (LL_USART_IsActiveFlag_NE(config->usart)) {
 8004f96:	0740      	lsls	r0, r0, #29
  return (READ_BIT(USARTx->SR, USART_SR_LBD) == (USART_SR_LBD));
 8004f98:	6818      	ldr	r0, [r3, #0]
		err |= UART_ERROR_NOISE;
 8004f9a:	bf48      	it	mi
 8004f9c:	f042 0220 	orrmi.w	r2, r2, #32
	if (LL_USART_IsActiveFlag_LBD(config->usart)) {
 8004fa0:	05c0      	lsls	r0, r0, #23
  WRITE_REG(USARTx->SR, ~(USART_SR_LBD));
 8004fa2:	bf42      	ittt	mi
 8004fa4:	f46f 7080 	mvnmi.w	r0, #256	; 0x100
		err |= UART_BREAK;
 8004fa8:	f042 0208 	orrmi.w	r2, r2, #8
 8004fac:	6018      	strmi	r0, [r3, #0]
	if (err & UART_ERROR_OVERRUN) {
 8004fae:	07d0      	lsls	r0, r2, #31
 8004fb0:	d502      	bpl.n	8004fb8 <uart_stm32_err_check+0x44>
		LL_USART_ClearFlag_ORE(config->usart);
 8004fb2:	6808      	ldr	r0, [r1, #0]
 8004fb4:	f7ff ffa7 	bl	8004f06 <LL_USART_ClearFlag_FE>
	if (err & UART_ERROR_PARITY) {
 8004fb8:	0793      	lsls	r3, r2, #30
 8004fba:	d502      	bpl.n	8004fc2 <uart_stm32_err_check+0x4e>
		LL_USART_ClearFlag_PE(config->usart);
 8004fbc:	6808      	ldr	r0, [r1, #0]
 8004fbe:	f7ff ffa2 	bl	8004f06 <LL_USART_ClearFlag_FE>
	if (err & UART_ERROR_FRAMING) {
 8004fc2:	0750      	lsls	r0, r2, #29
 8004fc4:	d502      	bpl.n	8004fcc <uart_stm32_err_check+0x58>
		LL_USART_ClearFlag_FE(config->usart);
 8004fc6:	6808      	ldr	r0, [r1, #0]
 8004fc8:	f7ff ff9d 	bl	8004f06 <LL_USART_ClearFlag_FE>
	if (err & UART_ERROR_NOISE) {
 8004fcc:	0693      	lsls	r3, r2, #26
 8004fce:	d502      	bpl.n	8004fd6 <uart_stm32_err_check+0x62>
		LL_USART_ClearFlag_NE(config->usart);
 8004fd0:	6808      	ldr	r0, [r1, #0]
 8004fd2:	f7ff ff98 	bl	8004f06 <LL_USART_ClearFlag_FE>
}
 8004fd6:	4610      	mov	r0, r2
 8004fd8:	bd08      	pop	{r3, pc}

08004fda <uart_stm32_fifo_fill>:
{
 8004fda:	b5f0      	push	{r4, r5, r6, r7, lr}
	const struct uart_stm32_config *config = dev->config;
 8004fdc:	6846      	ldr	r6, [r0, #4]
	if (!LL_USART_IsActiveFlag_TXE(config->usart)) {
 8004fde:	6833      	ldr	r3, [r6, #0]
  return (READ_BIT(USARTx->SR, USART_SR_TXE) == (USART_SR_TXE));
 8004fe0:	6818      	ldr	r0, [r3, #0]
 8004fe2:	f010 0080 	ands.w	r0, r0, #128	; 0x80
 8004fe6:	d010      	beq.n	800500a <uart_stm32_fifo_fill+0x30>
	__asm__ volatile(
 8004fe8:	f04f 0310 	mov.w	r3, #16
 8004fec:	f3ef 8711 	mrs	r7, BASEPRI
 8004ff0:	f383 8812 	msr	BASEPRI_MAX, r3
 8004ff4:	f3bf 8f6f 	isb	sy
	while ((size - num_tx > 0) &&
 8004ff8:	2300      	movs	r3, #0
 8004ffa:	b2dc      	uxtb	r4, r3
 8004ffc:	42a2      	cmp	r2, r4
 8004ffe:	4620      	mov	r0, r4
 8005000:	dc04      	bgt.n	800500c <uart_stm32_fifo_fill+0x32>
	__asm__ volatile(
 8005002:	f387 8811 	msr	BASEPRI, r7
 8005006:	f3bf 8f6f 	isb	sy
}
 800500a:	bdf0      	pop	{r4, r5, r6, r7, pc}
	       LL_USART_IsActiveFlag_TXE(config->usart)) {
 800500c:	6835      	ldr	r5, [r6, #0]
 800500e:	f8d5 c000 	ldr.w	ip, [r5]
	while ((size - num_tx > 0) &&
 8005012:	f01c 0f80 	tst.w	ip, #128	; 0x80
 8005016:	f103 0301 	add.w	r3, r3, #1
 800501a:	d0f2      	beq.n	8005002 <uart_stm32_fifo_fill+0x28>
  USARTx->DR = Value;
 800501c:	5d08      	ldrb	r0, [r1, r4]
 800501e:	6068      	str	r0, [r5, #4]
}
 8005020:	e7eb      	b.n	8004ffa <uart_stm32_fifo_fill+0x20>

08005022 <uart_stm32_fifo_read>:
{
 8005022:	b570      	push	{r4, r5, r6, lr}
	const struct uart_stm32_config *config = dev->config;
 8005024:	6845      	ldr	r5, [r0, #4]
	while ((size - num_rx > 0) &&
 8005026:	2400      	movs	r4, #0
 8005028:	b2e0      	uxtb	r0, r4
 800502a:	4282      	cmp	r2, r0
 800502c:	dd03      	ble.n	8005036 <uart_stm32_fifo_read+0x14>
	       LL_USART_IsActiveFlag_RXNE(config->usart)) {
 800502e:	682b      	ldr	r3, [r5, #0]
  return (READ_BIT(USARTx->SR, USART_SR_RXNE) == (USART_SR_RXNE));
 8005030:	681e      	ldr	r6, [r3, #0]
	while ((size - num_rx > 0) &&
 8005032:	06b6      	lsls	r6, r6, #26
 8005034:	d400      	bmi.n	8005038 <uart_stm32_fifo_read+0x16>
}
 8005036:	bd70      	pop	{r4, r5, r6, pc}
  return (uint8_t)(READ_BIT(USARTx->DR, USART_DR_DR));
 8005038:	685b      	ldr	r3, [r3, #4]
 800503a:	540b      	strb	r3, [r1, r0]
		if (LL_USART_IsActiveFlag_ORE(config->usart)) {
 800503c:	6828      	ldr	r0, [r5, #0]
  return (READ_BIT(USARTx->SR, USART_SR_ORE) == (USART_SR_ORE));
 800503e:	6803      	ldr	r3, [r0, #0]
 8005040:	071b      	lsls	r3, r3, #28
 8005042:	d501      	bpl.n	8005048 <uart_stm32_fifo_read+0x26>
			LL_USART_ClearFlag_ORE(config->usart);
 8005044:	f7ff ff5f 	bl	8004f06 <LL_USART_ClearFlag_FE>
 8005048:	3401      	adds	r4, #1
 800504a:	e7ed      	b.n	8005028 <uart_stm32_fifo_read+0x6>

0800504c <uart_stm32_irq_tx_enable>:
	LL_USART_EnableIT_TC(config->usart);
 800504c:	6843      	ldr	r3, [r0, #4]
 800504e:	681a      	ldr	r2, [r3, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 8005050:	f102 030c 	add.w	r3, r2, #12
 8005054:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_SET_BIT(USARTx->CR1, USART_CR1_TCIE);
 8005058:	f043 0340 	orr.w	r3, r3, #64	; 0x40
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 800505c:	f102 000c 	add.w	r0, r2, #12
 8005060:	e840 3100 	strex	r1, r3, [r0]
 8005064:	2900      	cmp	r1, #0
 8005066:	d1f3      	bne.n	8005050 <uart_stm32_irq_tx_enable+0x4>
}
 8005068:	4770      	bx	lr

0800506a <uart_stm32_irq_tx_disable>:
	LL_USART_DisableIT_TC(config->usart);
 800506a:	6843      	ldr	r3, [r0, #4]
 800506c:	681a      	ldr	r2, [r3, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 800506e:	f102 030c 	add.w	r3, r2, #12
 8005072:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_CLEAR_BIT(USARTx->CR1, USART_CR1_TCIE);
 8005076:	f023 0340 	bic.w	r3, r3, #64	; 0x40
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 800507a:	f102 000c 	add.w	r0, r2, #12
 800507e:	e840 3100 	strex	r1, r3, [r0]
 8005082:	2900      	cmp	r1, #0
 8005084:	d1f3      	bne.n	800506e <uart_stm32_irq_tx_disable+0x4>
}
 8005086:	4770      	bx	lr

08005088 <uart_stm32_irq_tx_ready>:
	return LL_USART_IsActiveFlag_TXE(config->usart) &&
 8005088:	6843      	ldr	r3, [r0, #4]
 800508a:	681b      	ldr	r3, [r3, #0]
  return (READ_BIT(USARTx->SR, USART_SR_TXE) == (USART_SR_TXE));
 800508c:	6818      	ldr	r0, [r3, #0]
 800508e:	f010 0080 	ands.w	r0, r0, #128	; 0x80
  return (READ_BIT(USARTx->CR1, USART_CR1_TCIE) == (USART_CR1_TCIE));
 8005092:	bf1c      	itt	ne
 8005094:	68d8      	ldrne	r0, [r3, #12]
 8005096:	f3c0 1080 	ubfxne	r0, r0, #6, #1
}
 800509a:	4770      	bx	lr

0800509c <uart_stm32_irq_tx_complete>:
	return LL_USART_IsActiveFlag_TC(config->usart);
 800509c:	6843      	ldr	r3, [r0, #4]
 800509e:	681b      	ldr	r3, [r3, #0]
  return (READ_BIT(USARTx->SR, USART_SR_TC) == (USART_SR_TC));
 80050a0:	6818      	ldr	r0, [r3, #0]
}
 80050a2:	f3c0 1080 	ubfx	r0, r0, #6, #1
 80050a6:	4770      	bx	lr

080050a8 <uart_stm32_irq_rx_enable>:
	LL_USART_EnableIT_RXNE(config->usart);
 80050a8:	6843      	ldr	r3, [r0, #4]
 80050aa:	681a      	ldr	r2, [r3, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 80050ac:	f102 030c 	add.w	r3, r2, #12
 80050b0:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_SET_BIT(USARTx->CR1, USART_CR1_RXNEIE);
 80050b4:	f043 0320 	orr.w	r3, r3, #32
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 80050b8:	f102 000c 	add.w	r0, r2, #12
 80050bc:	e840 3100 	strex	r1, r3, [r0]
 80050c0:	2900      	cmp	r1, #0
 80050c2:	d1f3      	bne.n	80050ac <uart_stm32_irq_rx_enable+0x4>
}
 80050c4:	4770      	bx	lr

080050c6 <uart_stm32_irq_rx_disable>:
	LL_USART_DisableIT_RXNE(config->usart);
 80050c6:	6843      	ldr	r3, [r0, #4]
 80050c8:	681a      	ldr	r2, [r3, #0]
   __ASM volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
 80050ca:	f102 030c 	add.w	r3, r2, #12
 80050ce:	e853 3f00 	ldrex	r3, [r3]
  ATOMIC_CLEAR_BIT(USARTx->CR1, USART_CR1_RXNEIE);
 80050d2:	f023 0320 	bic.w	r3, r3, #32
   __ASM volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
 80050d6:	f102 000c 	add.w	r0, r2, #12
 80050da:	e840 3100 	strex	r1, r3, [r0]
 80050de:	2900      	cmp	r1, #0
 80050e0:	d1f3      	bne.n	80050ca <uart_stm32_irq_rx_disable+0x4>
}
 80050e2:	4770      	bx	lr

080050e4 <uart_stm32_irq_rx_ready>:
	return LL_USART_IsActiveFlag_RXNE(config->usart);
 80050e4:	6843      	ldr	r3, [r0, #4]
 80050e6:	681b      	ldr	r3, [r3, #0]
  return (READ_BIT(USARTx->SR, USART_SR_RXNE) == (USART_SR_RXNE));
 80050e8:	6818      	ldr	r0, [r3, #0]
}
 80050ea:	f3c0 1040 	ubfx	r0, r0, #5, #1
 80050ee:	4770      	bx	lr

080050f0 <uart_stm32_irq_is_pending>:
	return ((LL_USART_IsActiveFlag_RXNE(config->usart) &&
 80050f0:	6843      	ldr	r3, [r0, #4]
 80050f2:	681b      	ldr	r3, [r3, #0]
 80050f4:	681a      	ldr	r2, [r3, #0]
		 LL_USART_IsEnabledIT_RXNE(config->usart)) ||
 80050f6:	0691      	lsls	r1, r2, #26
 80050f8:	d502      	bpl.n	8005100 <uart_stm32_irq_is_pending+0x10>
  return (READ_BIT(USARTx->CR1, USART_CR1_RXNEIE) == (USART_CR1_RXNEIE));
 80050fa:	68da      	ldr	r2, [r3, #12]
	return ((LL_USART_IsActiveFlag_RXNE(config->usart) &&
 80050fc:	0692      	lsls	r2, r2, #26
 80050fe:	d407      	bmi.n	8005110 <uart_stm32_irq_is_pending+0x20>
  return (READ_BIT(USARTx->SR, USART_SR_TC) == (USART_SR_TC));
 8005100:	6818      	ldr	r0, [r3, #0]
		 LL_USART_IsEnabledIT_RXNE(config->usart)) ||
 8005102:	f010 0040 	ands.w	r0, r0, #64	; 0x40
 8005106:	d004      	beq.n	8005112 <uart_stm32_irq_is_pending+0x22>
  return (READ_BIT(USARTx->CR1, USART_CR1_TCIE) == (USART_CR1_TCIE));
 8005108:	68d8      	ldr	r0, [r3, #12]
		(LL_USART_IsActiveFlag_TC(config->usart) &&
 800510a:	f3c0 1080 	ubfx	r0, r0, #6, #1
 800510e:	4770      	bx	lr
		 LL_USART_IsEnabledIT_RXNE(config->usart)) ||
 8005110:	2001      	movs	r0, #1
}
 8005112:	4770      	bx	lr

08005114 <uart_stm32_irq_update>:
}
 8005114:	2001      	movs	r0, #1
 8005116:	4770      	bx	lr

08005118 <uart_stm32_irq_callback_set>:
	struct uart_stm32_data *data = dev->data;
 8005118:	6903      	ldr	r3, [r0, #16]
	data->user_data = cb_data;
 800511a:	e9c3 1204 	strd	r1, r2, [r3, #16]
}
 800511e:	4770      	bx	lr

08005120 <uart_stm32_isr>:
	struct uart_stm32_data *data = dev->data;
 8005120:	6902      	ldr	r2, [r0, #16]
	if (data->user_cb) {
 8005122:	6913      	ldr	r3, [r2, #16]
 8005124:	b10b      	cbz	r3, 800512a <uart_stm32_isr+0xa>
		data->user_cb(dev, data->user_data);
 8005126:	6951      	ldr	r1, [r2, #20]
 8005128:	4718      	bx	r3
}
 800512a:	4770      	bx	lr

0800512c <uart_stm32_irq_config_func_0>:
		    PRE_KERNEL_1, CONFIG_SERIAL_INIT_PRIORITY,		\
		    &uart_stm32_driver_api);				\
									\
STM32_UART_IRQ_HANDLER(index)

DT_INST_FOREACH_STATUS_OKAY(STM32_UART_INIT)
 800512c:	b508      	push	{r3, lr}
 800512e:	2200      	movs	r2, #0
 8005130:	2026      	movs	r0, #38	; 0x26
 8005132:	4611      	mov	r1, r2
 8005134:	f7fc f88a 	bl	800124c <z_arm_irq_priority_set>
 8005138:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
 800513c:	2026      	movs	r0, #38	; 0x26
 800513e:	f7fc b877 	b.w	8001230 <arch_irq_enable>

08005142 <uart_stm32_config_get>:
	cfg->baudrate = data->baud_rate;
 8005142:	6903      	ldr	r3, [r0, #16]
 8005144:	681b      	ldr	r3, [r3, #0]
 8005146:	600b      	str	r3, [r1, #0]
	return LL_USART_GetParity(config->usart);
 8005148:	6843      	ldr	r3, [r0, #4]
 800514a:	681b      	ldr	r3, [r3, #0]
  return (uint32_t)(READ_BIT(USARTx->CR1, USART_CR1_PS | USART_CR1_PCE));
 800514c:	68db      	ldr	r3, [r3, #12]
 800514e:	f403 63c0 	and.w	r3, r3, #1536	; 0x600
	switch (parity) {
 8005152:	f5b3 6f80 	cmp.w	r3, #1024	; 0x400
 8005156:	d02f      	beq.n	80051b8 <uart_stm32_config_get+0x76>
 8005158:	f5a3 6cc0 	sub.w	ip, r3, #1536	; 0x600
 800515c:	f1dc 0300 	rsbs	r3, ip, #0
 8005160:	eb43 030c 	adc.w	r3, r3, ip
	cfg->parity = uart_stm32_ll2cfg_parity(uart_stm32_get_parity(dev));
 8005164:	710b      	strb	r3, [r1, #4]
	return LL_USART_GetStopBitsLength(config->usart);
 8005166:	6843      	ldr	r3, [r0, #4]
 8005168:	681b      	ldr	r3, [r3, #0]
  return (uint32_t)(READ_BIT(USARTx->CR2, USART_CR2_STOP));
 800516a:	691b      	ldr	r3, [r3, #16]
 800516c:	f403 5340 	and.w	r3, r3, #12288	; 0x3000
	switch (sb) {
 8005170:	f5b3 5f80 	cmp.w	r3, #4096	; 0x1000
 8005174:	d022      	beq.n	80051bc <uart_stm32_config_get+0x7a>
 8005176:	f5b3 5f40 	cmp.w	r3, #12288	; 0x3000
 800517a:	d021      	beq.n	80051c0 <uart_stm32_config_get+0x7e>
		return UART_CFG_STOP_BITS_2;
 800517c:	2b00      	cmp	r3, #0
 800517e:	bf0c      	ite	eq
 8005180:	2301      	moveq	r3, #1
 8005182:	2303      	movne	r3, #3
	cfg->stop_bits = uart_stm32_ll2cfg_stopbits(
 8005184:	714b      	strb	r3, [r1, #5]
	return LL_USART_GetDataWidth(config->usart);
 8005186:	6843      	ldr	r3, [r0, #4]
 8005188:	681b      	ldr	r3, [r3, #0]
  return (uint32_t)(READ_BIT(USARTx->CR1, USART_CR1_M));
 800518a:	68da      	ldr	r2, [r3, #12]
  return (uint32_t)(READ_BIT(USARTx->CR1, USART_CR1_PS | USART_CR1_PCE));
 800518c:	68db      	ldr	r3, [r3, #12]
	switch (db) {
 800518e:	04d2      	lsls	r2, r2, #19
 8005190:	f403 63c0 	and.w	r3, r3, #1536	; 0x600
 8005194:	d516      	bpl.n	80051c4 <uart_stm32_config_get+0x82>
			return UART_CFG_DATA_BITS_9;
 8005196:	2b00      	cmp	r3, #0
 8005198:	bf14      	ite	ne
 800519a:	2303      	movne	r3, #3
 800519c:	2304      	moveq	r3, #4
	cfg->data_bits = uart_stm32_ll2cfg_databits(
 800519e:	718b      	strb	r3, [r1, #6]
	return LL_USART_GetHWFlowCtrl(config->usart);
 80051a0:	6843      	ldr	r3, [r0, #4]
 80051a2:	681b      	ldr	r3, [r3, #0]
  return (uint32_t)(READ_BIT(USARTx->CR3, USART_CR3_RTSE | USART_CR3_CTSE));
 80051a4:	695b      	ldr	r3, [r3, #20]
 80051a6:	f403 7340 	and.w	r3, r3, #768	; 0x300
	if (fc == LL_USART_HWCONTROL_RTS_CTS) {
 80051aa:	f5a3 7240 	sub.w	r2, r3, #768	; 0x300
 80051ae:	4253      	negs	r3, r2
 80051b0:	4153      	adcs	r3, r2
 80051b2:	71cb      	strb	r3, [r1, #7]
}
 80051b4:	2000      	movs	r0, #0
 80051b6:	4770      	bx	lr
	switch (parity) {
 80051b8:	2302      	movs	r3, #2
 80051ba:	e7d3      	b.n	8005164 <uart_stm32_config_get+0x22>
		return UART_CFG_STOP_BITS_0_5;
 80051bc:	2300      	movs	r3, #0
 80051be:	e7e1      	b.n	8005184 <uart_stm32_config_get+0x42>
		return UART_CFG_STOP_BITS_1_5;
 80051c0:	2302      	movs	r3, #2
 80051c2:	e7df      	b.n	8005184 <uart_stm32_config_get+0x42>
			return UART_CFG_DATA_BITS_8;
 80051c4:	2b00      	cmp	r3, #0
 80051c6:	bf14      	ite	ne
 80051c8:	2302      	movne	r3, #2
 80051ca:	2303      	moveq	r3, #3
 80051cc:	e7e7      	b.n	800519e <uart_stm32_config_get+0x5c>

080051ce <pinctrl_lookup_state>:

#include <zephyr/drivers/pinctrl.h>

int pinctrl_lookup_state(const struct pinctrl_dev_config *config, uint8_t id,
			 const struct pinctrl_state **state)
{
 80051ce:	b530      	push	{r4, r5, lr}
	*state = &config->states[0];
 80051d0:	6803      	ldr	r3, [r0, #0]
 80051d2:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
 80051d4:	7905      	ldrb	r5, [r0, #4]
 80051d6:	6804      	ldr	r4, [r0, #0]
 80051d8:	eb04 04c5 	add.w	r4, r4, r5, lsl #3
 80051dc:	42a3      	cmp	r3, r4
 80051de:	d302      	bcc.n	80051e6 <pinctrl_lookup_state+0x18>
		}

		(*state)++;
	}

	return -ENOENT;
 80051e0:	f06f 0001 	mvn.w	r0, #1
}
 80051e4:	bd30      	pop	{r4, r5, pc}
		if (id == (*state)->id) {
 80051e6:	795c      	ldrb	r4, [r3, #5]
 80051e8:	428c      	cmp	r4, r1
 80051ea:	d001      	beq.n	80051f0 <pinctrl_lookup_state+0x22>
		(*state)++;
 80051ec:	3308      	adds	r3, #8
 80051ee:	e7f0      	b.n	80051d2 <pinctrl_lookup_state+0x4>
			return 0;
 80051f0:	2000      	movs	r0, #0
 80051f2:	e7f7      	b.n	80051e4 <pinctrl_lookup_state+0x16>

080051f4 <reset_stm32_status>:
static int reset_stm32_status(const struct device *dev, uint32_t id,
			      uint8_t *status)
{
	const struct reset_stm32_config *config = dev->config;

	*status = !!sys_test_bit(config->base + STM32_RESET_SET_OFFSET(id),
 80051f4:	6843      	ldr	r3, [r0, #4]
 80051f6:	f3c1 104b 	ubfx	r0, r1, #5, #12
 80051fa:	681b      	ldr	r3, [r3, #0]
 80051fc:	f001 011f 	and.w	r1, r1, #31
	uint32_t temp = *(volatile uint32_t *)addr;
 8005200:	58c0      	ldr	r0, [r0, r3]
	return temp & (1 << bit);
 8005202:	2301      	movs	r3, #1
 8005204:	408b      	lsls	r3, r1
 8005206:	4203      	tst	r3, r0
 8005208:	bf14      	ite	ne
 800520a:	2301      	movne	r3, #1
 800520c:	2300      	moveq	r3, #0
 800520e:	7013      	strb	r3, [r2, #0]
				 STM32_RESET_REG_BIT(id));

	return 0;
}
 8005210:	2000      	movs	r0, #0
 8005212:	4770      	bx	lr

08005214 <reset_stm32_line_assert>:

static int reset_stm32_line_assert(const struct device *dev, uint32_t id)
{
 8005214:	b510      	push	{r4, lr}
	const struct reset_stm32_config *config = dev->config;

	sys_set_bit(config->base + STM32_RESET_SET_OFFSET(id),
 8005216:	6843      	ldr	r3, [r0, #4]
 8005218:	f3c1 104b 	ubfx	r0, r1, #5, #12
 800521c:	681a      	ldr	r2, [r3, #0]
 800521e:	f001 011f 	and.w	r1, r1, #31
	uint32_t temp = *(volatile uint32_t *)addr;
 8005222:	5884      	ldr	r4, [r0, r2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
 8005224:	2301      	movs	r3, #1
 8005226:	408b      	lsls	r3, r1
 8005228:	4323      	orrs	r3, r4
 800522a:	5083      	str	r3, [r0, r2]
		    STM32_RESET_REG_BIT(id));

	return 0;
}
 800522c:	2000      	movs	r0, #0
 800522e:	bd10      	pop	{r4, pc}

08005230 <reset_stm32_line_deassert>:

static int reset_stm32_line_deassert(const struct device *dev, uint32_t id)
{
 8005230:	b510      	push	{r4, lr}

#if DT_INST_PROP(0, set_bit_to_deassert)
	sys_set_bit(config->base + STM32_RESET_CLR_OFFSET(id),
		    STM32_RESET_REG_BIT(id));
#else
	sys_clear_bit(config->base + STM32_RESET_SET_OFFSET(id),
 8005232:	6843      	ldr	r3, [r0, #4]
 8005234:	f3c1 144b 	ubfx	r4, r1, #5, #12
 8005238:	6818      	ldr	r0, [r3, #0]
 800523a:	f001 011f 	and.w	r1, r1, #31
	uint32_t temp = *(volatile uint32_t *)addr;
 800523e:	5823      	ldr	r3, [r4, r0]
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
 8005240:	2201      	movs	r2, #1
 8005242:	408a      	lsls	r2, r1
 8005244:	ea23 0302 	bic.w	r3, r3, r2
 8005248:	5023      	str	r3, [r4, r0]
		      STM32_RESET_REG_BIT(id));
#endif

	return 0;
}
 800524a:	2000      	movs	r0, #0
 800524c:	bd10      	pop	{r4, pc}

0800524e <reset_stm32_line_toggle>:

static int reset_stm32_line_toggle(const struct device *dev, uint32_t id)
{
 800524e:	b538      	push	{r3, r4, r5, lr}
 8005250:	4604      	mov	r4, r0
 8005252:	460d      	mov	r5, r1
	reset_stm32_line_assert(dev, id);
 8005254:	f7ff ffde 	bl	8005214 <reset_stm32_line_assert>
	reset_stm32_line_deassert(dev, id);
 8005258:	4629      	mov	r1, r5
 800525a:	4620      	mov	r0, r4
 800525c:	f7ff ffe8 	bl	8005230 <reset_stm32_line_deassert>

	return 0;
}
 8005260:	2000      	movs	r0, #0
 8005262:	bd38      	pop	{r3, r4, r5, pc}

08005264 <reset_stm32_init>:

static int reset_stm32_init(const struct device *dev)
{
	return 0;
}
 8005264:	2000      	movs	r0, #0
 8005266:	4770      	bx	lr

08005268 <z_device_state_init>:

	while (dev < __device_end) {
		z_object_init(dev);
		++dev;
	}
}
 8005268:	4770      	bx	lr

0800526a <z_device_is_ready>:
{
	/*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 */
	if (dev == NULL) {
 800526a:	b140      	cbz	r0, 800527e <z_device_is_ready+0x14>
		return false;
	}

	return dev->state->initialized && (dev->state->init_res == 0U);
 800526c:	68c3      	ldr	r3, [r0, #12]
 800526e:	7858      	ldrb	r0, [r3, #1]
 8005270:	f010 0001 	ands.w	r0, r0, #1
 8005274:	bf1e      	ittt	ne
 8005276:	7818      	ldrbne	r0, [r3, #0]
 8005278:	fab0 f080 	clzne	r0, r0
 800527c:	0940      	lsrne	r0, r0, #5
}
 800527e:	4770      	bx	lr

08005280 <arch_system_halt>:
	__asm__ volatile(
 8005280:	f04f 0210 	mov.w	r2, #16
 8005284:	f3ef 8311 	mrs	r3, BASEPRI
 8005288:	f382 8812 	msr	BASEPRI_MAX, r2
 800528c:	f3bf 8f6f 	isb	sy
	for (;;) {
 8005290:	e7fe      	b.n	8005290 <arch_system_halt+0x10>

08005292 <k_sys_fatal_error_handler>:
{
 8005292:	b508      	push	{r3, lr}
	arch_system_halt(reason);
 8005294:	f7ff fff4 	bl	8005280 <arch_system_halt>

08005298 <z_early_memset>:
	(void) memset(dst, c, n);
 8005298:	f7ff bc85 	b.w	8004ba6 <memset>

0800529c <z_early_memcpy>:
	(void) memcpy(dst, src, n);
 800529c:	f7ff bc78 	b.w	8004b90 <memcpy>

080052a0 <z_impl_k_thread_start>:
	z_sched_start(thread);
 80052a0:	f7fe ba1e 	b.w	80036e0 <z_sched_start>

080052a4 <adjust_owner_prio.isra.0>:
	if (mutex->owner->base.prio != new_prio) {
 80052a4:	f990 300e 	ldrsb.w	r3, [r0, #14]
 80052a8:	428b      	cmp	r3, r1
 80052aa:	d001      	beq.n	80052b0 <adjust_owner_prio.isra.0+0xc>
		return z_set_prio(mutex->owner, new_prio);
 80052ac:	f7fe bc64 	b.w	8003b78 <z_set_prio>
}
 80052b0:	2000      	movs	r0, #0
 80052b2:	4770      	bx	lr

080052b4 <z_impl_k_mutex_init>:
{
 80052b4:	4603      	mov	r3, r0
	mutex->owner = NULL;
 80052b6:	2000      	movs	r0, #0
	mutex->lock_count = 0U;
 80052b8:	e9c3 0002 	strd	r0, r0, [r3, #8]
	list->tail = (sys_dnode_t *)list;
 80052bc:	e9c3 3300 	strd	r3, r3, [r3]
}
 80052c0:	4770      	bx	lr

080052c2 <z_priq_rb_lessthan>:
	int32_t b1 = thread_1->base.prio;
 80052c2:	f990 200e 	ldrsb.w	r2, [r0, #14]
	int32_t b2 = thread_2->base.prio;
 80052c6:	f991 300e 	ldrsb.w	r3, [r1, #14]
	if (b1 != b2) {
 80052ca:	429a      	cmp	r2, r3
 80052cc:	d106      	bne.n	80052dc <z_priq_rb_lessthan+0x1a>
			? 1 : 0;
 80052ce:	6900      	ldr	r0, [r0, #16]
 80052d0:	690b      	ldr	r3, [r1, #16]
 80052d2:	4298      	cmp	r0, r3
 80052d4:	bf2c      	ite	cs
 80052d6:	2000      	movcs	r0, #0
 80052d8:	2001      	movcc	r0, #1
 80052da:	4770      	bx	lr
	if (cmp > 0) {
 80052dc:	4293      	cmp	r3, r2
 80052de:	bfd4      	ite	le
 80052e0:	2000      	movle	r0, #0
 80052e2:	2001      	movgt	r0, #1
}
 80052e4:	4770      	bx	lr

080052e6 <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
 80052e6:	4603      	mov	r3, r0
 80052e8:	b920      	cbnz	r0, 80052f4 <z_reschedule_irqlock+0xe>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
 80052ea:	f3ef 8205 	mrs	r2, IPSR
 80052ee:	b90a      	cbnz	r2, 80052f4 <z_reschedule_irqlock+0xe>
 80052f0:	f7fc b808 	b.w	8001304 <arch_swap>
	__asm__ volatile(
 80052f4:	f383 8811 	msr	BASEPRI, r3
 80052f8:	f3bf 8f6f 	isb	sy
}
 80052fc:	4770      	bx	lr

080052fe <z_reschedule_unlocked>:
	__asm__ volatile(
 80052fe:	f04f 0310 	mov.w	r3, #16
 8005302:	f3ef 8011 	mrs	r0, BASEPRI
 8005306:	f383 8812 	msr	BASEPRI_MAX, r3
 800530a:	f3bf 8f6f 	isb	sy
	(void) z_reschedule_irqlock(arch_irq_lock());
 800530e:	f7ff bfea 	b.w	80052e6 <z_reschedule_irqlock>

08005312 <z_impl_k_thread_priority_get>:
}
 8005312:	f990 000e 	ldrsb.w	r0, [r0, #14]
 8005316:	4770      	bx	lr

08005318 <sys_clock_tick_get_32>:

uint32_t sys_clock_tick_get_32(void)
{
 8005318:	b508      	push	{r3, lr}
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)sys_clock_tick_get();
 800531a:	f7ff f991 	bl	8004640 <sys_clock_tick_get>
#else
	return (uint32_t)curr_tick;
#endif
}
 800531e:	bd08      	pop	{r3, pc}

08005320 <z_impl_k_uptime_ticks>:

int64_t z_impl_k_uptime_ticks(void)
{
	return sys_clock_tick_get();
 8005320:	f7ff b98e 	b.w	8004640 <sys_clock_tick_get>
